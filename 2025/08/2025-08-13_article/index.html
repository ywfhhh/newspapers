

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Ywfhhh">
  <meta name="keywords" content="">
  
    <meta name="description" content="æ¯æ—¥æœ€æ–°è®ºæ–‡åˆ†äº«">
<meta property="og:type" content="article">
<meta property="og:title" content="ä»Šæ—¥è®ºæ–‡æŠ¥çº¸">
<meta property="og:url" content="http://example.com/2025/08/2025-08-13_article/index.html">
<meta property="og:site_name" content="è®ºæ–‡æŠ¥çº¸é›†åˆ">
<meta property="og:description" content="æ¯æ—¥æœ€æ–°è®ºæ–‡åˆ†äº«">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="og:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
<meta property="article:published_time" content="2025-08-12T16:00:00.000Z">
<meta property="article:modified_time" content="2025-08-13T10:39:57.843Z">
<meta property="article:author" content="Ywfhhh">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>ä»Šæ—¥è®ºæ–‡æŠ¥çº¸ - è®ºæ–‡æŠ¥çº¸é›†åˆ</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- ä¸»é¢˜ä¾èµ–çš„å›¾æ ‡åº“ï¼Œä¸è¦è‡ªè¡Œä¿®æ”¹ -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>ã€å­¦æœ¯åŠ¨æ€æŠ¥å‘Šã€‘è®ºæ–‡æŠ¥çº¸</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>è®ºæ–‡é›†åˆ</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="ä»Šæ—¥è®ºæ–‡æŠ¥çº¸"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-08-12 16:00" pubdate>
          æ˜ŸæœŸäºŒ, å…«æœˆ 12æ—¥ 2025
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          <!-- compatible with older versions-->
          45k å­—
        
      </span>
    

    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> æ¬¡
        </span>
        

      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">ä»Šæ—¥è®ºæ–‡æŠ¥çº¸</h1>
            
            
              <div class="markdown-body">
                
                <center><h1>ä»Šæ—¥è®ºæ–‡æŠ¥çº¸</h1></center>

<p>ğŸ“… <strong>æ—¥æœŸ</strong>ï¼š2025-08-13<br>ğŸ“„ <strong>å‘ç°è®ºæ–‡æ•°é‡</strong>ï¼š300  </p>
<h2 id="rl">Reinforcement Learning</h2>


<h3 id="1-Consensus-based-Decentralized-Multi-agent-Reinforcement-Learning-for-Random-Access-Network-Optimization"><a href="#1-Consensus-based-Decentralized-Multi-agent-Reinforcement-Learning-for-Random-Access-Network-Optimization" class="headerlink" title="1. Consensus-based Decentralized Multi-agent Reinforcement Learning for Random Access Network Optimization"></a>1. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Consensus-based_Decentralized_Multi-agent_Reinforcement_Learning_for_Random_Access_Network_Optimizat.pdf">Consensus-based Decentralized Multi-agent Reinforcement Learning for Random Access Network Optimization</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">The Ohio State University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºå…±è¯†çš„å…¨åˆ†å¸ƒå¼å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰æ–¹æ³•ï¼Œç”¨äºéšæœºæ¥å…¥ï¼ˆRAï¼‰ç½‘ç»œçš„MACå±‚ä¼˜åŒ–ã€‚æ–¹æ³•é€šè¿‡ä»…åœ¨é‚»å±…é—´äº¤æ¢å±€éƒ¨å¥–åŠ±ï¼Œç»“åˆactor-criticæ¶æ„ï¼Œåœ¨æ— éœ€ä¸­å¿ƒåŒ–è®­ç»ƒçš„æƒ…å†µä¸‹å®ç°å…¨å±€æ”¶æ•›ï¼Œæ˜¾è‘—é™ä½äº†é€šä¿¡å¼€é”€ã€‚ç†è®ºåˆ†æè¯æ˜äº†ç®—æ³•çš„æœ‰é™æ—¶é—´æ”¶æ•›æ€§ï¼Œå®éªŒç»“æœè¡¨æ˜è¯¥æ–¹æ³•åœ¨æå‡ç½‘ç»œååé‡å’Œå…¬å¹³æ€§æ–¹é¢ä¸ä¸­å¿ƒåŒ–æ–¹æ³•ç›¸å½“ï¼Œä½†æ›´å…·å®ç”¨æ€§å’Œæ‰©å±•æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="2-AR-GRPO-Training-Autoregressive-Image-Generation-Models-via-Reinforcement-Learning"><a href="#2-AR-GRPO-Training-Autoregressive-Image-Generation-Models-via-Reinforcement-Learning" class="headerlink" title="2. AR-GRPO: Training Autoregressive Image Generation Models via Reinforcement Learning"></a>2. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/AR-GRPO__Training_Autoregressive_Image_Generation_Models_via_Reinforcement_Learning.pdf">AR-GRPO: Training Autoregressive Image Generation Models via Reinforcement Learning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Kuaishou Technology</span></p>
<p>è¯¥è®ºæ–‡æå‡ºAR-GRPOæ–¹æ³•ï¼Œå°†åœ¨çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è®­ç»ƒé›†æˆåˆ°è‡ªå›å½’ï¼ˆARï¼‰å›¾åƒç”Ÿæˆæ¨¡å‹ä¸­ï¼Œå¹¶é¦–æ¬¡å°†Group Relative Policy Optimizationï¼ˆGRPOï¼‰ç®—æ³•åº”ç”¨äºå›¾åƒç”Ÿæˆï¼Œé€šè¿‡å¤šç»´åº¦å¥–åŠ±å‡½æ•°ï¼ˆå¦‚è¯­ä¹‰ä¸€è‡´æ€§ã€è§†è§‰è´¨é‡å’ŒçœŸå®æ„Ÿï¼‰ç»†è‡´ä¼˜åŒ–æ¨¡å‹è¾“å‡ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRLå¢å¼ºçš„ARæ¨¡å‹åœ¨ç±»åˆ«æ¡ä»¶å’Œæ–‡æœ¬æ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œæ˜¾è‘—æå‡äº†å›¾åƒè´¨é‡å’Œäººç±»åå¥½æŒ‡æ ‡ï¼Œå°¤å…¶åœ¨äººç±»è¯„ä»·ã€åˆ†è¾¨ç‡å’Œæ¨¡å‹è§„æ¨¡æ‰©å±•æ–¹é¢å±•ç°å¼ºå¤§æ³›åŒ–èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="3-Pushdown-Reward-Machines-for-Reinforcement-Learning"><a href="#3-Pushdown-Reward-Machines-for-Reinforcement-Learning" class="headerlink" title="3. Pushdown Reward Machines for Reinforcement Learning"></a>3. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Pushdown_Reward_Machines_for_Reinforcement_Learning.pdf">Pushdown Reward Machines for Reinforcement Learning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Utrecht Universiteit</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†Pushdown Reward Machinesï¼ˆpdRMsï¼‰ï¼ŒåŸºäºç¡®å®šæ€§ä¸‹æ¨è‡ªåŠ¨æœºï¼Œèƒ½å¤Ÿè¡¨è¾¾å’Œå¥–åŠ±å¯ç”±ç¡®å®šæ€§ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€è¡¨ç¤ºçš„éé©¬å°”å¯å¤«ä»»åŠ¡ï¼Œæ˜¾è‘—æå‡äº†ä»»åŠ¡è¡¨è¾¾èƒ½åŠ›ã€‚ä½œè€…è®¾è®¡äº†ä¸¤ç§ç­–ç•¥è®¿é—®æ¨¡å¼ï¼ˆå…¨æ ˆè®¿é—®ä¸top-kè®¿é—®ï¼‰ï¼Œå¹¶è¯æ˜åœ¨éƒ¨åˆ†åœºæ™¯ä¸‹top-kç­–ç•¥ä¸å…¨æ ˆç­–ç•¥åœ¨æœ€ä¼˜æ€§ä¸Šç­‰ä»·ï¼Œç†è®ºå’Œå®éªŒåˆ†æè¡¨æ˜pdRMsåœ¨éƒ¨åˆ†ä»»åŠ¡ä¸Šè¾ƒCounting Reward Automataå…·å¤‡æ›´é«˜ç©ºé—´æ•ˆç‡ï¼Œä¸”åœ¨å¤šç¦»æ•£å’Œè¿ç»­ä»»åŠ¡ä¸­æå‡äº†è®­ç»ƒæ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="4-Offline-to-Online-Reinforcement-Learning-with-Classifier-Free-Diffusion-Generation"><a href="#4-Offline-to-Online-Reinforcement-Learning-with-Classifier-Free-Diffusion-Generation" class="headerlink" title="4. Offline-to-Online Reinforcement Learning with Classifier-Free Diffusion Generation"></a>4. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Offline-to-Online_Reinforcement_Learning_with_Classifier-Free_Diffusion_Generation.pdf">Offline-to-Online Reinforcement Learning with Classifier-Free Diffusion Generation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Shanghai Jiao Tong University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ•°æ®å¢å¼ºæ–¹æ³•Classifier-Free Diffusion Generation (CFDG)ï¼Œåˆ©ç”¨æ— åˆ†ç±»å™¨å¼•å¯¼çš„æ‰©æ•£æ¨¡å‹åŒæ—¶å¯¹ç¦»çº¿æ•°æ®å’Œåœ¨çº¿æ•°æ®è¿›è¡Œå¢å¼ºï¼Œå¹¶é€šè¿‡æ•°æ®é‡åŠ æƒä½¿ç”Ÿæˆæ•°æ®æ›´è´´åˆåœ¨çº¿ç­–ç•¥åˆ†å¸ƒï¼Œå¯ä¸ä¸»æµO2O RLç®—æ³•ï¼ˆå¦‚IQLã€PEXã€APLï¼‰é›†æˆã€‚å®éªŒè¯æ˜ï¼ŒCFDGåœ¨D4RL Locomotionå’ŒAntMazeåŸºå‡†ä¸Šå¯å¹³å‡æå‡15%çš„æ€§èƒ½ï¼Œç”Ÿæˆçš„æ•°æ®æ›´é«˜è´¨é‡ã€ä¸åœ¨çº¿åˆ†å¸ƒæ›´ä¸€è‡´ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="5-Sparsity-Driven-Plasticity-in-Multi-Task-Reinforcement-Learning"><a href="#5-Sparsity-Driven-Plasticity-in-Multi-Task-Reinforcement-Learning" class="headerlink" title="5. Sparsity-Driven Plasticity in Multi-Task Reinforcement Learning"></a>5. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Sparsity-Driven_Plasticity_in_Multi-Task_Reinforcement_Learning.pdf">Sparsity-Driven Plasticity in Multi-Task Reinforcement Learning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Groningen</span></p>
<p>æœ¬æ–‡ç³»ç»Ÿæ€§ç ”ç©¶äº†åœ¨å¤šä»»åŠ¡å¼ºåŒ–å­¦ä¹ ï¼ˆMTRLï¼‰ä¸­ï¼Œç¨€ç–åŒ–æ–¹æ³•ï¼ˆç‰¹åˆ«æ˜¯Gradual Magnitude Pruningä¸Sparse Evolutionary Trainingï¼‰å¯¹æå‡ç¥ç»ç½‘ç»œå¯å¡‘æ€§åŠä»»åŠ¡è¡¨ç°çš„ä½œç”¨ã€‚é€šè¿‡åœ¨å¤šç§MTRLæ¶æ„ä¸æ ‡å‡†åŸºå‡†ç¯å¢ƒä¸Šçš„å®è¯åˆ†æï¼Œç»“æœè¡¨æ˜ç¨€ç–åŒ–ä¸ä»…ç¼“è§£äº†ç¥ç»å…ƒä¼‘çœ å’Œè¡¨ç¤ºå´©æºƒç­‰å¯å¡‘æ€§é€€åŒ–ç°è±¡ï¼Œè¿˜å¸¸å¸¸æå‡äº†å¤šä»»åŠ¡æ€§èƒ½ï¼Œä¼˜äºè‡´åŠ›äºå¯å¡‘æ€§æå‡çš„ä¸“ç”¨æ–¹æ³•å’Œå¸¸ç”¨æ­£åˆ™åŒ–æ‰‹æ®µï¼Œå°¤å…¶åœ¨å¸¸è§æ¶æ„å¦‚MTPPOå’ŒMoEä¸­è¡¨ç°çªå‡ºã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="6-Multi-level-Advantage-Credit-Assignment-for-Cooperative-Multi-Agent-Reinforcement-Learning"><a href="#6-Multi-level-Advantage-Credit-Assignment-for-Cooperative-Multi-Agent-Reinforcement-Learning" class="headerlink" title="6. Multi-level Advantage Credit Assignment for Cooperative Multi-Agent Reinforcement Learning"></a>6. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Multi-level_Advantage_Credit_Assignment_for_Cooperative_Multi-Agent_Reinforcement_Learning.pdf">Multi-level Advantage Credit Assignment for Cooperative Multi-Agent Reinforcement Learning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Mila - Quebec AI Institute</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šå±‚æ¬¡ä¼˜åŠ¿ä¿¡å·åˆ†é…æ–¹æ³•ï¼ˆMACAï¼‰ï¼Œé€šè¿‡æ˜¾å¼çš„åäº‹å®æ¨ç†ï¼Œåˆ†åˆ«å¯¹ä¸ªä½“ã€è”åˆåŠå¼ºç›¸å…³å­é›†çš„åŠ¨ä½œè´¡çŒ®è¿›è¡Œæ¨æ–­ï¼Œå¹¶ç»“åˆTransformerè‡ªæ³¨æ„åŠ›æœºåˆ¶åŠ¨æ€å»ºæ¨¡å¤šæ™ºèƒ½ä½“é—´çš„ç›¸å…³æ€§ï¼Œå®ç°å¤šå±‚æ¬¡çš„ä¿¡ç”¨åˆ†é…ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMACAåœ¨StarCraftå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ åŸºå‡†ä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†åä½œæ•ˆç‡å’Œæ”¶æ•›æ€§èƒ½ï¼Œä¼˜äºç°æœ‰ä¸»æµæ–¹æ³•ï¼Œç†è®ºåˆ†æä¹Ÿæ”¯æŒå…¶æœ‰æ•ˆæ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="7-Natural-Language-Driven-Viewpoint-Navigation-for-Volume-Exploration-via-Semantic-Block-Representation"><a href="#7-Natural-Language-Driven-Viewpoint-Navigation-for-Volume-Exploration-via-Semantic-Block-Representation" class="headerlink" title="7. Natural Language-Driven Viewpoint Navigation for Volume Exploration via Semantic Block Representation"></a>7. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Natural_Language-Driven_Viewpoint_Navigation_for_Volume_Exploration_via_Semantic_Block_Representatio.pdf">Natural Language-Driven Viewpoint Navigation for Volume Exploration via Semantic Block Representation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Sun Yat-sen University</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè‡ªç„¶è¯­è¨€äº¤äº’çš„ä½“æ•°æ®æ¢ç´¢æ¡†æ¶ï¼Œé€šè¿‡å°†ä½“æ•°æ®åˆ†å‰²ä¸ºè¯­ä¹‰å—ï¼Œå¹¶åˆ©ç”¨CLIPæ¨¡å‹å¯¹å›¾åƒå’Œæ–‡æœ¬è¿›è¡Œå¯¹é½ï¼Œç»“åˆå¼ºåŒ–å­¦ä¹ ï¼ˆPPOç®—æ³•ï¼‰è‡ªåŠ¨ä¼˜åŒ–è§†ç‚¹é€‰æ‹©ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å‡†ç¡®æ•æ‰ç”¨æˆ·æ„å›¾ï¼Œæå‡ä½“æ•°æ®å¯¼èˆªæ•ˆç‡å’Œå¯è§£é‡Šæ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="8-Stackelberg-Coupling-of-Online-Representation-Learning-and-Reinforcement-Learning"><a href="#8-Stackelberg-Coupling-of-Online-Representation-Learning-and-Reinforcement-Learning" class="headerlink" title="8. Stackelberg Coupling of Online Representation Learning and Reinforcement Learning"></a>8. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Stackelberg_Coupling_of_Online_Representation_Learning_and_Reinforcement_Learning.pdf">Stackelberg Coupling of Online Representation Learning and Reinforcement Learning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Fordham University</span></p>
<p>æœ¬æ–‡æå‡ºäº†SCORERæ¡†æ¶ï¼Œé€šè¿‡å°†æ„ŸçŸ¥ç½‘ç»œï¼ˆè¡¨å¾å­¦ä¹ ï¼‰å’Œæ§åˆ¶ç½‘ç»œï¼ˆå¼ºåŒ–å­¦ä¹ ï¼‰ä¹‹é—´çš„åä½œå»ºæ¨¡ä¸ºStackelbergåšå¼ˆï¼Œå®ç°äº†ä¸¤è€…çš„å±‚çº§åŠ¨æ€è€¦åˆã€‚æ–¹æ³•é‡‡ç”¨ä¸¤æ—¶é—´å°ºåº¦æ¢¯åº¦ä¸‹é™è¿‘ä¼¼åšå¼ˆå‡è¡¡ï¼Œå¹¶åœ¨å¤šç§DQNå˜ä½“åŠæ ‡å‡†ä»»åŠ¡ä¸ŠéªŒè¯ï¼Œç»“æœæ˜¾ç¤ºSCORERåœ¨æ ·æœ¬æ•ˆç‡å’Œæœ€ç»ˆè¡¨ç°ä¸Šå‡ä¼˜äºä¼ ç»Ÿç«¯åˆ°ç«¯æ–¹æ³•ã€‚ç»“è®ºï¼šåŸºäºåšå¼ˆè®ºçš„æ„ŸçŸ¥-æ§åˆ¶åŠ¨æ€è®¾è®¡å¯ä»¥åœ¨ä¸å¢åŠ å¤æ‚è¾…åŠ©ç›®æ ‡æˆ–æ¶æ„çš„å‰æä¸‹æ˜¾è‘—æå‡æ·±åº¦å¼ºåŒ–å­¦ä¹ æ€§èƒ½ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="9-Efficient-Reward-Identification-In-Max-Entropy-Reinforcement-Learning-with-Sparsity-and-Rank-Priors"><a href="#9-Efficient-Reward-Identification-In-Max-Entropy-Reinforcement-Learning-with-Sparsity-and-Rank-Priors" class="headerlink" title="9. Efficient Reward Identification In Max Entropy Reinforcement Learning with Sparsity and Rank Priors"></a>9. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Efficient_Reward_Identification_In_Max_Entropy_Reinforcement_Learning_with_Sparsity_and_Rank_Priors.pdf">Efficient Reward Identification In Max Entropy Reinforcement Learning with Sparsity and Rank Priors</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Michigan</span></p>
<p>æœ¬æ–‡æå‡ºäº†åœ¨æœ€å¤§ç†µå¼ºåŒ–å­¦ä¹ ä¸­é«˜æ•ˆè¯†åˆ«æ—¶å˜å¥–åŠ±å‡½æ•°çš„ä¼˜åŒ–æ–¹æ³•ï¼ŒåŒ…æ‹¬åŸºäºå¥–åŠ±åˆ‡æ¢ç¨€ç–æ€§å’Œç‰¹å¾ä½ç§©å‡è®¾çš„ç®—æ³•ã€‚é€šè¿‡è´ªå¿ƒåŒºé—´åˆ’åˆ†å’Œæ ¸èŒƒæ•°ä¼˜åŒ–ï¼Œæœ‰æ•ˆæ¢å¤å¥–åŠ±ç»“æ„ï¼Œåœ¨å¤šç§ç½‘æ ¼ä¸–ç•Œå®éªŒä¸­æ˜¾ç¤ºå‡ºé²æ£’æ€§å’Œè¾ƒä¼˜çš„è¿ç§»èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="10-Pentest-R1-Towards-Autonomous-Penetration-Testing-Reasoning-Optimized-via-Two-Stage-Reinforcement-Learning"><a href="#10-Pentest-R1-Towards-Autonomous-Penetration-Testing-Reasoning-Optimized-via-Two-Stage-Reinforcement-Learning" class="headerlink" title="10. Pentest-R1: Towards Autonomous Penetration Testing Reasoning Optimized via Two-Stage Reinforcement Learning"></a>10. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Pentest-R1__Towards_Autonomous_Penetration_Testing_Reasoning_Optimized_via_Two-Stage_Reinforcement_L.pdf">Pentest-R1: Towards Autonomous Penetration Testing Reasoning Optimized via Two-Stage Reinforcement Learning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">State Key Laboratory of Cyberspace Security Defense, Institute of Information Engineering, Chinese Academy of Sciences</span></p>
<p>æœ¬æ–‡æå‡ºäº†Pentest-R1æ¡†æ¶ï¼Œé€šè¿‡ä¸¤é˜¶æ®µå¼ºåŒ–å­¦ä¹ æå‡å¤§è¯­è¨€æ¨¡å‹åœ¨è‡ªåŠ¨æ¸—é€æµ‹è¯•ä¸­çš„æ¨ç†ä¸è‡ªé€‚åº”èƒ½åŠ›ã€‚æ–¹æ³•é¦–å…ˆåœ¨åŒ…å«500å¤šæ¡çœŸå®å¤šæ­¥ä¸“å®¶æ¸—é€æµ‹è¯•æ¼”ç»ƒçš„æ•°æ®é›†ä¸Šè¿›è¡Œç¦»çº¿å¼ºåŒ–å­¦ä¹ ï¼Œå¥ å®šåŸºç¡€æ”»å‡»é€»è¾‘ï¼Œå†åœ¨äº¤äº’å¼CTFç¯å¢ƒä¸­é€šè¿‡åœ¨çº¿å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–ç­–ç•¥ä¸é”™è¯¯è‡ªçº èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼ŒPentest-R1åœ¨Cybenchå’ŒAutoPenBenchåŸºå‡†ä¸Šè¶…è¶Šäº†å¤§éƒ¨åˆ†åŒç±»å¼€æºåŠä¸“æœ‰æ¨¡å‹ï¼ŒéªŒè¯äº†ä¸¤é˜¶æ®µç»“åˆå¯¹æå‡è‡ªåŠ¨æ¸—é€æµ‹è¯•è¡¨ç°çš„å…³é”®ä½œç”¨ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="11-Policy-Newton-methods-for-Distortion-Riskmetrics"><a href="#11-Policy-Newton-methods-for-Distortion-Riskmetrics" class="headerlink" title="11. Policy Newton methods for Distortion Riskmetrics"></a>11. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Policy_Newton_methods_for_Distortion_Riskmetrics.pdf">Policy Newton methods for Distortion Riskmetrics</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Indian Institute of Technology Madras</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åœ¨æœ‰é™æ—¶åŸŸMarkovå†³ç­–è¿‡ç¨‹ï¼ˆMDPï¼‰ä¸­æœ€å¤§åŒ–ç•¸å˜é£é™©åº¦é‡ï¼ˆDistortion Riskmetric, DRMï¼‰çš„ç­–ç•¥Newtonæ³•ã€‚æ–¹æ³•ä¸Šï¼Œä½œè€…æ¨å¯¼äº†DRMç›®æ ‡çš„ç­–ç•¥Hessianå®šç†ï¼Œé€šè¿‡ä¼¼ç„¶æ¯”æ³•æ„å»ºäº†åŸºäºæ ·æœ¬è½¨è¿¹çš„DRMæ¢¯åº¦å’ŒHessianä¼°è®¡å™¨ï¼Œå¹¶æå‡ºäº†å¸¦ä¸‰æ¬¡æ­£åˆ™åŒ–çš„ç­–ç•¥Newtonç®—æ³•ï¼ˆCRPN-DRMï¼‰ï¼Œç†è®ºä¸Šè¯æ˜è¯¥ç®—æ³•ä»¥O(Ïµ^-3.5)çš„æ ·æœ¬å¤æ‚åº¦æ”¶æ•›åˆ°Ïµ-äºŒé˜¶ç¨³å®šç‚¹ï¼Œèƒ½æœ‰æ•ˆè§„é¿éç‚¹ã€‚å®éªŒåœ¨Cliff Walkã€Cart PoleåŠHumanoidç­‰ç¯å¢ƒä¸‹è¡¨æ˜ï¼Œè¯¥ç®—æ³•åœ¨é£é™©æ•æ„Ÿç›®æ ‡ä¸‹ä¼˜äºé£é™©ä¸­æ€§åŸºçº¿ç­–ç•¥ï¼Œè·å¾—æ›´é«˜æœŸæœ›å›æŠ¥ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="12-Pref-GUIDE-Continual-Policy-Learning-from-Real-Time-Human-Feedback-via-Preference-Based-Learning"><a href="#12-Pref-GUIDE-Continual-Policy-Learning-from-Real-Time-Human-Feedback-via-Preference-Based-Learning" class="headerlink" title="12. Pref-GUIDE: Continual Policy Learning from Real-Time Human Feedback via Preference-Based Learning"></a>12. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Pref-GUIDE__Continual_Policy_Learning_from_Real-Time_Human_Feedback_via_Preference-Based_Learning.pdf">Pref-GUIDE: Continual Policy Learning from Real-Time Human Feedback via Preference-Based Learning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Duke University</span></p>
<p>æœ¬æ–‡æå‡ºPref-GUIDEæ¡†æ¶ï¼Œé€šè¿‡å°†å®æ—¶äººç±»æ ‡æ³¨çš„å™ªå£°æ ‡é‡åé¦ˆè½¬åŒ–ä¸ºå±€éƒ¨å¯¹æ¯”åå¥½æ•°æ®ï¼Œå®ç°æ›´ç¨³å®šå’Œé«˜æ•ˆçš„å¥–åŠ±æ¨¡å‹è®­ç»ƒï¼Œæå‡åŸºäºäººç±»åé¦ˆçš„æŒç»­ç­–ç•¥å­¦ä¹ ã€‚Pref-GUIDEç”±ä¸¤ä¸ªå…³é”®æ¨¡å—ç»„æˆï¼šPref-GUIDE Individualåœ¨å±€éƒ¨æ—¶é—´çª—å£å†…å°†æ ‡é‡åé¦ˆè½¬ä¸ºåå¥½å¯¹ï¼ŒPref-GUIDE Votingåˆ™åœ¨å¤šè¯„ä¼°è€…é—´èšåˆå¥–åŠ±æ¨¡å‹ä»¥è¾¾æˆç¾¤ä½“å…±è¯†ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸‰ä¸ªå¤æ‚è§†è§‰RLä»»åŠ¡ä¸­ä¼˜äºåŸºäºæ ‡é‡å›å½’çš„ä¸»æµæ–¹æ³•ï¼Œå¹¶åœ¨éƒ¨åˆ†ä»»åŠ¡ä¸Šè¶…è¿‡ä¸“å®¶è®¾è®¡çš„ç¨ å¯†å¥–åŠ±ï¼ŒéªŒè¯äº†å…¶åœ¨é«˜å™ªå£°ã€å¤šäººåé¦ˆä¸‹çš„ç¨³å¥æ€§å’Œå¯æ‰©å±•æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="13-Reinforcement-Learning-in-Vision-A-Survey"><a href="#13-Reinforcement-Learning-in-Vision-A-Survey" class="headerlink" title="13. Reinforcement Learning in Vision: A Survey"></a>13. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Reinforcement_Learning_in_Vision__A_Survey.pdf">Reinforcement Learning in Vision: A Survey</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">National University of Singapore</span></p>
<p>æœ¬è®ºæ–‡ç³»ç»Ÿç»¼è¿°äº†è§†è§‰é¢†åŸŸä¸­å¼ºåŒ–å­¦ä¹ ï¼ˆVisual RLï¼‰çš„æœ€æ–°è¿›å±•ï¼Œæ¶µç›–å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ã€è§†è§‰ç”Ÿæˆã€ç»Ÿä¸€æ¨¡å‹å’Œè§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹å››å¤§æ–¹å‘ï¼Œæ¢³ç†äº†ä»RLHFã€PPOåˆ°GRPOç­‰ä¸»æµç­–ç•¥ï¼Œå¹¶æå‡ºäº†ä»¥å¥–åŠ±ç²’åº¦å’Œç›‘ç£æ–¹å¼ä¸ºåŸºç¡€çš„è§†è§‰RLæ–¹æ³•å­¦åˆ†ç±»æ¡†æ¶ã€‚ç»“è®ºæŒ‡å‡ºï¼Œè§†è§‰RLæ­£æ¨åŠ¨æ„ŸçŸ¥ã€æ¨ç†ä¸ç”Ÿæˆä»»åŠ¡çš„ç»Ÿä¸€å‘å±•ï¼Œä½†åœ¨æ ·æœ¬æ•ˆç‡ã€æ³›åŒ–èƒ½åŠ›ã€å¥–åŠ±è®¾è®¡ç­‰æ–¹é¢ä»é¢ä¸´é‡å¤§æŒ‘æˆ˜ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="14-Part-I-Tricks-or-Traps-A-Deep-Dive-into-RL-for-LLM-Reasoning"><a href="#14-Part-I-Tricks-or-Traps-A-Deep-Dive-into-RL-for-LLM-Reasoning" class="headerlink" title="14. Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning"></a>14. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Part_I__Tricks_or_Traps__A_Deep_Dive_into_RL_for_LLM_Reasoning.pdf">Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Alibaba Group</span></p>
<p>æœ¬æ–‡ç³»ç»Ÿæ€§è¯„æµ‹äº†å½“å‰å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†ä¸­çš„ä¸»æµå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æŠ€æœ¯ï¼ŒåŒ…æ‹¬å½’ä¸€åŒ–ã€è£å‰ªã€è¿‡æ»¤åŠæŸå¤±èšåˆç­‰å…³é”®æŠ€å·§ï¼Œå¹¶åœ¨ç»Ÿä¸€å¼€æºå¹³å°ä¸‹é€šè¿‡ä¸åŒæ¨¡å‹è§„æ¨¡ä¸æ•°æ®éš¾åº¦çš„ç²¾ç»†å®éªŒï¼Œæ­ç¤ºå„æŠ€æœ¯çš„å†…åœ¨æœºåˆ¶åŠé€‚ç”¨åœºæ™¯ã€‚ç»“è®ºæŒ‡å‡ºï¼Œå¤šæ•°RLæŠ€æœ¯å¯¹å®éªŒè®¾ç½®é«˜åº¦æ•æ„Ÿï¼Œå¹¶æå‡ºåªç”¨åˆ†ç»„å‡å€¼+æ‰¹æ¬¡æ ‡å‡†å·®å½’ä¸€åŒ–å’Œtokençº§æŸå¤±èšåˆä¸¤é¡¹ç®€å•æŠ€æœ¯ï¼ˆLite PPOï¼‰å³å¯æ˜¾è‘—æå‡æ— è¯„ä»·å™¨ç­–ç•¥çš„å­¦ä¹ èƒ½åŠ›ï¼Œä¼˜äºä¼—å¤šç¹æ‚ç®—æ³•ï¼Œä¸ºRL4LLMå®è·µæä¾›äº†æ¸…æ™°å®ç”¨çš„é€‰æ‹©æŒ‡å—ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="15-ReconDreamer-RL-Enhancing-Reinforcement-Learning-via-Diffusion-based-Scene-Reconstruction"><a href="#15-ReconDreamer-RL-Enhancing-Reinforcement-Learning-via-Diffusion-based-Scene-Reconstruction" class="headerlink" title="15. ReconDreamer-RL: Enhancing Reinforcement Learning via Diffusion-based Scene Reconstruction"></a>15. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/ReconDreamer-RL__Enhancing_Reinforcement_Learning_via_Diffusion-based_Scene_Reconstruction.pdf">ReconDreamer-RL: Enhancing Reinforcement Learning via Diffusion-based Scene Reconstruction</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">GigaAI</span></p>
<p>è¯¥è®ºæ–‡æå‡ºReconDreamer-RLæ¡†æ¶ï¼Œå°†è§†é¢‘æ‰©æ•£å…ˆéªŒä¸ä¸‰ç»´é«˜æ–¯æ³¼æº…ï¼ˆ3DGSï¼‰åœºæ™¯é‡å»ºå’ŒåŠ¨åŠ›å­¦å»ºæ¨¡ç›¸ç»“åˆï¼Œæ„å»ºæ›´çœŸå®çš„æ¨¡æ‹Ÿç¯å¢ƒä»¥æå‡ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶ä¸­çš„å¼ºåŒ–å­¦ä¹ ã€‚æ–¹æ³•åŒ…æ‹¬ReconSimulatorå®ç°é«˜ä¿çœŸæ„ŸçŸ¥ä¸ç‰©ç†å»ºæ¨¡ï¼ŒDynamic Adversary Agentï¼ˆDAAï¼‰è‡ªåŠ¨ç”Ÿæˆå¤æ‚è§’è½æ¡ˆä¾‹ï¼ŒCousin Trajectory Generatorï¼ˆCTGï¼‰æ‰©å±•è®­ç»ƒæ•°æ®å¤šæ ·æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ¯”æ¨¡ä»¿å­¦ä¹ æ–¹æ³•å°†ç¢°æ’ç‡é™ä½5å€ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨æç«¯åœºæ™¯ä¸‹çš„å®‰å…¨æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="16-Pose-RFT-Enhancing-MLLMs-for-3D-Pose-Generation-via-Hybrid-Action-Reinforcement-Fine-Tuning"><a href="#16-Pose-RFT-Enhancing-MLLMs-for-3D-Pose-Generation-via-Hybrid-Action-Reinforcement-Fine-Tuning" class="headerlink" title="16. Pose-RFT: Enhancing MLLMs for 3D Pose Generation via Hybrid Action Reinforcement Fine-Tuning"></a>16. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Pose-RFT__Enhancing_MLLMs_for_3D_Pose_Generation_via_Hybrid_Action_Reinforcement_Fine-Tuning.pdf">Pose-RFT: Enhancing MLLMs for 3D Pose Generation via Hybrid Action Reinforcement Fine-Tuning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">CASIA</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†Pose-RFTï¼Œä¸€ç§ä¸“ä¸º3Däººä½“å§¿æ€ç”Ÿæˆä»»åŠ¡è®¾è®¡çš„å¼ºåŒ–å¾®è°ƒæ¡†æ¶ï¼Œé’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ã€‚æ–¹æ³•å°†3Då§¿æ€ç”Ÿæˆå»ºæ¨¡ä¸ºç¦»æ•£ï¼ˆæ–‡æœ¬ï¼‰ä¸è¿ç»­ï¼ˆå§¿æ€å‚æ•°ï¼‰æ··åˆåŠ¨ä½œç©ºé—´ä¸‹çš„å¼ºåŒ–å­¦ä¹ é—®é¢˜ï¼Œå¹¶å¼•å…¥HyGRPOç®—æ³•ï¼Œå®ç°å¯¹æ–‡æœ¬å’Œ3Då§¿æ€çš„è”åˆä¼˜åŒ–ã€‚Pose-RFTç»“åˆç©ºé—´å’Œè¯­ä¹‰å¯¹é½ç­‰ä»»åŠ¡ç‰¹å®šå¥–åŠ±å‡½æ•°ï¼Œæœ‰æ•ˆæå‡äº†æ¨¡å‹åœ¨å›¾åƒåˆ°å§¿æ€ã€æ–‡æœ¬åˆ°å§¿æ€ç­‰ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„å§¿æ€ç”ŸæˆMLLMsï¼Œè¯å®äº†æ··åˆåŠ¨ä½œå¼ºåŒ–å¾®è°ƒåœ¨3Då§¿æ€ç”Ÿæˆä¸­çš„æœ‰æ•ˆæ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="17-A-Tutorial-An-Intuitive-Explanation-of-Offline-Reinforcement-Learning-Theory"><a href="#17-A-Tutorial-An-Intuitive-Explanation-of-Offline-Reinforcement-Learning-Theory" class="headerlink" title="17. A Tutorial: An Intuitive Explanation of Offline Reinforcement Learning Theory"></a>17. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/A_Tutorial__An_Intuitive_Explanation_of_Offline_Reinforcement_Learning_Theory.pdf">A Tutorial: An Intuitive Explanation of Offline Reinforcement Learning Theory</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Alberta</span></p>
<p>æœ¬è®ºæ–‡ç³»ç»Ÿæ¢³ç†äº†ç¦»çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆOffline RLï¼‰çš„ç†è®ºåŸºç¡€ï¼Œé‡ç‚¹åˆ†æäº†å‡½æ•°è¡¨ç¤ºå’Œæ•°æ®è¦†ç›–çš„å‡è®¾æ¡ä»¶ï¼Œå¹¶é€šè¿‡åä¾‹æ­ç¤ºäº†ç¦»çº¿RLçš„å›ºæœ‰éš¾åº¦ï¼Œå¼ºè°ƒæ ·æœ¬å¤æ‚åº¦ä¸è¦†ç›–æ¡ä»¶çš„å…³ç³»ã€‚ç»“è®ºæŒ‡å‡ºï¼Œåªæœ‰åœ¨æ»¡è¶³ç‰¹å®šçš„è¦†ç›–ä¸è¡¨ç¤ºå‡è®¾ã€é‡‡ç”¨å¦‚æ‚²è§‚ä¼°è®¡å’ŒÎ»-returnç­‰æŠ€æœ¯ï¼Œæ‰èƒ½ä¿è¯å¤šé¡¹å¼æ ·æœ¬é«˜æ•ˆå­¦ä¹ ï¼Œå½“å‰ç†è®ºä¸ºå®é™…ç®—æ³•è®¾è®¡æä¾›äº†æ¸…æ™°çš„è¾¹ç•Œå’Œå¯ç¤ºã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="18-Symmetry-Aware-Transformer-Training-for-Automated-Planning"><a href="#18-Symmetry-Aware-Transformer-Training-for-Automated-Planning" class="headerlink" title="18. Symmetry-Aware Transformer Training for Automated Planning"></a>18. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Symmetry-Aware_Transformer_Training_for_Automated_Planning.pdf">Symmetry-Aware Transformer Training for Automated Planning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">LinkÃ¶ping University</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§é¢å‘è‡ªåŠ¨è§„åˆ’çš„å¯¹ç§°æ€§æ„ŸçŸ¥Transformerè®­ç»ƒæ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥åŸºäºå¯¹ç§°æ€§çš„å¯¹æ¯”å­¦ä¹ ç›®æ ‡ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆå¿½ç•¥è¾“å…¥ä¸­çš„å¯¹è±¡å‘½åå’ŒåŸå­é¡ºåºç­‰å†—ä½™å¯¹ç§°æ€§ï¼Œå¹¶é‡‡ç”¨æ— ä½ç½®ç¼–ç çš„ç¼–ç å™¨-è§£ç å™¨æ¶æ„å¤„ç†è§„åˆ’ä»»åŠ¡ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªè§„åˆ’é¢†åŸŸç›¸æ¯”PlanGPTæ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ³›åŒ–ä¸å¤–æ¨èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨æœªè§è¿‡çš„å¤§è§„æ¨¡é—®é¢˜ä¸Šæœ‰è¾ƒå¥½è¡¨ç°ï¼Œä½†åœ¨æå¤§è§„æ¨¡æˆ–å¤æ‚åŸŸä»å­˜åœ¨ä¸€å®šå±€é™ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="19-Robust-Reinforcement-Learning-over-Wireless-Networks-with-Homomorphic-State-Representations"><a href="#19-Robust-Reinforcement-Learning-over-Wireless-Networks-with-Homomorphic-State-Representations" class="headerlink" title="19. Robust Reinforcement Learning over Wireless Networks with Homomorphic State Representations"></a>19. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Robust_Reinforcement_Learning_over_Wireless_Networks_with_Homomorphic_State_Representations.pdf">Robust Reinforcement Learning over Wireless Networks with Homomorphic State Representations</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Padova</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºHomomorphic Robust Remote Reinforcement Learning (HR3L)çš„æ–°æ¶æ„ï¼Œç”¨äºåœ¨éç†æƒ³æ— çº¿ç½‘ç»œä¸­é«˜æ•ˆè®­ç»ƒè¿œç¨‹RLæ™ºèƒ½ä½“ã€‚HR3Lé€šè¿‡é©¬å°”å¯å¤«åŒæ€ç†è®ºå¯¹ç¯å¢ƒçŠ¶æ€è¿›è¡Œå‹ç¼©è¡¨å¾ï¼Œé‡‡ç”¨æ¨é€å¼é€šä¿¡å’Œå¼‚æ­¥æ¨¡å‹æ›´æ–°ï¼Œæ˜¾è‘—é™ä½é€šä¿¡å’Œè®¡ç®—è´Ÿæ‹…ï¼ŒåŒæ—¶æå‡å¯¹ä¿¡é“ä¸¢åŒ…ã€å»¶è¿Ÿå’Œå¸¦å®½å—é™ç­‰åœºæ™¯çš„é²æ£’æ€§ã€‚å®éªŒè¯æ˜HR3Låœ¨DeepMind Control Suiteå¤šä¸ªæ§åˆ¶ä»»åŠ¡å’Œå¤šç§ä¿¡é“æ¡ä»¶ä¸‹ï¼Œæ ·æœ¬æ•ˆç‡ã€å¸¦å®½å ç”¨å’Œé²æ£’æ€§å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶åœ¨é«˜ç»´è§‚æµ‹å’Œæœ‰é™èµ„æºä¸‹è¡¨ç°çªå‡ºã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="20-MORE-CLEAR-Multimodal-Offline-Reinforcement-learning-for-Clinical-notes-Leveraged-Enhanced-State-Representation"><a href="#20-MORE-CLEAR-Multimodal-Offline-Reinforcement-learning-for-Clinical-notes-Leveraged-Enhanced-State-Representation" class="headerlink" title="20. MORE-CLEAR: Multimodal Offline Reinforcement learning for Clinical notes Leveraged Enhanced State Representation"></a>20. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/MORE-CLEAR__Multimodal_Offline_Reinforcement_learning_for_Clinical_notes_Leveraged_Enhanced_State_Re.pdf">MORE-CLEAR: Multimodal Offline Reinforcement learning for Clinical notes Leveraged Enhanced State Representation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Seoul National University Hospital</span></p>
<p>è¯¥è®ºæ–‡æå‡ºMORE-CLEARæ¡†æ¶ï¼Œé€šè¿‡ç»“åˆç»“æ„åŒ–æ•°æ®ï¼ˆå¦‚å®éªŒå®¤ç»“æœã€ç”Ÿå‘½ä½“å¾ï¼‰ä¸éç»“æ„åŒ–ä¸´åºŠæ–‡æœ¬ï¼ˆé€šè¿‡å¤§è¯­è¨€æ¨¡å‹ç¼–ç ä¸æ‘˜è¦ï¼‰ï¼Œåˆ©ç”¨ä¸Šä¸‹æ–‡é—¨æ§èåˆä¸åŒå‘è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶ï¼Œæå‡ICUè„“æ¯’ç—‡æ²»ç–—ä¸­çš„æ‚£è€…çŠ¶æ€è¡¨å¾ï¼Œä»è€Œæ”¯æŒæ›´é²æ£’çš„ç¦»çº¿å¼ºåŒ–å­¦ä¹ ç­–ç•¥ä¼˜åŒ–ã€‚å®éªŒåœ¨MIMIC-IIIã€MIMIC-IVå’ŒçœŸå®åŒ»é™¢æ•°æ®é›†ä¸Šè¡¨æ˜ï¼Œå¤šæ¨¡æ€æ–¹æ³•åœ¨å­˜æ´»ç‡ä¼°è®¡å’Œç­–ç•¥è¡¨ç°ä¸Šå‡æ˜¾è‘—ä¼˜äºå•æ¨¡æ€åŸºçº¿ï¼Œå¹¶ä¸”è¯¥æ¡†æ¶æ˜“äºè¿ç§»è‡³å…¶å®ƒåŒ»å­¦å†³ç­–åœºæ™¯ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h2 id="robot">Robotics</h2>


<h3 id="21-DexFruit-Dexterous-Manipulation-and-Gaussian-Splatting-Inspection-of-Fruit"><a href="#21-DexFruit-Dexterous-Manipulation-and-Gaussian-Splatting-Inspection-of-Fruit" class="headerlink" title="21. DexFruit: Dexterous Manipulation and Gaussian Splatting Inspection of Fruit"></a>21. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/DexFruit__Dexterous_Manipulation_and_Gaussian_Splatting_Inspection_of_Fruit.pdf">DexFruit: Dexterous Manipulation and Gaussian Splatting Inspection of Fruit</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Stanford University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºDexFruitæ¡†æ¶ï¼Œå°†å…‰å­¦è§¦è§‰ä¼ æ„Ÿä¸æ‰©æ•£å¼æ¨¡ä»¿å­¦ä¹ ç­–ç•¥ç»“åˆï¼Œå®ç°å¯¹è‰è“ã€ç•ªèŒ„å’Œé»‘è“ç­‰è„†å¼±æ°´æœçš„æ¸©å’Œè‡ªä¸»æ“ä½œï¼Œæœ‰æ•ˆå‡å°‘æŸä¼¤ã€‚å…¶åˆ›æ–°çš„FruitSplatæ–¹æ³•åŸºäº3D Gaussian Splattingï¼Œèƒ½é«˜ç²¾åº¦å®šé‡åˆ†ææ°´æœè¡¨é¢æŸä¼¤ï¼Œå®ç°é«˜åˆ†è¾¨ç‡ä¸‰ç»´å¯è§†åŒ–ã€‚å®éªŒç»“æœæ˜¾ç¤ºDexFruitåœ¨å¤šç§æ°´æœä¸ŠæŠ“å–æˆåŠŸç‡è¾¾92%ï¼Œå¤–éƒ¨æŸä¼¤é™ä½20%ï¼Œæ˜¾è‘—ä¼˜äºè§†è§‰æˆ–è§¦è§‰å•ä¸€æ–¹æ³•ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="22-Communication-Efficient-Multi-Agent-3D-Detection-via-Hybrid-Collaboration"><a href="#22-Communication-Efficient-Multi-Agent-3D-Detection-via-Hybrid-Collaboration" class="headerlink" title="22. Communication-Efficient Multi-Agent 3D Detection via Hybrid Collaboration"></a>22. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Communication-Efficient_Multi-Agent_3D_Detection_via_Hybrid_Collaboration.pdf">Communication-Efficient Multi-Agent 3D Detection via Hybrid Collaboration</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Shanghai Jiao Tong University</span></p>
<p>æœ¬æ–‡æå‡ºäº†HyCommï¼Œä¸€ç§åŸºäºæ··åˆåä½œçš„é«˜æ•ˆé€šä¿¡å¤šæ™ºèƒ½ä½“LiDAR 3Dç›®æ ‡æ£€æµ‹ç³»ç»Ÿã€‚æ–¹æ³•é€šè¿‡ä¸ç¡®å®šæ€§å¼•å¯¼ä¸‹è‡ªé€‚åº”èåˆç´§å‡‘çš„æ„ŸçŸ¥è¾“å‡ºä¸ä¸°å¯Œçš„åŸå§‹è§‚æµ‹æ•°æ®ï¼Œå¹¶å¯¹æ¯ç±»æ¶ˆæ¯ä¼˜å…ˆé€‰æ‹©æœ€é‡è¦çš„æ•°æ®ï¼Œå®ç°äº†åœ¨ä¸åŒé€šä¿¡å¸¦å®½ä¸‹çš„æœ€ä¼˜æ„ŸçŸ¥ä¿¡æ¯äº¤æ¢ã€‚å®éªŒç»“æœæ˜¾ç¤ºHyCommåœ¨DAIR-V2Xä¸OPV2Væ•°æ®é›†ä¸Šï¼Œæ— è®ºæ¨¡å‹åŒæ„æˆ–å¼‚æ„ï¼Œéƒ½æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå®ç°äº†æ›´ä½é€šä¿¡é‡ä¸‹æ›´é«˜æ£€æµ‹æ€§èƒ½ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="23-From-Data-to-Safe-Mobile-Robot-Navigation-An-Efficient-and-Modular-Robust-MPC-Design-Pipeline"><a href="#23-From-Data-to-Safe-Mobile-Robot-Navigation-An-Efficient-and-Modular-Robust-MPC-Design-Pipeline" class="headerlink" title="23. From Data to Safe Mobile Robot Navigation: An Efficient and Modular Robust MPC Design Pipeline"></a>23. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/From_Data_to_Safe_Mobile_Robot_Navigation__An_Efficient_and_Modular_Robust_MPC_Design_Pipeline.pdf">From Data to Safe Mobile Robot Navigation: An Efficient and Modular Robust MPC Design Pipeline</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Delft University of Technology</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€å¥—é«˜æ•ˆä¸”æ¨¡å—åŒ–çš„é²æ£’æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆMPCï¼‰è®¾è®¡æµç¨‹ï¼Œé’ˆå¯¹ç§»åŠ¨æœºå™¨äººå¯¼èˆªä¸­çš„å®‰å…¨æ€§é—®é¢˜ï¼Œç³»ç»Ÿæ€§åœ°ä»å®éªŒæ•°æ®å‡ºå‘ï¼Œé€šè¿‡è¿­ä»£å¼ç§»åŠ¨åœ°å¹³çº¿ä¼°è®¡ç®—æ³•å®šé‡ä¸ç¡®å®šæ€§ï¼Œå¹¶ç»“åˆè¾“å‡ºåé¦ˆé²æ£’MPCæ–¹æ¡ˆå®ç°ç¢°æ’è§„é¿å’Œçº¦æŸå¯è¡Œæ€§ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æµç¨‹åœ¨å­˜åœ¨æ‰°åŠ¨å’Œæµ‹é‡å™ªå£°çš„æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿåœ¨æ— äººæœºä»¿çœŸç¯å¢ƒä¸­ä¿è¯é²æ£’çº¦æŸæ»¡è¶³å’Œé€’å½’å¯è¡Œæ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="24-ForeSight-Multi-View-Streaming-Joint-Object-Detection-and-Trajectory-Forecasting"><a href="#24-ForeSight-Multi-View-Streaming-Joint-Object-Detection-and-Trajectory-Forecasting" class="headerlink" title="24. ForeSight: Multi-View Streaming Joint Object Detection and Trajectory Forecasting"></a>24. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/ForeSight__Multi-View_Streaming_Joint_Object_Detection_and_Trajectory_Forecasting.pdf">ForeSight: Multi-View Streaming Joint Object Detection and Trajectory Forecasting</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Toronto</span></p>
<p>æœ¬æ–‡æå‡ºäº†ForeSightï¼Œä¸€ç§é¢å‘è‡ªåŠ¨é©¾é©¶åœºæ™¯çš„å¤šè§†è§’æµå¼è”åˆæ£€æµ‹ä¸è½¨è¿¹é¢„æµ‹æ¡†æ¶ã€‚æ–¹æ³•åˆ›æ–°æ€§åœ°é€šè¿‡ç»Ÿä¸€çš„Transformeræ¶æ„å’ŒåŒå‘æŸ¥è¯¢è®°å¿†ï¼Œæ‰“ç ´ä¼ ç»Ÿæ£€æµ‹å’Œé¢„æµ‹ä¸²è¡Œå¤„ç†çš„å£å’ï¼Œä½¿æ£€æµ‹ä¸é¢„æµ‹ä»»åŠ¡åœ¨æ—¶åºä¸Šå®ç°ä¿¡æ¯å…±äº«å’Œé—­ç¯åé¦ˆï¼Œæ”¯æŒæ— è·Ÿè¸ªå…³è”çš„ç«¯åˆ°ç«¯æ¨ç†ã€‚å®éªŒè¯æ˜ï¼ŒForeSightåœ¨nuScenesæ•°æ®é›†ä¸Šå®ç°äº†æ£€æµ‹å’Œé¢„æµ‹çš„åŒSOTAæ€§èƒ½ï¼ŒmAPä¸EPAæŒ‡æ ‡å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†å¤æ‚åœºæ™¯ä¸‹æ„ŸçŸ¥çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="25-Model-Predictive-Control-for-Crowd-Navigation-via-Learning-Based-Trajectory-Prediction"><a href="#25-Model-Predictive-Control-for-Crowd-Navigation-via-Learning-Based-Trajectory-Prediction" class="headerlink" title="25. Model Predictive Control for Crowd Navigation via Learning-Based Trajectory Prediction"></a>25. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Model_Predictive_Control_for_Crowd_Navigation_via_Learning-Based_Trajectory_Prediction.pdf">Model Predictive Control for Crowd Navigation via Learning-Based Trajectory Prediction</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Bauhaus-Universitat Weimar</span></p>
<p>è¯¥è®ºæ–‡æå‡ºå°†æ·±åº¦å­¦ä¹ é©±åŠ¨çš„Social-Implicit(SI)è¡Œäººè½¨è¿¹é¢„æµ‹æ¨¡å‹é›†æˆè¿›æ¨¡å‹é¢„æµ‹æ§åˆ¶(MPC)æ¡†æ¶ï¼Œå¹¶åœ¨å®ä½“æœºå™¨äººä¸Šè¿›è¡Œäº†éªŒè¯ã€‚å®éªŒæ˜¾ç¤ºï¼Œåœ¨ä¸åŒäººç¾¤å¯†åº¦ä¸‹ï¼ŒSI-MPCç³»ç»Ÿæ˜¾è‘—æå‡äº†é¢„æµ‹å‡†ç¡®æ€§å’Œæœºå™¨äººå¯¼èˆªçš„å®‰å…¨æ€§ä¸å¹³æ»‘æ€§ï¼Œå°¤å…¶åœ¨ä½å¯†åº¦åœºæ™¯ä¸‹é¢„æµ‹è¯¯å·®å‡å°‘é«˜è¾¾76%ã€‚ç»“è®ºè¡¨æ˜ï¼Œå­¦ä¹ å‹é¢„æµ‹å™¨åœ¨çœŸå®åŠ¨æ€ç¯å¢ƒä¸­èƒ½æå‡å®‰å…¨å’Œç¤¾äº¤é€‚åº”æ€§ï¼Œä½†å®é™…éƒ¨ç½²éœ€å…³æ³¨ç³»ç»Ÿçº§è¯„ä¼°ä¸æ•ˆç‡-ä¿å®ˆæ€§æƒè¡¡ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="26-P3-Toward-Versatile-Embodied-Agents"><a href="#26-P3-Toward-Versatile-Embodied-Agents" class="headerlink" title="26. P3: Toward Versatile Embodied Agents"></a>26. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/$_mathcal%7BP%7D%5E3$__Toward_Versatile_Embodied_Agents.pdf">P3: Toward Versatile Embodied Agents</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Southern University of Science and Technology</span></p>
<p>æœ¬æ–‡æå‡ºäº†P3æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥ç»Ÿä¸€çš„æ„ŸçŸ¥æ¨¡å—ä¸»åŠ¨æ„ŸçŸ¥ç¯å¢ƒå˜åŒ–ã€æ¶ˆé™¤å¯¹å·¥å…·åé¦ˆçš„ä¾èµ–ï¼Œå®ç°ä»»æ„å·¥å…·å³æ’å³ç”¨ï¼Œå¹¶ç»“åˆåŠ¨æ€å¤šä»»åŠ¡è°ƒåº¦å™¨ï¼Œå®ç°ä»»åŠ¡çš„æ™ºèƒ½è§„åˆ’ã€ä¼˜å…ˆçº§æ’åºä¸æ‰§è¡Œã€‚å¤§é‡çœŸå®ç¯å¢ƒå®éªŒè¡¨æ˜ï¼ŒP3æå¤§æå‡äº†æœºå™¨äººå¯¹å¤æ‚åŠ¨æ€ç¯å¢ƒçš„é€‚åº”æ€§å’Œé€šç”¨æ€§ï¼Œç¼©å°äº†åŸºå‡†ä¸å®é™…éƒ¨ç½²çš„å·®è·ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="27-Neural-Channel-Knowledge-Map-Assisted-Scheduling-Optimization-of-Active-IRSs-in-Multi-User-Systems"><a href="#27-Neural-Channel-Knowledge-Map-Assisted-Scheduling-Optimization-of-Active-IRSs-in-Multi-User-Systems" class="headerlink" title="27. Neural Channel Knowledge Map Assisted Scheduling Optimization of Active IRSs in Multi-User Systems"></a>27. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Neural_Channel_Knowledge_Map_Assisted_Scheduling_Optimization_of_Active_IRSs_in_Multi-User_Systems.pdf">Neural Channel Knowledge Map Assisted Scheduling Optimization of Active IRSs in Multi-User Systems</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Xiamen University</span></p>
<p>æœ¬è®ºæ–‡æå‡ºä¸€ç§åŸºäºç¥ç»ä¿¡é“çŸ¥è¯†å›¾ï¼ˆCKMï¼‰çš„å¤šç”¨æˆ·ä¸»åŠ¨æ™ºèƒ½åå°„è¡¨é¢ï¼ˆAIRSï¼‰è°ƒåº¦ä¼˜åŒ–æ¡†æ¶ï¼Œé€šè¿‡è®¾è®¡Transformeræ·±åº¦ç¥ç»ç½‘ç»œï¼ˆLPS-Netå’ŒSE-Netï¼‰å®ç°å†å²ä¿¡é“ä¸ååé‡æ•°æ®çš„é«˜æ•ˆé¢„æµ‹ï¼Œå¹¶ä»¥æ­¤è¾…åŠ©æ—¶é¢‘èµ„æºä¸AIRSåˆ†é…ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†é¢„æµ‹ç²¾åº¦å’Œè®¡ç®—æ•ˆç‡ï¼ŒSM-IBç®—æ³•åœ¨å¤æ‚æ€§è¾ƒä½çš„æƒ…å†µä¸‹è¾¾åˆ°äº†è¿‘ä¼¼æœ€ä¼˜çš„æœ€å¤§æœ€å°ååé‡ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="28-EGS-SLAM-RGB-D-Gaussian-Splatting-SLAM-with-Events"><a href="#28-EGS-SLAM-RGB-D-Gaussian-Splatting-SLAM-with-Events" class="headerlink" title="28. EGS-SLAM: RGB-D Gaussian Splatting SLAM with Events"></a>28. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/EGS-SLAM__RGB-D_Gaussian_Splatting_SLAM_with_Events.pdf">EGS-SLAM: RGB-D Gaussian Splatting SLAM with Events</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Nanyang Technological University</span></p>
<p>æœ¬æ–‡æå‡ºäº†EGS-SLAMï¼Œä¸€ç§èåˆäº‹ä»¶ç›¸æœºæ•°æ®ã€RGBå›¾åƒå’Œæ·±åº¦ä¿¡æ¯çš„3D Gaussian Splatting SLAMç³»ç»Ÿï¼Œæ˜¾å¼å»ºæ¨¡æ›å…‰æœŸé—´çš„è¿ç»­ç›¸æœºè½¨è¿¹ï¼Œå¹¶å¼•å…¥å¯å­¦ä¹ çš„ç›¸æœºå“åº”å‡½æ•°ï¼ˆCRFï¼‰ä¸no-event lossï¼Œå®ç°äº‹ä»¶-å›¾åƒ-æ·±åº¦çš„è”åˆè·Ÿè¸ªå’Œé«˜ä¿çœŸä¸‰ç»´é‡å»ºã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æœ‰ä¸¥é‡è¿åŠ¨æ¨¡ç³Šæ—¶ï¼Œç›¸è¾ƒäºç°æœ‰GS-SLAMæ–¹æ¡ˆåœ¨å®šä½å’Œé‡å»ºè´¨é‡ä¸Šå‡æœ‰æ˜¾è‘—æå‡ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="29-ĞœĞ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ‚Ğ¾Ñ€-Ğ´Ğ»Ñ-Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ¸-Ğ»ÑĞ´ÑĞ¼-Ñ-Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸-Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑĞ¼Ğ¸"><a href="#29-ĞœĞ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ‚Ğ¾Ñ€-Ğ´Ğ»Ñ-Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ¸-Ğ»ÑĞ´ÑĞ¼-Ñ-Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸-Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑĞ¼Ğ¸" class="headerlink" title="29. ĞœĞ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ‚Ğ¾Ñ€ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ¸ Ğ»ÑĞ´ÑĞ¼ Ñ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑĞ¼Ğ¸"></a>29. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Manipulator_for_people_with_limited_abilities.pdf">ĞœĞ°Ğ½Ğ¸Ğ¿ÑƒĞ»ÑÑ‚Ğ¾Ñ€ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ¸ Ğ»ÑĞ´ÑĞ¼ Ñ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑĞ¼Ğ¸</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">ĞœĞ¾ÑĞºĞ¾Ğ²ÑĞºĞ¸Ğ¹ Ğ³Ğ¾ÑÑƒĞ´Ğ°Ñ€ÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ¸Ñ‚ĞµÑ‚ Ğ¸Ğ¼ĞµĞ½Ğ¸ Ğ.Ğ­. Ğ‘Ğ°ÑƒĞ¼Ğ°Ğ½Ğ°</span></p>
<p>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§é¢å‘è¡ŒåŠ¨ä¸ä¾¿äººå£«çš„æœºå™¨äººè¾…åŠ©å–‚é£Ÿç³»ç»ŸRoboBKï¼ŒåŒ…æ‹¬æœºæ¢°ç»“æ„è®¾è®¡ã€åŠ¨åŠ›ä¸èƒ½è€—åˆ†æã€å››è‡ªç”±åº¦è¿åŠ¨å­¦å»ºæ¨¡ã€åŸºäºè§†è§‰çš„ç›®æ ‡æ£€æµ‹ã€ROSå¹³å°ä¸‹çš„æ§åˆ¶ä¸è¿åŠ¨è§„åˆ’ã€ä»¥åŠè½¯ç¡¬ä»¶ä¸€ä½“åŒ–å®ç°ã€‚é€šè¿‡é›†æˆ3Då»ºæ¨¡ã€åŠ¨åŠ›å­¦ä»¿çœŸã€é—­ç¯æ§åˆ¶å’ŒåŸºäºæ‘„åƒå¤´çš„äººè„¸ï¼ˆé¼»éƒ¨ï¼‰è¯†åˆ«ï¼Œæœ€ç»ˆå®Œæˆäº†ä½æˆæœ¬åŸå‹å¼€å‘ä¸å¤šæ¨¡å¼å®é™…æµ‹è¯•ï¼ŒéªŒè¯äº†ç³»ç»Ÿçš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="30-From-Imitation-to-Optimization-A-Comparative-Study-of-Offline-Learning-for-Autonomous-Driving"><a href="#30-From-Imitation-to-Optimization-A-Comparative-Study-of-Offline-Learning-for-Autonomous-Driving" class="headerlink" title="30. From Imitation to Optimization: A Comparative Study of Offline Learning for Autonomous Driving"></a>30. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/From_Imitation_to_Optimization__A_Comparative_Study_of_Offline_Learning_for_Autonomous_Driving.pdf">From Imitation to Optimization: A Comparative Study of Offline Learning for Autonomous Driving</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Independent Researcher</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªå®Œæ•´çš„è‡ªåŠ¨é©¾é©¶ç¦»çº¿å­¦ä¹ æµç¨‹ï¼Œç³»ç»Ÿæ¯”è¾ƒäº†è¡Œä¸ºå…‹éš†ï¼ˆBCï¼‰å’Œä¿å®ˆQå­¦ä¹ ï¼ˆCQLï¼‰åœ¨Waymo Open Motion Datasetä¸Šçš„è¡¨ç°ã€‚é€šè¿‡æ„å»ºç»“æ„åŒ–çŠ¶æ€è¡¨ç¤ºå’ŒTransformeræ¶æ„ï¼Œä½œè€…å‘ç°BCæ–¹æ³•åœ¨é•¿æ—¶åºä»»åŠ¡ä¸­æ˜“å †ç§¯è¯¯å·®ï¼Œè€Œé‡‡ç”¨CQLçš„ç¦»çº¿å¼ºåŒ–å­¦ä¹ èƒ½å¤Ÿæ˜¾è‘—æå‡ç­–ç•¥çš„é²æ£’æ€§å’ŒæˆåŠŸç‡ã€‚ç»“è®ºè¡¨æ˜ï¼Œç¦»çº¿å¼ºåŒ–å­¦ä¹ æ–¹æ³•å¯¹äºä»é™æ€ä¸“å®¶æ•°æ®ä¸­å­¦ä¹ é«˜é²æ£’æ€§çš„è‡ªåŠ¨é©¾é©¶ç­–ç•¥è‡³å…³é‡è¦ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="31-Imaginative-World-Modeling-with-Scene-Graphs-for-Embodied-Agent-Navigation"><a href="#31-Imaginative-World-Modeling-with-Scene-Graphs-for-Embodied-Agent-Navigation" class="headerlink" title="31. Imaginative World Modeling with Scene Graphs for Embodied Agent Navigation"></a>31. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Imaginative_World_Modeling_with_Scene_Graphs_for_Embodied_Agent_Navigation.pdf">Imaginative World Modeling with Scene Graphs for Embodied Agent Navigation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Michigan, Ann Arbor</span></p>
<p>æœ¬æ–‡æå‡ºSGImagineNavï¼Œä¸€ä¸ªåŸºäºç¬¦å·ä¸–ç•Œå»ºæ¨¡çš„ä¸»åŠ¨å¯¼èˆªæ¡†æ¶ï¼Œé€šè¿‡æ„å»ºåˆ†å±‚åœºæ™¯å›¾å¹¶åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹å¯¹æœªçŸ¥åŒºåŸŸè¿›è¡Œè¯­ä¹‰æ¨ç†ï¼Œå®ç°ç¯å¢ƒçš„å…¨å±€ç»“æ„åŒ–è¡¨ç¤ºã€‚ç³»ç»Ÿåœ¨ä»¿çœŸå’ŒçœŸå®åœºæ™¯ä¸‹å‡æ˜¾è‘—æå‡äº†ç›®æ ‡å®šä½æ•ˆç‡ï¼Œè·¨æ¥¼å±‚å’Œè·¨æˆ¿é—´å¯¼èˆªæˆåŠŸç‡åˆ†åˆ«è¾¾65.4%å’Œ66.8%ï¼Œå±•ç¤ºäº†å…¶æ³›åŒ–æ€§å’Œå®ç”¨ä»·å€¼ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="32-PANAMA-A-Network-Aware-MARL-Framework-for-Multi-Agent-Path-Finding-in-Digital-Twin-Ecosystems"><a href="#32-PANAMA-A-Network-Aware-MARL-Framework-for-Multi-Agent-Path-Finding-in-Digital-Twin-Ecosystems" class="headerlink" title="32. PANAMA: A Network-Aware MARL Framework for Multi-Agent Path Finding in Digital Twin Ecosystems"></a>32. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/PANAMA__A_Network-Aware_MARL_Framework_for_Multi-Agent_Path_Finding_in_Digital_Twin_Ecosystems.pdf">PANAMA: A Network-Aware MARL Framework for Multi-Agent Path Finding in Digital Twin Ecosystems</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Huawei Canada Advanced Research Center</span></p>
<p>æœ¬æ–‡æå‡ºäº†PANAMAç®—æ³•ï¼Œä¸€ç§åŸºäºä¼˜å…ˆçº§éå¯¹ç§°æ€§çš„ç½‘ç»œæ„ŸçŸ¥å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰æ¡†æ¶ï¼Œç”¨äºæ•°å­—å­ªç”Ÿç”Ÿæ€ç³»ç»Ÿä¸­çš„å¤šæ™ºèƒ½ä½“è·¯å¾„è§„åˆ’ã€‚è¯¥æ–¹æ³•ç»“åˆCentralized Training with Decentralized Executionï¼ˆCTDEï¼‰ã€å¼‚æ­¥actor-learnerç»“æ„å’Œä¼˜å…ˆç»éªŒå›æ”¾ï¼Œå¹¶å¼•å…¥åŠ¨æ€ä¼˜å…ˆçº§å’Œç½‘ç»œä¿¡å·è´¨é‡æ„ŸçŸ¥ï¼Œæå¤§æå‡äº†å¤šæ™ºèƒ½ä½“åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„åä½œä¸è·¯å¾„æ•ˆç‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPANAMAåœ¨å‡†ç¡®ç‡ã€é€Ÿåº¦å’Œå¯æ‰©å±•æ€§æ–¹é¢ä¼˜äºç°æœ‰åŸºçº¿ï¼Œå°¤å…¶åœ¨æ‹¥æŒ¤å’Œé€šä¿¡å—é™åœºæ™¯ä¸‹è¡¨ç°çªå‡ºï¼Œè¯æ˜äº†ç½‘ç»œæ„ŸçŸ¥å¯¹äºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿé«˜æ•ˆåä½œå’Œé²æ£’æ€§çš„å…³é”®ä½œç”¨ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="33-Energy-Efficient-Task-Offloading-in-UAV-Enabled-MEC-Using-a-Fully-Decentralized-Deep-Reinforcement-Learning-Approach"><a href="#33-Energy-Efficient-Task-Offloading-in-UAV-Enabled-MEC-Using-a-Fully-Decentralized-Deep-Reinforcement-Learning-Approach" class="headerlink" title="33. Energy Efficient Task Offloading in UAV-Enabled MEC Using a Fully Decentralized Deep Reinforcement Learning Approach"></a>33. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Energy_Efficient_Task_Offloading_in_UAV-Enabled_MEC_Using_a_Fully_Decentralized_Deep_Reinforcement_L.pdf">Energy Efficient Task Offloading in UAV-Enabled MEC Using a Fully Decentralized Deep Reinforcement Learning Approach</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Iran University of Science and Technology</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§ç”¨äºæ— äººæœºï¼ˆUAVï¼‰æ”¯æŒçš„å¤šæ¥å…¥è¾¹ç¼˜è®¡ç®—ï¼ˆMECï¼‰ç³»ç»Ÿçš„å…¨åˆ†å¸ƒå¼æ·±åº¦å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡ç»“åˆå›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆGATï¼‰ä¸ç»éªŒå’Œå‚æ•°å…±äº«çš„PPOï¼ˆEPS-PPOï¼‰ï¼Œå®ç°æ— äººæœºä»»åŠ¡å¸è½½å’Œè½¨è¿¹ä¼˜åŒ–ï¼Œå„æ— äººæœºä»…ä¸é‚»å±…é€šä¿¡ï¼Œæ— éœ€ä¸­å¿ƒèŠ‚ç‚¹ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨èƒ½è€—ã€ä»»åŠ¡å¤„ç†æ•°ã€æ”¶æ•›é€Ÿåº¦å’Œé²æ£’æ€§ç­‰æ–¹é¢å‡ä¼˜äºåŠä¸­å¿ƒåŒ–çš„MADDPGæ–¹æ³•ï¼Œé€‚ç”¨äºåŠ¨æ€MECç¯å¢ƒã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="34-D3P-Dynamic-Denoising-Diffusion-Policy-via-Reinforcement-Learning"><a href="#34-D3P-Dynamic-Denoising-Diffusion-Policy-via-Reinforcement-Learning" class="headerlink" title="34. D3P: Dynamic Denoising Diffusion Policy via Reinforcement Learning"></a>34. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/D3P__Dynamic_Denoising_Diffusion_Policy_via_Reinforcement_Learning.pdf">D3P: Dynamic Denoising Diffusion Policy via Reinforcement Learning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Tsinghua University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºDynamic Denoising Diffusion Policy (D3P)çš„æ–¹æ³•ï¼Œåœ¨æœºå™¨äººè§†è§‰æ“ä½œä»»åŠ¡ä¸­ï¼Œæ ¹æ®åŠ¨ä½œå…³é”®æ€§åŠ¨æ€åˆ†é…æ‰©æ•£å»å™ªæ­¥éª¤ã€‚D3PåŒ…å«åŸºç¡€æ‰©æ•£ç­–ç•¥å’Œè½»é‡çº§é€‚é…å™¨ï¼Œå¹¶é€šè¿‡å¼ºåŒ–å­¦ä¹ è”åˆä¼˜åŒ–ï¼Œä¸‰é˜¶æ®µè®­ç»ƒç­–ç•¥ä¿è¯æ”¶æ•›ç¨³å®šã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒD3Påœ¨å…«é¡¹ä»¿çœŸä»»åŠ¡å’Œå®é™…æœºå™¨äººéƒ¨ç½²ä¸­ï¼Œæ¨ç†é€Ÿåº¦è¾ƒä¼ ç»Ÿæ–¹æ³•å¹³å‡åŠ é€Ÿ2.2å€ä¸”ä»»åŠ¡æˆåŠŸç‡æ— æ˜¾è‘—ä¸‹é™ï¼ŒéªŒè¯äº†è‡ªé€‚åº”æ¨ç†çš„æ•ˆç‡å’Œå®ç”¨æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="35-Learning-a-Vision-Based-Footstep-Planner-for-Hierarchical-Walking-Control"><a href="#35-Learning-a-Vision-Based-Footstep-Planner-for-Hierarchical-Walking-Control" class="headerlink" title="35. Learning a Vision-Based Footstep Planner for Hierarchical Walking Control"></a>35. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Learning_a_Vision-Based_Footstep_Planner_for_Hierarchical_Walking_Control.pdf">Learning a Vision-Based Footstep Planner for Hierarchical Walking Control</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Pennsylvania</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè§†è§‰çš„åˆ†å±‚æ§åˆ¶æ¡†æ¶ï¼Œç”¨äºåŒè¶³æœºå™¨äººæ­¥æ€è§„åˆ’ã€‚æ–¹æ³•é€šè¿‡å•ç›®æ·±åº¦æ‘„åƒå¤´å’Œå±€éƒ¨é«˜ç¨‹å›¾ï¼Œç»“åˆå¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„é«˜å±‚æ­¥æ€è§„åˆ’å™¨ï¼Œä»¥åŠä½å±‚æ“ä½œç©ºé—´æ§åˆ¶å™¨ï¼Œå®ç°äº†åœ¨å¤æ‚åœ°å½¢ä¸Šçš„å®æ—¶æ­¥æ€å†³ç­–å’Œè½¨è¿¹è·Ÿè¸ªï¼Œå¹¶é‡‡ç”¨ALIPæ¨¡å‹ç®€åŒ–çŠ¶æ€ç©ºé—´ã€‚ç»“è®ºæ˜¾ç¤ºè¯¥æ¡†æ¶åœ¨ä»¿çœŸå’Œç¡¬ä»¶å®éªŒä¸­å‡è¡¨ç°å‡ºä¼˜å¼‚çš„åœ°å½¢é€‚åº”æ€§ä¸é²æ£’æ€§ï¼Œä½†åœ¨å¤æ‚åœ°å½¢å’Œå®é™…éƒ¨ç½²æ—¶ä»å—é™äºæ¨¡å‹è¡¨è¾¾èƒ½åŠ›å’Œåˆ†å±‚ç»“æ„çš„è¿ç§»éš¾é¢˜ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="36-Triple-S-A-Collaborative-Multi-LLM-Framework-for-Solving-Long-Horizon-Implicative-Tasks-in-Robotics"><a href="#36-Triple-S-A-Collaborative-Multi-LLM-Framework-for-Solving-Long-Horizon-Implicative-Tasks-in-Robotics" class="headerlink" title="36. Triple-S: A Collaborative Multi-LLM Framework for Solving Long-Horizon Implicative Tasks in Robotics"></a>36. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Triple-S__A_Collaborative_Multi-LLM_Framework_for_Solving_Long-Horizon_Implicative_Tasks_in_Robotics.pdf">Triple-S: A Collaborative Multi-LLM Framework for Solving Long-Horizon Implicative Tasks in Robotics</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Northeastern University</span></p>
<p>æœ¬æ–‡æå‡ºTriple-Sæ¡†æ¶ï¼Œé€šè¿‡å¤šå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åä½œï¼ŒåŒ…æ‹¬ä»»åŠ¡ç®€åŒ–ã€ç¤ºä¾‹æ£€ç´¢ã€é—­ç¯å†³ç­–å’ŒAPIå°è£…ï¼Œæœ‰æ•ˆæå‡æœºå™¨äººåœ¨é•¿æ—¶åºå¤æ‚ä»»åŠ¡ä¸­çš„ä»£ç ç”ŸæˆæˆåŠŸç‡å’Œé²æ£’æ€§ã€‚å®éªŒåœ¨LDIPæ•°æ®é›†å’ŒçœŸå®æœºå™¨äººä¸­éªŒè¯äº†Triple-Sæ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œä»»åŠ¡æˆåŠŸç‡æ˜¾è‘—é«˜äºç°æœ‰æ–¹æ³•ï¼Œå±•ç¤ºäº†åœ¨æŒ‡ä»¤å’Œç¯å¢ƒéšå«æ¡ä»¶ä¸‹çš„å¼ºæ³›åŒ–èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="37-Multimodal-Spiking-Neural-Network-for-Space-Robotic-Manipulation"><a href="#37-Multimodal-Spiking-Neural-Network-for-Space-Robotic-Manipulation" class="headerlink" title="37. Multimodal Spiking Neural Network for Space Robotic Manipulation"></a>37. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Multimodal_Spiking_Neural_Network_for_Space_Robotic_Manipulation.pdf">Multimodal Spiking Neural Network for Space Robotic Manipulation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Harbin Institute of Technology</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤šæ¨¡æ€è„‰å†²ç¥ç»ç½‘ç»œï¼ˆSNNï¼‰çš„ç©ºé—´æœºå™¨äººè‡‚æ§åˆ¶æ¡†æ¶ï¼Œç»“åˆå‡ ä½•çŠ¶æ€ã€è§¦è§‰ã€è¯­ä¹‰ä¿¡æ¯æå‡ç¯å¢ƒæ„ŸçŸ¥ï¼Œå¹¶ä»¥åŒé€šé“ä¸‰é˜¶æ®µè¯¾ç¨‹å¼ºåŒ–å­¦ä¹ ï¼ˆCRLï¼‰åˆ†é˜¶æ®µå¼•å¯¼ç­–ç•¥è®­ç»ƒï¼Œå®ç°èƒ½æ•ˆé«˜ã€è‡ªä¸»æ“ä½œçš„ç©ºé—´ææ–™æ¬è¿ä¸æ“æ§ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä»»åŠ¡æˆåŠŸç‡ä¸èƒ½è€—æ–¹é¢å‡ä¼˜äºä¼ ç»Ÿäººå·¥ç¥ç»ç½‘ç»œï¼ˆANNï¼‰åŸºçº¿ï¼Œé€‚ç”¨äºèµ„æºå—é™çš„çœŸå®èˆªå¤©åœºæ™¯ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="38-MonoMPC-Monocular-Vision-Based-Navigation-with-Learned-Collision-Model-and-Risk-Aware-Model-Predictive-Control"><a href="#38-MonoMPC-Monocular-Vision-Based-Navigation-with-Learned-Collision-Model-and-Risk-Aware-Model-Predictive-Control" class="headerlink" title="38. MonoMPC: Monocular Vision Based Navigation with Learned Collision Model and Risk-Aware Model Predictive Control"></a>38. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/MonoMPC__Monocular_Vision_Based_Navigation_with_Learned_Collision_Model_and_Risk-Aware_Model_Predict.pdf">MonoMPC: Monocular Vision Based Navigation with Learned Collision Model and Risk-Aware Model Predictive Control</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Tartu</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºå•ç›®è§†è§‰çš„æœºå™¨äººå¯¼èˆªæ–¹æ³•ï¼Œé€šè¿‡å°†å™ªå£°è¾ƒå¤§çš„ä¼°è®¡æ·±åº¦ä½œä¸ºè¾“å…¥ï¼Œè”åˆå­¦ä¹ æ¦‚ç‡åŒ–ç¢°æ’æ¨¡å‹å’Œé£é™©åº¦é‡ï¼Œå¹¶å°†å…¶é›†æˆåˆ°é£é™©æ„ŸçŸ¥MPCè§„åˆ’å™¨ä¸­ã€‚æ–¹æ³•åˆ©ç”¨PointNet++æå–ç‚¹äº‘ç‰¹å¾ï¼Œè”åˆæ§åˆ¶åºåˆ—ï¼Œé€šè¿‡ç¥ç»ç½‘ç»œè¾“å‡ºè½¨è¿¹æœ€å°éšœç¢ç‰©é—´éš™åˆ†å¸ƒï¼Œè”åˆä¸‹æ¸¸é£é™©ç›‘ç£ä¼˜åŒ–æ¨¡å‹ä¸ç¡®å®šæ€§ï¼Œå®ç°å®‰å…¨é«˜æ•ˆå¯¼èˆªã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤æ‚ç¯å¢ƒä¸‹æˆåŠŸç‡æ˜¾è‘—é«˜äºROSå¯¼èˆªå’ŒNoMaDï¼Œå¹¶èƒ½æœ‰æ•ˆè§„é¿ç¢°æ’ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="39-A-Hybrid-Force-Position-Strategy-for-Shape-Control-of-Deformable-Linear-Objects-With-Graph-Attention-Networks"><a href="#39-A-Hybrid-Force-Position-Strategy-for-Shape-Control-of-Deformable-Linear-Objects-With-Graph-Attention-Networks" class="headerlink" title="39. A Hybrid Force-Position Strategy for Shape Control of Deformable Linear Objects With Graph Attention Networks"></a>39. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/A_Hybrid_Force-Position_Strategy_for_Shape_Control_of_Deformable_Linear_Objects_With_Graph_Attention.pdf">A Hybrid Force-Position Strategy for Shape Control of Deformable Linear Objects With Graph Attention Networks</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Tsinghua University</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§é¢å‘å¯å˜å½¢çº¿çŠ¶ç‰©ä½“ï¼ˆDLOï¼‰å½¢çŠ¶æ§åˆ¶çš„æ··åˆåŠ›-ä½æ§åˆ¶ç­–ç•¥ï¼Œèåˆäº†åŸºäºå›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆGATï¼‰çš„åŠ¨åŠ›å­¦å»ºæ¨¡åŠåŠ›-ä½åŒæ¨¡æ€çŠ¶æ€è¡¨ç¤ºã€‚è¯¥æ–¹æ³•é€šè¿‡åŠ›ç©ºé—´ä¸­çš„è½¨è¿¹è§„åˆ’ä¸ä½ç½®ç©ºé—´ä¸­çš„æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆMPCï¼‰ç›¸ç»“åˆï¼Œæœ‰æ•ˆåˆ†è§£å¤§å˜å½¢ä»»åŠ¡ï¼Œé¿å…é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚å®éªŒè¯æ˜ï¼Œè¯¥ç­–ç•¥åœ¨ä»¿çœŸå’Œç°å®åœºæ™¯ä¸‹å‡èƒ½æ˜¾è‘—æå‡DLOæ“æ§çš„æ•ˆç‡ä¸ç¨³å®šæ€§ï¼Œç¡®ä¿å½¢çŠ¶è¿‡æ¸¡å¹³æ»‘ä¸”é²æ£’ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="40-Integrating-Neurosymbolic-AI-in-Advanced-Air-Mobility-A-Comprehensive-Survey"><a href="#40-Integrating-Neurosymbolic-AI-in-Advanced-Air-Mobility-A-Comprehensive-Survey" class="headerlink" title="40. Integrating Neurosymbolic AI in Advanced Air Mobility: A Comprehensive Survey"></a>40. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Integrating_Neurosymbolic_AI_in_Advanced_Air_Mobility__A_Comprehensive_Survey.pdf">Integrating Neurosymbolic AI in Advanced Air Mobility: A Comprehensive Survey</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Maryland, Baltimore County</span></p>
<p>è¯¥è®ºæ–‡ç³»ç»Ÿç»¼è¿°äº†Neurosymbolic AIï¼ˆç»“åˆç¥ç»ç½‘ç»œå­¦ä¹ å’Œç¬¦å·æ¨ç†ï¼‰åœ¨å…ˆè¿›ç©ºä¸­ç§»åŠ¨ï¼ˆAAMï¼‰ä¸­çš„åº”ç”¨ï¼ŒåŒ…æ‹¬éœ€æ±‚é¢„æµ‹ã€é£æœºè®¾è®¡ã€è‡ªåŠ¨åŒ–ç®¡æ§ã€å®æ—¶äº¤é€šç®¡ç†ç­‰å…³é”®é¢†åŸŸï¼Œé‡ç‚¹åˆ†æäº†Neurosymbolic Reinforcement Learningç­‰æ–¹æ³•åœ¨åŠ¨æ€ä¼˜åŒ–ä¸­çš„æ½œåŠ›å’Œé¢ä¸´çš„å¯æ‰©å±•æ€§ã€ç¨³å¥æ€§åŠåˆè§„æ€§æŒ‘æˆ˜ã€‚è®ºæ–‡ç»“è®ºè®¤ä¸ºï¼ŒNeurosymbolic AIèƒ½æ˜¾è‘—æå‡AAMç³»ç»Ÿçš„é€æ˜æ€§ã€å®‰å…¨æ€§å’Œé€‚åº”æ€§ï¼Œä½†éœ€æŒç»­æ¨åŠ¨è·¨å­¦ç§‘åˆä½œä¸æ ‡å‡†åŒ–ï¼Œä»¥è§£å†³æ•°æ®èåˆã€ç½‘ç»œå®‰å…¨å’Œè®¤è¯ç­‰æ ¸å¿ƒé—®é¢˜ï¼ŒåŠ©åŠ›ä¸‹ä¸€ä»£èˆªç©ºç§»åŠ¨è§£å†³æ–¹æ¡ˆçš„è½åœ°ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="41-ODYSSEY-Open-World-Quadrupeds-Exploration-and-Manipulation-for-Long-Horizon-Tasks"><a href="#41-ODYSSEY-Open-World-Quadrupeds-Exploration-and-Manipulation-for-Long-Horizon-Tasks" class="headerlink" title="41. ODYSSEY: Open-World Quadrupeds Exploration and Manipulation for Long-Horizon Tasks"></a>41. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/ODYSSEY__Open-World_Quadrupeds_Exploration_and_Manipulation_for_Long-Horizon_Tasks.pdf">ODYSSEY: Open-World Quadrupeds Exploration and Manipulation for Long-Horizon Tasks</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Zhejiang University</span></p>
<p>ODYSSEYæå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„ç§»åŠ¨æ“æ§æ¡†æ¶ï¼Œå°†å±‚æ¬¡åŒ–çš„è§†è§‰-è¯­è¨€ä»»åŠ¡è§„åˆ’ä¸åœ°å½¢è‡ªé€‚åº”å…¨èº«æ§åˆ¶ç»“åˆï¼Œä¸“ä¸ºå…·å¤‡æœºæ¢°è‡‚çš„æ•æ·å››è¶³æœºå™¨äººè®¾è®¡ã€‚ç³»ç»Ÿé€šè¿‡è§†è§‰-è¯­è¨€æ¨¡å‹é©±åŠ¨çš„åˆ†å±‚è§„åˆ’å’Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„å…¨èº«æ§åˆ¶ç­–ç•¥ï¼Œå®ç°äº†åœ¨å¤šæ ·å¤æ‚åœ°å½¢ä¸‹çš„é•¿æœŸä»»åŠ¡åˆ†è§£ä¸ç²¾ç¡®åŠ¨ä½œæ‰§è¡Œï¼Œå¹¶é€šè¿‡ä¸°å¯Œå®¤å†…å¤–åœºæ™¯çš„ä»¿çœŸä¸å®åœ°æµ‹è¯•éªŒè¯äº†å…¶é€šç”¨æ€§å’Œé²æ£’æ€§ã€‚ç»“è®ºè¡¨æ˜è¯¥æ–¹æ³•èƒ½æ˜¾è‘—æå‡ç§»åŠ¨æœºå™¨äººåœ¨å¼€æ”¾ç¯å¢ƒä¸­çš„æ¢ç´¢ä¸æ“ä½œèƒ½åŠ›ï¼Œä¸ºé€šç”¨å‹æœºå™¨äººåŠ©æ‰‹çš„å®é™…éƒ¨ç½²å¥ å®šåŸºç¡€ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="42-BeyondMimic-From-Motion-Tracking-to-Versatile-Humanoid-Control-via-Guided-Diffusion"><a href="#42-BeyondMimic-From-Motion-Tracking-to-Versatile-Humanoid-Control-via-Guided-Diffusion" class="headerlink" title="42. BeyondMimic: From Motion Tracking to Versatile Humanoid Control via Guided Diffusion"></a>42. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/BeyondMimic__From_Motion_Tracking_to_Versatile_Humanoid_Control_via_Guided_Diffusion.pdf">BeyondMimic: From Motion Tracking to Versatile Humanoid Control via Guided Diffusion</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of California, Berkeley</span></p>
<p>æœ¬æ–‡æå‡ºäº†BeyondMimicæ¡†æ¶ï¼Œå®ç°äº†ä»äººç±»åŠ¨ä½œæ•æ‰æ•°æ®åˆ°å¤šæ ·åŒ–ä»¿äººæœºå™¨äººæ§åˆ¶çš„ç«¯åˆ°ç«¯æµç¨‹ã€‚æ–¹æ³•ä¸Šï¼Œé¦–å…ˆé€šè¿‡ç»Ÿä¸€çš„MDPå’Œè¶…å‚æ•°è®­ç»ƒé«˜è´¨é‡ã€é«˜åŠ¨æ€çš„è¿åŠ¨è·Ÿè¸ªç­–ç•¥ï¼Œå¹¶åˆ©ç”¨ç¦»çº¿çŸ¥è¯†è’¸é¦å’Œå¼•å¯¼æ‰©æ•£æ¨¡å‹ï¼Œå°†å¤šç§è¿åŠ¨æŠ€èƒ½åˆæˆä¸ºå•ä¸€ç­–ç•¥ï¼Œå®ç°é›¶æ ·æœ¬ä¸‹ä»»åŠ¡è‡ªé€‚åº”æ§åˆ¶ï¼Œæ”¯æŒå¯¼èˆªã€é¥æ§å’Œé¿éšœç­‰å¤šä»»åŠ¡ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨çœŸå®ç¡¬ä»¶ä¸Šå±•ç°å‡ºå¼ºå¥æ€§ã€æ³›åŒ–æ€§å’Œäººç±»åŠ¨ä½œé£æ ¼ï¼Œé¦–æ¬¡å®ç°äº†æå…·æŒ‘æˆ˜æ€§çš„è¿ç»­åŠ¨æ€åŠ¨ä½œçš„ä»¿äººæœºå™¨äººçœŸå®æ‰§è¡Œã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="43-Spatial-ORMLLM-Improve-Spatial-Relation-Understanding-in-the-Operating-Room-with-Multimodal-Large-Language-Model"><a href="#43-Spatial-ORMLLM-Improve-Spatial-Relation-Understanding-in-the-Operating-Room-with-Multimodal-Large-Language-Model" class="headerlink" title="43. Spatial-ORMLLM: Improve Spatial Relation Understanding in the Operating Room with Multimodal Large Language Model"></a>43. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Spatial-ORMLLM__Improve_Spatial_Relation_Understanding_in_the_Operating_Room_with_Multimodal_Large_L.pdf">Spatial-ORMLLM: Improve Spatial Relation Understanding in the Operating Room with Multimodal Large Language Model</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Hunan University</span></p>
<p>Spatial-ORMLLMæå‡ºäº†ä¸€ç§ç”¨äºæ‰‹æœ¯å®¤åœºæ™¯ä¸‹3Dç©ºé—´å…³ç³»ç†è§£çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼Œä»…ä¾é RGBå›¾åƒï¼Œé€šè¿‡3D Spatial Blockç”Ÿæˆæ·±åº¦å›¾ã€å…¨æ™¯åˆ†å‰²å’Œç‚¹äº‘ç­‰ä¼ªæ¨¡æ€ï¼Œåˆ©ç”¨ç©ºé—´å¢å¼ºç‰¹å¾èåˆå—å°†å¤šæ¨¡æ€ç‰¹å¾ç»Ÿä¸€æŠ•å½±è‡³LLMçš„tokenç©ºé—´ï¼Œå®ç°ç»†ç²’åº¦ç©ºé—´æ¨ç†å’Œåœºæ™¯å›¾ç”Ÿæˆã€‚å®éªŒæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ç©ºé—´æ¨ç†å’Œåœºæ™¯å›¾ä»»åŠ¡ä¸Šè¶…è¶Šç°æœ‰2Då’Œ3Dè§†è§‰-è¯­è¨€æ¨¡å‹ï¼ŒéªŒè¯äº†åœ¨æ¨¡æ€å—é™æ¡ä»¶ä¸‹å¯å®ç°é«˜ç²¾åº¦ç©ºé—´ç†è§£å’Œç»“æ„åŒ–åœºæ™¯å»ºæ¨¡ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="44-Vision-Based-Localization-and-LLM-based-Navigation-for-Indoor-Environments"><a href="#44-Vision-Based-Localization-and-LLM-based-Navigation-for-Indoor-Environments" class="headerlink" title="44. Vision-Based Localization and LLM-based Navigation for Indoor Environments"></a>44. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Vision-Based_Localization_and_LLM-based_Navigation_for_Indoor_Environments.pdf">Vision-Based Localization and LLM-based Navigation for Indoor Environments</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Brown University</span></p>
<p>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§èåˆè§†è§‰å®šä½ä¸å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯¼èˆªçš„å®¤å†…å¯¼èˆªç³»ç»Ÿï¼šé€šè¿‡ä¸¤é˜¶æ®µå¾®è°ƒçš„ResNet-50å·ç§¯ç¥ç»ç½‘ç»œå¯¹æ™ºèƒ½æ‰‹æœºæ‘„åƒå¤´å›¾åƒè¿›è¡Œå®šä½ï¼Œéšåç»“åˆé¢„å¤„ç†æ¥¼å±‚åœ°å›¾å’ŒChatGPTå¤§è¯­è¨€æ¨¡å‹ï¼Œç”Ÿæˆé€æ­¥å¯¼èˆªæŒ‡ä»¤ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å¤æ‚èµ°å»Šç¯å¢ƒä¸‹ï¼Œè§†è§‰å®šä½æ¨¡å—å…·å¤‡96%å‡†ç¡®ç‡ï¼ŒLLMå¯¼èˆªæ¨¡å—å¹³å‡æŒ‡ä»¤å‡†ç¡®ç‡ä¸º75%ï¼Œè¡¨æ˜è¯¥æ–¹æ³•æœ‰æœ›å®ç°èµ„æºæœ‰é™ç¯å¢ƒä¸‹çš„å¯æ‰©å±•ã€æ— åŸºç¡€è®¾æ–½å®¤å†…å¯¼èˆªï¼Œä½†å¯¼èˆªæ¨¡å—ä»å—é™äºç©ºé—´æ¨ç†èƒ½åŠ›å’Œå“åº”é€Ÿåº¦ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="45-COM-PACT-COMponent-Aware-Pruning-for-Accelerated-Control-Tasks-in-Latent-Space-Models"><a href="#45-COM-PACT-COMponent-Aware-Pruning-for-Accelerated-Control-Tasks-in-Latent-Space-Models" class="headerlink" title="45. COM-PACT: COMponent-Aware Pruning for Accelerated Control Tasks in Latent Space Models"></a>45. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/COMponent-Aware_Pruning_for_Accelerated_Control_Tasks_in_Latent_Space_Models.pdf">COM-PACT: COMponent-Aware Pruning for Accelerated Control Tasks in Latent Space Models</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">RPTU University Kaiserslautern-Landau</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºç»„ä»¶æ„ŸçŸ¥çš„ç»“æ„åŒ–å‰ªææ–¹æ³•ï¼Œé€šè¿‡ä¼˜åŒ–å„ç»„ä»¶çš„å‰ªææ¯”ä¾‹ï¼Œå®ç°ç¥ç»ç½‘ç»œæ§åˆ¶å™¨ï¼ˆNNCï¼‰åœ¨åµŒå…¥å¼ç¡¬ä»¶ä¸Šçš„é«˜æ•ˆéƒ¨ç½²ï¼Œå¹¶ä»¥Lyapunovç¨³å®šæ€§ä¸ºçº¦æŸï¼Œç¡®ä¿å‹ç¼©åæ¨¡å‹ä»èƒ½æ»¡è¶³æ§åˆ¶ç³»ç»Ÿçš„ç¨³å®šæ€§éœ€æ±‚ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨TD-MPCæ§åˆ¶ä»»åŠ¡ä¸­èƒ½æ˜¾è‘—å‡å°‘æ¨¡å‹è§„æ¨¡ï¼Œç»´æŒå…³é”®ç¨³å®šæ€§ç•Œé™ï¼Œå¹¶æ­ç¤ºä¸åŒç»„ä»¶å¯¹ç³»ç»Ÿç¨³å®šæ€§çš„æ•æ„Ÿæ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="46-AimBot-A-Simple-Auxiliary-Visual-Cue-to-Enhance-Spatial-Awareness-of-Visuomotor-Policies"><a href="#46-AimBot-A-Simple-Auxiliary-Visual-Cue-to-Enhance-Spatial-Awareness-of-Visuomotor-Policies" class="headerlink" title="46. AimBot: A Simple Auxiliary Visual Cue to Enhance Spatial Awareness of Visuomotor Policies"></a>46. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/AimBot__A_Simple_Auxiliary_Visual_Cue_to_Enhance_Spatial_Awareness_of_Visuomotor_Policies.pdf">AimBot: A Simple Auxiliary Visual Cue to Enhance Spatial Awareness of Visuomotor Policies</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Michigan</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†AimBotï¼Œä¸€ç§è½»é‡çº§è§†è§‰å¢å¼ºæ–¹æ³•ï¼Œé€šè¿‡åœ¨å¤šè§†è§’RGBå›¾åƒä¸Šå åŠ å°„çº¿å’Œå‡†æ˜Ÿï¼Œæ˜¾å¼ç¼–ç æœºæ¢°è‡‚æœ«ç«¯æ‰§è¡Œå™¨çš„ç©ºé—´çŠ¶æ€ï¼Œå¢å¼ºè§†è§‰è¿åŠ¨ç­–ç•¥åœ¨æœºå™¨äººæ“ä½œä¸­çš„ç©ºé—´æ„ŸçŸ¥ã€‚AimBotæ— éœ€æ›´æ”¹æ¨¡å‹æ¶æ„ï¼Œå‡ ä¹ä¸å¢åŠ è®¡ç®—å¼€é”€ï¼Œå®éªŒè¡¨æ˜å…¶åœ¨æ¨¡æ‹Ÿä¸çœŸå®ç¯å¢ƒä¸­å‡èƒ½æ˜¾è‘—æå‡å¤šç§è§†è§‰è¯­è¨€åŠ¨ä½œæ¨¡å‹çš„ä»»åŠ¡æˆåŠŸç‡ï¼Œå°¤å…¶åœ¨å¤æ‚é•¿æ—¶åºæ“ä½œä»»åŠ¡ä¸­æ•ˆæœçªå‡ºã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="47-Grid2Guide-A-Enabled-Small-Language-Model-for-Indoor-Navigation"><a href="#47-Grid2Guide-A-Enabled-Small-Language-Model-for-Indoor-Navigation" class="headerlink" title="47. Grid2Guide: A* Enabled Small Language Model for Indoor Navigation"></a>47. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Grid2Guide__A__Enabled_Small_Language_Model_for_Indoor_Navigation.pdf">Grid2Guide: A* Enabled Small Language Model for Indoor Navigation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">The University of Alabama</span></p>
<p>è¯¥è®ºæ–‡æå‡ºGrid2Guideï¼Œä¸€ä¸ªç»“åˆA<em>æœç´¢ç®—æ³•ä¸å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰çš„å®¤å†…å¯¼èˆªæ–¹æ³•ã€‚æµç¨‹åŒ…æ‹¬å°†æ¥¼å±‚å¹³é¢å›¾è½¬åŒ–ä¸ºäºŒå€¼å ç”¨ç½‘æ ¼ï¼Œé€šè¿‡A</em>ç®—æ³•è§„åˆ’æœ€ä¼˜è·¯å¾„ï¼Œå¹¶ç”¨SLMå°†å‹ç¼©åçš„è·¯å¾„æŒ‡ä»¤è½¬åŒ–ä¸ºè‡ªç„¶è¯­è¨€å¯¼èˆªæŒ‡ä»¤ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§å®é™…åœºæ™¯ä¸‹å®ç°äº†é«˜ç²¾åº¦ã€ä½å»¶è¿Ÿçš„å®æ—¶å¯¼èˆªï¼Œä¼˜äºçº¯LLMæ–¹æ¡ˆï¼Œé€‚åˆæ‰‹æŒè®¾å¤‡éƒ¨ç½²ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="48-PCHands-PCA-based-Hand-Pose-Synergy-Representation-on-Manipulators-with-N-DoF"><a href="#48-PCHands-PCA-based-Hand-Pose-Synergy-Representation-on-Manipulators-with-N-DoF" class="headerlink" title="48. PCHands: PCA-based Hand Pose Synergy Representation on Manipulators with N-DoF"></a>48. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/PCHands__PCA-based_Hand_Pose_Synergy_Representation_on_Manipulators_with_N-DoF.pdf">PCHands: PCA-based Hand Pose Synergy Representation on Manipulators with N-DoF</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Istituto Italiano di Tecnologia (IIT)</span></p>
<p>æœ¬æ–‡æå‡ºäº†PCHandsæ¡†æ¶ï¼Œé€šè¿‡Anchor Description Format (ADF)ã€æ¡ä»¶å˜åˆ†è‡ªç¼–ç å™¨(CVAE)å’Œä¸»æˆåˆ†åˆ†æ(PCA)ç»“åˆï¼Œç»Ÿä¸€æå–ä¸åŒæœºæ¢°æ‰‹ï¼ˆåŒ…æ‹¬äººæ‰‹ã€ç±»äººæ‰‹ã€äºŒæŒ‡å¤¹çˆªç­‰ï¼‰å§¿æ€ååŒçš„å¯å˜é•¿åº¦è¡¨å¾ã€‚PCHandsä¸ä»…æå‡äº†åŸºäºRLçš„çµå·§æ“ä½œä»»åŠ¡çš„å­¦ä¹ æ•ˆç‡å’Œä¸€è‡´æ€§ï¼Œè¿˜èƒ½åœ¨ä¸åŒæœºæ¢°æ‰‹ä¹‹é—´å®ç°é«˜æ•ˆçš„æ“ä½œç­–ç•¥å’Œæ¼”ç¤ºè¿ç§»ï¼Œå¹¶åœ¨çœŸå®æœºå™¨äººä¸Šå®ç°äº†é›¶æ ·æœ¬è¿ç§»ï¼ŒéªŒè¯äº†å…¶å®ç”¨æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="49-MolmoAct-Action-Reasoning-Models-that-can-Reason-in-Space"><a href="#49-MolmoAct-Action-Reasoning-Models-that-can-Reason-in-Space" class="headerlink" title="49. MolmoAct: Action Reasoning Models that can Reason in Space"></a>49. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/MolmoAct__Action_Reasoning_Models_that_can_Reason_in_Space.pdf">MolmoAct: Action Reasoning Models that can Reason in Space</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Allen Institute for AI</span></p>
<p>MolmoActæå‡ºäº†ä¸€ç§ç»“æ„åŒ–ä¸‰é˜¶æ®µæ¨ç†æµç¨‹çš„å¼€æ”¾å¼è¡ŒåŠ¨æ¨ç†æ¨¡å‹ï¼ˆARMï¼‰ï¼Œé›†æˆäº†æ„ŸçŸ¥ã€è§„åˆ’å’Œæ§åˆ¶ï¼šé¦–å…ˆå°†å›¾åƒå’Œè¯­è¨€æŒ‡ä»¤ç¼–ç ä¸ºæ·±åº¦æ„ŸçŸ¥Tokenï¼Œç„¶åç”Ÿæˆå¯ç¼–è¾‘çš„ç©ºé—´è½¨è¿¹è¡¨ç¤ºï¼Œæœ€åé¢„æµ‹ç²¾ç¡®çš„æœºå™¨äººåº•å±‚åŠ¨ä½œï¼Œæå‡äº†æ¨¡å‹çš„å¯è§£é‡Šæ€§å’Œå¯æ§æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒMolmoActåœ¨SimperEnvã€LIBEROç­‰ä»¿çœŸåŠçœŸå®ç¯å¢ƒä¸‹è¶…è¶Šä¸»æµåŸºçº¿ï¼Œå…·å¤‡ä¼˜å¼‚çš„é›¶æ ·æœ¬æ³›åŒ–ã€å¿«é€Ÿé€‚åº”å’Œç©ºé—´æ¨ç†èƒ½åŠ›ï¼Œå¹¶é€šè¿‡å‘å¸ƒå…¨å¥—æ¨¡å‹æƒé‡ä¸æ•°æ®é›†æ¨åŠ¨ç¤¾åŒºå‘å±•ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="50-DETACH-Cross-domain-Learning-for-Long-Horizon-Tasks-via-Mixture-of-Disentangled-Experts"><a href="#50-DETACH-Cross-domain-Learning-for-Long-Horizon-Tasks-via-Mixture-of-Disentangled-Experts" class="headerlink" title="50. DETACH: Cross-domain Learning for Long-Horizon Tasks via Mixture of Disentangled Experts"></a>50. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/DETACH__Cross-domain_Learning_for_Long-Horizon_Tasks_via_Mixture_of_Disentangled_Experts.pdf">DETACH: Cross-domain Learning for Long-Horizon Tasks via Mixture of Disentangled Experts</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Beijing University of Technology</span></p>
<p>è¯¥è®ºæ–‡æå‡ºDETACHæ¡†æ¶ï¼Œé€šè¿‡å—ç”Ÿç‰©å¯å‘çš„åŒæµæ¨¡å—ï¼ˆç¯å¢ƒç¼–ç å™¨å’Œè‡ªæˆ‘ç¼–ç å™¨ï¼‰å®ç°ç¯å¢ƒæ„ŸçŸ¥ä¸è‡ªæˆ‘çŠ¶æ€çš„åŠŸèƒ½è§£è€¦ï¼Œç»“åˆå¤šç­–ç•¥è‡ªé€‚åº”ç‰¹å¾èåˆæœºåˆ¶ï¼Œæ˜¾è‘—æå‡è·¨åŸŸæ³›åŒ–å’ŒæŠ€èƒ½å¤ç”¨èƒ½åŠ›ã€‚å®éªŒåœ¨å¤šä¸ªäºº-åœºæ™¯äº¤äº’é•¿æ—¶åºä»»åŠ¡ä¸­éªŒè¯ï¼ŒDETACHåœ¨ä»»åŠ¡æˆåŠŸç‡å’Œæ‰§è¡Œæ•ˆç‡ä¸Šå‡è¶…è¿‡ç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨è·¨ç¯å¢ƒå’Œå¤šæŠ€èƒ½ç»„åˆåœºæ™¯ä¸‹è¡¨ç°ä¼˜å¼‚ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="51-Touch-Speaks-Sound-Feels-A-Multimodal-Approach-to-Affective-and-Social-Touch-from-Robots-to-Humans"><a href="#51-Touch-Speaks-Sound-Feels-A-Multimodal-Approach-to-Affective-and-Social-Touch-from-Robots-to-Humans" class="headerlink" title="51. Touch Speaks, Sound Feels: A Multimodal Approach to Affective and Social Touch from Robots to Humans"></a>51. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Touch_Speaks,_Sound_Feels__A_Multimodal_Approach_to_Affective_and_Social_Touch_from_Robots_to_Humans.pdf">Touch Speaks, Sound Feels: A Multimodal Approach to Affective and Social Touch from Robots to Humans</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Ghent University</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æœºå™¨äººå¯¹äººç±»çš„å¤šæ¨¡æ€æƒ…æ„Ÿä¸ç¤¾äº¤è§¦è§‰äº¤äº’ç³»ç»Ÿï¼Œç»“åˆ25ç‚¹é˜µéœ‡åŠ¨é©¬è¾¾å’ŒéŸ³é¢‘åŒæ­¥åé¦ˆï¼Œå®ç°è§¦è§‰ä¸å¬è§‰ä¿¡æ¯çš„èåˆï¼›é€šè¿‡å®éªŒè®©32åä¸­å›½å‚ä¸è€…è§£ç ç”±æœºå™¨äººä¼ é€’çš„10ç§æƒ…æ„Ÿå’Œ6ç§ç¤¾äº¤æ‰‹åŠ¿ï¼Œåˆ†åˆ«åœ¨å•ä¸€è§¦è§‰ã€å•ä¸€å¬è§‰åŠä¸¤è€…ç»“åˆä¸‹è¿›è¡Œè¯†åˆ«ã€‚ç»“æœæ˜¾ç¤ºï¼Œè§¦è§‰ä¸å¬è§‰ç»“åˆæ–¹å¼æ˜¾è‘—æå‡äº†æƒ…æ„Ÿè¯†åˆ«çš„å‡†ç¡®æ€§ï¼Œå•ä¸€é€šé“å„æœ‰ä¼˜åŠ¿ä½†éš¾ä»¥åŒºåˆ†éƒ¨åˆ†ä½å”¤é†’æˆ–ç›¸è¿‘æƒ…æ„Ÿï¼Œæ‰‹åŠ¿è¯†åˆ«æ€»ä½“ä¼˜äºæƒ…æ„Ÿè¯†åˆ«ã€‚ç ”ç©¶å¼ºè°ƒå¤šæ„Ÿå®˜èåˆå¯¹äºæå‡äººæœºæƒ…æ„Ÿäº¤äº’çš„å¿…è¦æ€§ï¼Œå¹¶ä¸ºç¤¾äº¤å‹æœºå™¨äººè®¾è®¡æä¾›äº†ä¾æ®ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="52-AgentWorld-An-Interactive-Simulation-Platform-for-Scene-Construction-and-Mobile-Robotic-Manipulation"><a href="#52-AgentWorld-An-Interactive-Simulation-Platform-for-Scene-Construction-and-Mobile-Robotic-Manipulation" class="headerlink" title="52. AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation"></a>52. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/AgentWorld__An_Interactive_Simulation_Platform_for_Scene_Construction_and_Mobile_Robotic_Manipulatio.pdf">AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Tencent Robotics X</span></p>
<p>è¯¥è®ºæ–‡æå‡ºAgentWorldï¼Œä¸€ä¸ªé›†æˆç¨‹åºåŒ–åœºæ™¯æ„å»ºå’Œç§»åŠ¨æœºå™¨äººæ“ä½œçš„æ•°æ®æ”¶é›†ä»¿çœŸå¹³å°ï¼ŒåŒ…å«é«˜ä¿çœŸ3Dèµ„äº§åº“ã€ç‰©ç†å±æ€§ä»¿çœŸã€ç§»åŠ¨å’ŒåŒè‡‚&#x2F;çµå·§æ‰‹è¿œç¨‹æ§åˆ¶ç³»ç»Ÿã€‚é€šè¿‡æ­å»ºå¤šæ ·å®¶åº­ç¯å¢ƒä¸æ”¶é›†å¤šé˜¶æ®µæ“ä½œè½¨è¿¹ï¼Œå¹¶åœ¨æ¨¡ä»¿å­¦ä¹ ç®—æ³•ï¼ˆå¦‚è¡Œä¸ºå…‹éš†ã€ACTã€æ‰©æ•£ç­–ç•¥ã€è§†è§‰è¯­è¨€åŠ¨ä½œæ¨¡å‹ï¼‰ä¸ŠåŸºå‡†æµ‹è¯•ï¼Œå®ç°äº†æœ‰æ•ˆçš„ä»¿çœŸåˆ°ç°å®è¿ç§»ã€‚ç»“è®ºè¡¨æ˜AgentWorldèƒ½å¤§å¹…æå‡å¤æ‚å®¶å±…ç¯å¢ƒä¸‹æœºå™¨äººæ³›åŒ–ä¸æŠ€èƒ½å­¦ä¹ èƒ½åŠ›ï¼Œä¸ºå®é™…éƒ¨ç½²æä¾›äº†åšå®åŸºç¡€ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="53-NeeCo-Image-Synthesis-of-Novel-Instrument-States-Based-on-Dynamic-and-Deformable-3D-Gaussian-Reconstruction"><a href="#53-NeeCo-Image-Synthesis-of-Novel-Instrument-States-Based-on-Dynamic-and-Deformable-3D-Gaussian-Reconstruction" class="headerlink" title="53. NeeCo: Image Synthesis of Novel Instrument States Based on Dynamic and Deformable 3D Gaussian Reconstruction"></a>53. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/NeeCo__Image_Synthesis_of_Novel_Instrument_States_Based_on_Dynamic_and_Deformable_3D_Gaussian_Recons.pdf">NeeCo: Image Synthesis of Novel Instrument States Based on Dynamic and Deformable 3D Gaussian Reconstruction</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Leeds</span></p>
<p>æœ¬æ–‡æå‡ºNeeCoæ¡†æ¶ï¼Œåˆ©ç”¨åŠ¨æ€å¯å˜å½¢3Dé«˜æ–¯é‡å»ºæŠ€æœ¯ï¼Œé€šè¿‡å­¦ä¹ æ‰‹æœ¯å™¨æ¢°è¿åŠ¨å­¦å’Œé«˜æ–¯æ¸²æŸ“ï¼Œè‡ªåŠ¨åˆæˆä¸åŒå§¿æ€å’Œå˜å½¢ä¸‹çš„æ‰‹æœ¯å™¨æ¢°é«˜è´¨é‡å›¾åƒåŠå…¶æ ‡æ³¨ï¼Œå¹¶å¼•å…¥åŠ¨æ€è®­ç»ƒè°ƒæ•´ç­–ç•¥ä»¥åº”å¯¹çœŸå®åœºæ™¯ä¸‹çš„ç›¸æœºå§¿æ€è¯¯å·®ã€‚å®éªŒæ˜¾ç¤ºï¼ŒNeeCoç”Ÿæˆçš„æ•°æ®é›†åœ¨æå‡æ‰‹æœ¯å™¨æ¢°æ£€æµ‹ä¸åˆ†å‰²ç¥ç»ç½‘ç»œæ€§èƒ½æ–¹é¢ä¼˜äºSOTAæ–¹æ³•ï¼Œä¸”è‡ªåŠ¨æ ‡æ³¨ç²¾åº¦é«˜ï¼Œæœ‰æ•ˆè§£å†³äº†åŒ»å­¦å›¾åƒæ•°æ®ç¨€ç¼ºä¸æ ‡æ³¨éš¾é¢˜ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="54-Autonomous-Navigation-of-Cloud-Controlled-Quadcopters-in-Confined-Spaces-Using-Multi-Modal-Perception-and-LLM-Driven-High-Semantic-Reasoning"><a href="#54-Autonomous-Navigation-of-Cloud-Controlled-Quadcopters-in-Confined-Spaces-Using-Multi-Modal-Perception-and-LLM-Driven-High-Semantic-Reasoning" class="headerlink" title="54. Autonomous Navigation of Cloud-Controlled Quadcopters in Confined Spaces Using Multi-Modal Perception and LLM-Driven High Semantic Reasoning"></a>54. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Autonomous_Navigation_of_Cloud-Controlled_Quadcopters_in_Confined_Spaces_Using_Multi-Modal_Perceptio.pdf">Autonomous Navigation of Cloud-Controlled Quadcopters in Confined Spaces Using Multi-Modal Perception and LLM-Driven High Semantic Reasoning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Rajshahi University of Engineering and Technology</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºGPS-deniedå®¤å†…ç¯å¢ƒè‡ªä¸»æ— äººæœºå¯¼èˆªçš„å¤šæ¨¡æ€æ„ŸçŸ¥ä¸äº‘ç«¯å¤§æ¨¡å‹å†³ç­–ç³»ç»Ÿã€‚æ–¹æ³•åŒ…æ‹¬YOLOv11ç›®æ ‡æ£€æµ‹ã€Depth Anything V2å•ç›®æ·±åº¦ä¼°è®¡ã€å®šåˆ¶PCBé›†æˆToFå’ŒIMUä¼ æ„Ÿå™¨ã€å¤šçº¿ç¨‹æ¶æ„ã€VLMåœºæ™¯ç†è§£ï¼Œä»¥åŠäº‘ç«¯å¾®è°ƒLLMè¿›è¡Œé«˜è¯­ä¹‰å¯¼èˆªå†³ç­–ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨42æ¬¡è¯•éªŒä¸­ä»…å‘ç”Ÿ16æ¬¡é˜²æŠ¤ç½©çªç ´ï¼Œç«¯åˆ°ç«¯å»¶è¿Ÿä½äº1ç§’ï¼Œå¯¼èˆªå‘½ä»¤å‡†ç¡®ç‡è¾¾68%ï¼Œå®ç°äº†é²æ£’çš„å®¤å†…è‡ªä¸»é£è¡Œå’Œå®‰å…¨é¿éšœã€‚ç»“è®ºï¼šé›†æˆå¤šæ¨¡æ€æ„ŸçŸ¥ä¸å¤§æ¨¡å‹è¯­ä¹‰æ¨ç†æ˜¾è‘—æå‡äº†å®¤å†…æ— äººæœºçš„æ™ºèƒ½è‡ªä¸»å¯¼èˆªèƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="55-Being-M0-5-A-Real-Time-Controllable-Vision-Language-Motion-Model"><a href="#55-Being-M0-5-A-Real-Time-Controllable-Vision-Language-Motion-Model" class="headerlink" title="55. Being-M0.5: A Real-Time Controllable Vision-Language-Motion Model"></a>55. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Being-M0.5__A_Real-Time_Controllable_Vision-Language-Motion_Model.pdf">Being-M0.5: A Real-Time Controllable Vision-Language-Motion Model</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">CASIA</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†Being-M0.5ï¼Œä¸€ä¸ªå…·å¤‡å®æ—¶ã€å¯æ§æ€§çš„äººä½“è¿åŠ¨ç”Ÿæˆçš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹ï¼ˆVLMMï¼‰ï¼Œé‡‡ç”¨å¤§è§„æ¨¡å¤šæ¨¡æ€æ•°æ®é›†HuMo100Må’Œåˆ›æ–°çš„éƒ¨ä½æ„ŸçŸ¥æ®‹å·®é‡åŒ–ï¼ˆPRQï¼‰æŠ€æœ¯ï¼Œå®ç°å¯¹èº«ä½“å„éƒ¨ä½çš„ç»†ç²’åº¦æ§åˆ¶ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨å¤šç§åŠ¨ä½œç”ŸæˆåŸºå‡†ä¸Šå‡è¾¾åˆ°äº†æœ€æ–°æœ€ä¼˜æ€§èƒ½ï¼Œå¹¶å…·å¤‡å®é™…éƒ¨ç½²çš„é«˜æ•ˆç‡å’Œå¹¿æ³›é€‚åº”æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="56-Learning-Satellite-Attitude-Dynamics-with-Physics-Informed-Normalising-Flow"><a href="#56-Learning-Satellite-Attitude-Dynamics-with-Physics-Informed-Normalising-Flow" class="headerlink" title="56. Learning Satellite Attitude Dynamics with Physics-Informed Normalising Flow"></a>56. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Learning_Satellite_Attitude_Dynamics_with_Physics-Informed_Normalising_Flow.pdf">Learning Satellite Attitude Dynamics with Physics-Informed Normalising Flow</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Politecnico di Torino</span></p>
<p>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§ç»“åˆç‰©ç†çº¦æŸå’Œæ•°æ®é©±åŠ¨çš„Real NVPæ­£åˆ™åŒ–æµç¥ç»ç½‘ç»œï¼ˆç»“åˆè‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼‰ï¼Œç”¨äºå­¦ä¹ å«æ˜Ÿå§¿æ€åŠ¨åŠ›å­¦ï¼Œå¹¶é€šè¿‡å¼•å…¥ç‰©ç†ä¿¡æ¯æŸå¤±å‡½æ•°ï¼ˆåŸºäºLagrangian dualæ–¹æ³•åŠ¨æ€è°ƒèŠ‚æƒé‡ï¼‰æå‡æ¨¡å‹æ³›åŒ–å’Œé²æ£’æ€§ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨çŠ¶æ€é¢„æµ‹å’ŒåµŒå…¥MPCæ§åˆ¶æ¡†æ¶ä¸­çš„è¡¨ç°å‡ä¼˜äºçº¯æ•°æ®é©±åŠ¨æ¨¡å‹ï¼Œå¹³å‡ç›¸å¯¹è¯¯å·®é™ä½27.08%~90.22%ï¼Œé—­ç¯æ§åˆ¶é²æ£’æ€§å’Œç¨³å®šæ€§æå‡æ˜¾è‘—ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="57-SwarmVLM-VLM-Guided-Impedance-Control-for-Autonomous-Navigation-of-Heterogeneous-Robots-in-Dynamic-Warehousing"><a href="#57-SwarmVLM-VLM-Guided-Impedance-Control-for-Autonomous-Navigation-of-Heterogeneous-Robots-in-Dynamic-Warehousing" class="headerlink" title="57. SwarmVLM: VLM-Guided Impedance Control for Autonomous Navigation of Heterogeneous Robots in Dynamic Warehousing"></a>57. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/SwarmVLM__VLM-Guided_Impedance_Control_for_Autonomous_Navigation_of_Heterogeneous_Robots_in_Dynamic_.pdf">SwarmVLM: VLM-Guided Impedance Control for Autonomous Navigation of Heterogeneous Robots in Dynamic Warehousing</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Skolkovo Institute of Science and Technology</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†SwarmVLMç³»ç»Ÿï¼Œå°†äººå·¥åŠ¿åœºï¼ˆAPFï¼‰è·¯å¾„è§„åˆ’ã€è™šæ‹Ÿé˜»æŠ—æ§åˆ¶ã€è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ä¸æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ¡†æ¶ç›¸ç»“åˆï¼Œå®ç°æ— äººæœºä¸åœ°é¢ç§»åŠ¨æœºå™¨äººåœ¨åŠ¨æ€ä»“å‚¨ç¯å¢ƒä¸‹çš„åä½œå¯¼èˆªã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿèƒ½æ ¹æ®éšœç¢ç‰©åˆ†å¸ƒè‡ªé€‚åº”è°ƒæ•´é˜»æŠ—å‚æ•°ï¼ŒçœŸå®åœºæ™¯ä¸‹å¯¼èˆªæˆåŠŸç‡è¾¾92%ï¼ŒVLM-RAGæ¨¡å—åœ¨è‰¯å¥½å…‰ç…§ä¸‹ç‰©ä½“æ£€æµ‹åŠå‚æ•°é€‰æ‹©å‡†ç¡®ç‡ä¸º80%ã€‚ç»“è®ºè¡¨æ˜ï¼šè¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†å¼‚æ„æœºå™¨äººåœ¨å¯†é›†åŠ¨æ€ç¯å¢ƒä¸­çš„å®‰å…¨ä¸æ™ºèƒ½å¯¼èˆªèƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="58-Risk-Map-As-Middleware-Towards-Interpretable-Cooperative-End-to-end-Autonomous-Driving-for-Risk-Aware-Planning"><a href="#58-Risk-Map-As-Middleware-Towards-Interpretable-Cooperative-End-to-end-Autonomous-Driving-for-Risk-Aware-Planning" class="headerlink" title="58. Risk Map As Middleware: Towards Interpretable Cooperative End-to-end Autonomous Driving for Risk-Aware Planning"></a>58. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Risk_Map_As_Middleware__Towards_Interpretable_Cooperative_End-to-end_Autonomous_Driving_for_Risk-Awa.pdf">Risk Map As Middleware: Towards Interpretable Cooperative End-to-end Autonomous Driving for Risk-Aware Planning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Tongji University</span></p>
<p>æœ¬æ–‡æå‡ºäº†Risk Map as Middlewareï¼ˆRiskMMï¼‰ï¼Œä¸€ç§ç»“åˆå¤šæ™ºèƒ½ä½“æ—¶ç©ºåä½œæ„ŸçŸ¥ã€Transformeræ¶æ„ä¸æ˜¾å¼é£é™©å»ºæ¨¡çš„ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶æ¡†æ¶ã€‚RiskMMåˆ©ç”¨å¤šè½¦åŠåŸºç¡€è®¾æ–½çš„æ„ŸçŸ¥æ•°æ®ï¼Œç”Ÿæˆå¯è§£é‡Šçš„æ—¶ç©ºé£é™©å›¾ï¼Œå¹¶é€šè¿‡å­¦ä¹ å‹MPCæ¨¡å—ï¼Œåœ¨ç‰©ç†çº¦æŸä¸‹è¿›è¡Œé£é™©æ„ŸçŸ¥çš„è½¨è¿¹è§„åˆ’ã€‚å®éªŒè¡¨æ˜ï¼ŒRiskMMåœ¨V2XPnP-SeqçœŸå®æ•°æ®é›†ä¸Šå¤§å¹…æå‡äº†è§„åˆ’å®‰å…¨æ€§å’Œè§£é‡Šæ€§ï¼Œä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶å…·å¤‡è‰¯å¥½é²æ£’æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="59-AIS-LLM-A-Unified-Framework-for-Maritime-Trajectory-Prediction-Anomaly-Detection-and-Collision-Risk-Assessment-with-Explainable-Forecasting"><a href="#59-AIS-LLM-A-Unified-Framework-for-Maritime-Trajectory-Prediction-Anomaly-Detection-and-Collision-Risk-Assessment-with-Explainable-Forecasting" class="headerlink" title="59. AIS-LLM: A Unified Framework for Maritime Trajectory Prediction, Anomaly Detection, and Collision Risk Assessment with Explainable Forecasting"></a>59. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/AIS-LLM__A_Unified_Framework_for_Maritime_Trajectory_Prediction,_Anomaly_Detection,_and_Collision_Ri.pdf">AIS-LLM: A Unified Framework for Maritime Trajectory Prediction, Anomaly Detection, and Collision Risk Assessment with Explainable Forecasting</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Hanbat National University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºAIS-LLMæ¡†æ¶ï¼Œå°†å¤šå°ºåº¦AISæ—¶åºæ•°æ®ä¸å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç»“åˆï¼Œé‡‡ç”¨å¤šä»»åŠ¡å­¦ä¹ ç»“æ„åŒæ—¶å®ç°èˆ¹èˆ¶è½¨è¿¹é¢„æµ‹ã€å¼‚å¸¸æ£€æµ‹å’Œç¢°æ’é£é™©è¯„ä¼°ï¼Œå¹¶æ”¯æŒæ•°å€¼é¢„æµ‹å’Œè‡ªç„¶è¯­è¨€è§£é‡Šã€‚å®éªŒæ˜¾ç¤ºAIS-LLMåœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†æµ·äº‹äº¤é€šåˆ†æçš„å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="60-End-to-End-Humanoid-Robot-Safe-and-Comfortable-Locomotion-Policy"><a href="#60-End-to-End-Humanoid-Robot-Safe-and-Comfortable-Locomotion-Policy" class="headerlink" title="60. End-to-End Humanoid Robot Safe and Comfortable Locomotion Policy"></a>60. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/End-to-End_Humanoid_Robot_Safe_and_Comfortable_Locomotion_Policy.pdf">End-to-End Humanoid Robot Safe and Comfortable Locomotion Policy</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">The Hong Kong University of Science and Technology (Guangzhou)</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§ç«¯åˆ°ç«¯çš„ä»¿äººæœºå™¨äººè¡Œèµ°ç­–ç•¥ï¼Œåˆ©ç”¨åŸå§‹æ—¶ç©ºLiDARç‚¹äº‘ï¼Œç»ç”±GRU-MLPç»“æ„ç›´æ¥æ˜ å°„è‡³æœºå™¨äººç”µæœºå‘½ä»¤ï¼Œå®ç°å¤æ‚3DåŠ¨æ€åœºæ™¯ä¸‹çš„å®‰å…¨èˆ’é€‚å¯¼èˆªã€‚æ–¹æ³•å°†æ§åˆ¶éšœç¢å‡½æ•°ï¼ˆCBFï¼‰åŸç†èå…¥çº¦æŸé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆCMDPï¼‰å¹¶é‡‡ç”¨P3Oç®—æ³•è®­ç»ƒï¼ŒåŒæ—¶å¼•å…¥åŸºäºäººæœºäº¤äº’çš„èˆ’é€‚æ€§å¥–åŠ±ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç­–ç•¥åœ¨ä»¿çœŸå’ŒçœŸå®æœºå™¨äººä¸Šå‡å¯å®ç°é«˜æ•ˆã€å®‰å…¨ã€å¹³æ»‘ä¸”ç¬¦åˆç¤¾ä¼šè§„èŒƒçš„é¿éšœè¡Œèµ°ï¼Œæ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="61-Training-Free-ANN-to-SNN-Conversion-for-High-Performance-Spiking-Transformer"><a href="#61-Training-Free-ANN-to-SNN-Conversion-for-High-Performance-Spiking-Transformer" class="headerlink" title="61. Training-Free ANN-to-SNN Conversion for High-Performance Spiking Transformer"></a>61. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Training-Free_ANN-to-SNN_Conversion_for_High-Performance_Spiking_Transformer.pdf">Training-Free ANN-to-SNN Conversion for High-Performance Spiking Transformer</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Electronic Science and Technology of China</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†é¢å‘Transformeræ¶æ„çš„æ— è®­ç»ƒäººå·¥ç¥ç»ç½‘ç»œï¼ˆANNï¼‰åˆ°è„‰å†²ç¥ç»ç½‘ç»œï¼ˆSNNï¼‰è½¬æ¢æ¡†æ¶ï¼Œæ ¸å¿ƒæ–¹æ³•æ˜¯å¤šåŸºæŒ‡æ•°è¡°å‡ï¼ˆMBEï¼‰ç¥ç»å…ƒï¼Œé€šè¿‡æŒ‡æ•°è¡°å‡å’Œå¤šåŸºç¼–ç ç²¾å‡†æ‹ŸåˆTransformerä¸­çš„éçº¿æ€§æ“ä½œï¼ˆå¦‚GELUã€Softmaxã€LayerNormã€æµ®ç‚¹ä¹˜æ³•ï¼‰ï¼Œæ— éœ€ä¿®æ”¹é¢„è®­ç»ƒANNæƒé‡ã€‚å®éªŒè¦†ç›–CVã€NLUã€NLGä¸‰å¤§ä»»åŠ¡å’ŒViTã€RoBERTaã€GPT-2ç­‰ä¸»æµæ¨¡å‹ï¼Œç»“æœæ˜¾ç¤ºè¯¥æ–¹æ³•åœ¨ä¿æŒè¿‘ä¹æ— æŸç²¾åº¦çš„åŒæ—¶æ˜¾è‘—é™ä½æ¨ç†å»¶è¿Ÿï¼Œä¸ºé«˜æ•ˆå¯æ‰©å±•éƒ¨ç½²è„‰å†²Transformeræä¾›æ–°æ€è·¯ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="62-LAURON-VI-A-Six-Legged-Robot-for-Dynamic-Walking"><a href="#62-LAURON-VI-A-Six-Legged-Robot-for-Dynamic-Walking" class="headerlink" title="62. LAURON VI: A Six-Legged Robot for Dynamic Walking"></a>62. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/LAURON_VI__A_Six-Legged_Robot_for_Dynamic_Walking.pdf">LAURON VI: A Six-Legged Robot for Dynamic Walking</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">FZI Research Center for Information Technology</span></p>
<p>æœ¬æ–‡æå‡ºäº†å…­è¶³æœºå™¨äººå¹³å°LAURON VIï¼Œé‡‡ç”¨18ä¸ªä¸²è”å¼¹æ€§å…³èŠ‚é©±åŠ¨å™¨ï¼Œå¹¶è®¾è®¡å®ç°äº†ä¸‰ç§åŠ¨æ€è¡Œèµ°æ§åˆ¶å™¨ï¼šåŸºäºè¿åŠ¨å­¦çš„æ–¹æ³•ã€æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆMPCï¼‰ã€å’Œå¼ºåŒ–å­¦ä¹ ç­–ç•¥ã€‚å®éªŒè¡¨æ˜ï¼Œä¸‰ç§æ§åˆ¶ç­–ç•¥å‡èƒ½åœ¨ä¸åŒç¯å¢ƒä¸‹å®ç°çµæ´»ä¸”é«˜æ•ˆçš„è¿åŠ¨ï¼Œæ˜¾è‘—æå‡äº†å…­è¶³æœºå™¨äººåœ¨å¤æ‚åœ°å½¢å’Œå®é™…ä»»åŠ¡ä¸­çš„é€Ÿåº¦å’Œé€‚åº”æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="63-GraphCoT-VLA-A-3D-Spatial-Aware-Reasoning-Vision-Language-Action-Model-for-Robotic-Manipulation-with-Ambiguous-Instructions"><a href="#63-GraphCoT-VLA-A-3D-Spatial-Aware-Reasoning-Vision-Language-Action-Model-for-Robotic-Manipulation-with-Ambiguous-Instructions" class="headerlink" title="63. GraphCoT-VLA: A 3D Spatial-Aware Reasoning Vision-Language-Action Model for Robotic Manipulation with Ambiguous Instructions"></a>63. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/GraphCoT-VLA__A_3D_Spatial-Aware_Reasoning_Vision-Language-Action_Model_for_Robotic_Manipulation_wit.pdf">GraphCoT-VLA: A 3D Spatial-Aware Reasoning Vision-Language-Action Model for Robotic Manipulation with Ambiguous Instructions</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Noahâ€™s Ark Lab, Huawei</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºGraphCoT-VLAçš„ç«¯åˆ°ç«¯æœºå™¨äººæ“ä½œæ¨¡å‹ï¼Œé€šè¿‡å¼•å…¥ç»“æ„åŒ–Chain-of-Thoughtæ¨ç†æ¨¡å—å’Œå®æ—¶å¯æ›´æ–°çš„3D Pose-Objectå›¾ï¼Œå®ç°äº†å¯¹å¤šè§†è§’è§†è§‰ã€è¯­è¨€æŒ‡ä»¤åŠæœºå™¨äººçŠ¶æ€çš„è”åˆç†è§£å’ŒåŠ¨æ€æ¨ç†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨é¢å¯¹æ¨¡ç³ŠæŒ‡ä»¤å’Œå¼€æ”¾ç¯å¢ƒæ—¶ï¼Œåœ¨ä»»åŠ¡æˆåŠŸç‡ã€å“åº”é€Ÿåº¦å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢å‡æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h2 id="cv">Computer Vision</h2>


<h3 id="64-Sensory-Robustness-through-Top-Down-Feedback-and-Neural-Stochasticity-in-Recurrent-Vision-Models"><a href="#64-Sensory-Robustness-through-Top-Down-Feedback-and-Neural-Stochasticity-in-Recurrent-Vision-Models" class="headerlink" title="64. Sensory Robustness through Top-Down Feedback and Neural Stochasticity in Recurrent Vision Models"></a>64. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Sensory_robustness_through_top-down_feedback_and_neural_stochasticity_in_recurrent_vision_models.pdf">Sensory Robustness through Top-Down Feedback and Neural Stochasticity in Recurrent Vision Models</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Department of Neural Dynamics and Magnetoencephalography, Hertie Institute for Clinical Brain Research, University of TÃ¼bingen</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»“åˆå·ç§¯é€’å½’ç¥ç»ç½‘ç»œï¼ˆConvRNNï¼‰ä¸­çš„é¡¶å±‚-åº•å±‚åé¦ˆé€šè·¯å’Œç¥ç»å…ƒéšæœºæ€§ï¼ˆé€šè¿‡dropoutå®ç°ï¼‰çš„è§†è§‰æ¨¡å‹ï¼Œå¹¶åœ¨å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­ç³»ç»Ÿæ¯”è¾ƒäº†æœ‰æ— åé¦ˆå’Œæœ‰æ— éšæœºæ€§çš„ä¸åŒæ¶æ„ã€‚ç ”ç©¶å‘ç°ï¼šåªæœ‰åŒæ—¶å…·å¤‡é¡¶å±‚åé¦ˆå’Œç¥ç»å…ƒéšæœºæ€§æ—¶ï¼Œæ¨¡å‹æ‰èƒ½åœ¨é€Ÿåº¦-å‡†ç¡®ç‡æƒè¡¡ã€å™ªå£°æ‰°åŠ¨å’Œå¯¹æŠ—æ”»å‡»ç­‰åˆ†å¸ƒå¤–åœºæ™¯ä¸‹è¡¨ç°å‡ºæ˜¾è‘—çš„é²æ£’æ€§å’Œé«˜æ•ˆæ€§ã€‚è¿›ä¸€æ­¥åˆ†ææ˜¾ç¤ºï¼Œåé¦ˆä¿¡å·èƒ½æ˜¾è‘—å¡‘é€ ç½‘ç»œçš„è¡¨ç¤ºç©ºé—´ï¼Œå°†ç‰¹å¾çº¦æŸåˆ°ä½ç»´æµå½¢ä¸Šï¼Œæå‡æ³›åŒ–èƒ½åŠ›å’Œç¨³å®šæ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="65-TeSO-Representing-and-Compressing-3D-Point-Cloud-Scenes-with-Textured-Surfel-Octree"><a href="#65-TeSO-Representing-and-Compressing-3D-Point-Cloud-Scenes-with-Textured-Surfel-Octree" class="headerlink" title="65. TeSO: Representing and Compressing 3D Point Cloud Scenes with Textured Surfel Octree"></a>65. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/TeSO__Representing_and_Compressing_3D_Point_Cloud_Scenes_with_Textured_Surfel_Octree.pdf">TeSO: Representing and Compressing 3D Point Cloud Scenes with Textured Surfel Octree</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">New York University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†Textured Surfel Octree (TeSO)ï¼Œä¸€ç§ç»“åˆç‚¹äº‘å’Œç½‘æ ¼ä¼˜åŠ¿çš„æ–°å‹3Dåœºæ™¯è¡¨ç¤ºæ–¹æ³•ã€‚å…¶æµç¨‹åŒ…æ‹¬åˆ©ç”¨ç‚¹äº‘æ„å»ºå…«å‰æ ‘ç»“æ„çš„è¡¨é¢å…ƒç´ ï¼ˆsurfelï¼‰ï¼Œå¹¶ä¸ºæ¯ä¸ªsurfelåˆ†é…çº¹ç†è´´å›¾ï¼ŒåŒæ—¶è®¾è®¡äº†åŸºäºç¥ç»ç½‘ç»œçš„ç†µæ¨¡å‹å’Œæ ‡å‡†ç¼–è§£ç å™¨å®ç°é«˜æ•ˆå‹ç¼©ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTeSOåœ¨ä½æ¯”ç‰¹ç‡ä¸‹å¯å®ç°æ¯”ä¼ ç»Ÿç‚¹äº‘å’Œ3Dé«˜æ–¯åŸºçº¿æ›´é«˜è´¨é‡çš„æ¸²æŸ“ï¼Œæ”¯æŒå®æ—¶æ¸²æŸ“ä¸”æ›´é€‚åˆ3Då†…å®¹æµåª’ä½“å’ŒXRåº”ç”¨ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="66-BrainATCL-Adaptive-Temporal-Brain-Connectivity-Learning-for-Functional-Link-Prediction-and-Age-Estimation"><a href="#66-BrainATCL-Adaptive-Temporal-Brain-Connectivity-Learning-for-Functional-Link-Prediction-and-Age-Estimation" class="headerlink" title="66. BrainATCL: Adaptive Temporal Brain Connectivity Learning for Functional Link Prediction and Age Estimation"></a>66. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/BrainATCL__Adaptive_Temporal_Brain_Connectivity_Learning_for_Functional_Link_Prediction_and_Age_Esti.pdf">BrainATCL: Adaptive Temporal Brain Connectivity Learning for Functional Link Prediction and Age Estimation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">New Jersey Institute of Technology</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§æ— ç›‘ç£ã€è‡ªé€‚åº”çš„æ—¶åºè„‘è¿æ¥å­¦ä¹ æ–¹æ³•BrainATCLï¼Œé€šè¿‡åŸºäºæ–°é¢–æ€§æŒ‡æ•°åŠ¨æ€è°ƒæ•´æ¯ä¸ªæ—¶é—´ç‚¹çš„å†å²çª—å£é•¿åº¦ï¼Œå¹¶ç»“åˆç»“æ„&#x2F;åŠŸèƒ½ç›¸å…³çš„è¾¹å±æ€§ï¼Œåˆ©ç”¨GINE-Mamba2éª¨å¹²ç½‘ç»œç¼–ç fMRIåŠ¨æ€åŠŸèƒ½è¿æ¥æ—¶åºå›¾ï¼Œå®ç°äº†åŠŸèƒ½è¿æ¥é¢„æµ‹å’Œå¹´é¾„ä¼°è®¡ã€‚å®éªŒè¡¨æ˜ï¼ŒBrainATCLåœ¨Human Connectome Projectæ•°æ®ä¸Šå¯¹åŠŸèƒ½è¿æ¥é¢„æµ‹å’Œå¹´é¾„ä¼°è®¡ä»»åŠ¡è¡¨ç°ä¼˜å¼‚ï¼Œæ³›åŒ–èƒ½åŠ›å¼ºï¼Œè¶…è¶Šäº†ç°æœ‰é™æ€å’ŒåŠ¨æ€å›¾å­¦ä¹ åŸºçº¿ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="67-Large-Language-Model-Evaluated-Stand-alone-Attention-Assisted-Graph-Neural-Network-with-Spatial-and-Structural-Information-Interaction-for-Precise-Endoscopic-Image-Segmentation"><a href="#67-Large-Language-Model-Evaluated-Stand-alone-Attention-Assisted-Graph-Neural-Network-with-Spatial-and-Structural-Information-Interaction-for-Precise-Endoscopic-Image-Segmentation" class="headerlink" title="67. Large Language Model Evaluated Stand-alone Attention-Assisted Graph Neural Network with Spatial and Structural Information Interaction for Precise Endoscopic Image Segmentation"></a>67. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Large_Language_Model_Evaluated_Stand-alone_Attention-Assisted_Graph_Neural_Network_with_Spatial_and_.pdf">Large Language Model Evaluated Stand-alone Attention-Assisted Graph Neural Network with Spatial and Structural Information Interaction for Precise Endoscopic Image Segmentation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">The Chinese University of Hong Kong</span></p>
<p>æœ¬æ–‡æå‡ºFOCUS-Medï¼Œä¸€ç§èåˆç©ºé—´å’Œç»“æ„å›¾ã€å¸¦æœ‰æ³¨æ„åŠ›æœºåˆ¶çš„å›¾ç¥ç»ç½‘ç»œæ–¹æ³•ï¼Œç”¨äºå†…é•œå›¾åƒä¸­ç²¾ç¡®æ¯è‚‰åˆ†å‰²ã€‚æ–¹æ³•åŒ…æ‹¬Dual-GCNæ¨¡å—ç”¨äºç©ºé—´å’Œæ‹“æ‰‘ç‰¹å¾æå–ã€ä½ç½®èåˆè‡ªæ³¨æ„åŠ›æœºåˆ¶è¿›è¡Œå…¨å±€ä¸Šä¸‹æ–‡æ•´åˆã€ä»¥åŠåŠ æƒå¿«é€Ÿå½’ä¸€åŒ–èåˆå®ç°å¤šå°ºåº¦ç‰¹å¾èšåˆï¼Œå¹¶é¦–æ¬¡å¼•å…¥å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¾…åŠ©åˆ†å‰²ç»“æœçš„ä¸“å®¶çº§å®šæ€§è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFOCUS-Medåœ¨å¤šä¸ªå…¬å¼€åŒ»å­¦å›¾åƒæ•°æ®é›†ä¸Šåˆ†å‰²æ€§èƒ½è¶…è¶Šç°æœ‰å…ˆè¿›æ¨¡å‹ï¼Œå…·æœ‰è¾ƒé«˜ç²¾åº¦å’Œä¸´åºŠåº”ç”¨æ½œåŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="68-TerraMAE-Learning-Spatial-Spectral-Representations-from-Hyperspectral-Earth-Observation-Data-via-Adaptive-Masked-Autoencoders"><a href="#68-TerraMAE-Learning-Spatial-Spectral-Representations-from-Hyperspectral-Earth-Observation-Data-via-Adaptive-Masked-Autoencoders" class="headerlink" title="68. TerraMAE: Learning Spatial-Spectral Representations from Hyperspectral Earth Observation Data via Adaptive Masked Autoencoders"></a>68. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/TerraMAE__Learning_Spatial-Spectral_Representations_from_Hyperspectral_Earth_Observation_Data_via_Ad.pdf">TerraMAE: Learning Spatial-Spectral Representations from Hyperspectral Earth Observation Data via Adaptive Masked Autoencoders</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Colorado State University</span></p>
<p>æœ¬æ–‡æå‡ºTerraMAEï¼Œä¸€ç§ä¸“ä¸ºé«˜å…‰è°±é¥æ„Ÿå½±åƒè®¾è®¡çš„è‡ªç›‘ç£Masked Autoencoderé¢„è®­ç»ƒæ¡†æ¶ï¼Œé€šè¿‡åŸºäºç»Ÿè®¡åå°„ç‰¹æ€§çš„è‡ªé€‚åº”é€šé“åˆ†ç»„å’Œç»“åˆç©ºé—´ç»“æ„ä¸å…‰è°±ä¸€è‡´æ€§çš„å¤åˆæŸå¤±å‡½æ•°ï¼Œå®ç°ç©ºé—´-å…‰è°±ç‰¹å¾çš„é«˜æ•ˆå»ºæ¨¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTerraMAEåœ¨é«˜ä¿çœŸå½±åƒé‡å»ºä¸ä¸‹æ¸¸åœŸå£¤è´¨åœ°é¢„æµ‹ã€ä½œç‰©ç±»å‹è¯†åˆ«å’ŒåœŸåœ°è¦†ç›–åˆ†ç±»ç­‰åœ°ç†ç©ºé—´ä»»åŠ¡ä¸­å‡æ˜¾è‘—ä¼˜äºä¼ ç»ŸMAEå’ŒResNet-50ç­‰åŸºçº¿æ–¹æ³•ï¼Œå…·æœ‰å¾ˆå¼ºçš„æ³›åŒ–å’Œè¿ç§»èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="69-OctreeNCA-Single-Pass-184-MP-Segmentation-on-Consumer-Hardware"><a href="#69-OctreeNCA-Single-Pass-184-MP-Segmentation-on-Consumer-Hardware" class="headerlink" title="69. OctreeNCA: Single-Pass 184 MP Segmentation on Consumer Hardware"></a>69. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/OctreeNCA__Single-Pass_184_MP_Segmentation_on_Consumer_Hardware.pdf">OctreeNCA: Single-Pass 184 MP Segmentation on Consumer Hardware</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Technical University of Darmstadt</span></p>
<p>æœ¬æ–‡æå‡ºäº†OctreeNCAï¼Œä¸€ç§åŸºäºå…«å‰æ ‘ç»“æ„çš„ç¥ç»å…ƒå…ƒèƒè‡ªåŠ¨æœºï¼ˆNCAï¼‰åˆ†å‰²æ¶æ„ï¼Œé€šè¿‡åˆ†å±‚æ–¹å¼å¿«é€Ÿä¼ æ’­å…¨å±€ä¸Šä¸‹æ–‡å¹¶è¿›è¡Œé«˜åˆ†è¾¨ç‡åŒ»å­¦å›¾åƒå’Œè§†é¢‘çš„ç«¯åˆ°ç«¯åˆ†å‰²ã€‚è¯¥æ–¹æ³•ç»“åˆè‡ªå®šä¹‰CUDAæ¨ç†å†…æ ¸ï¼Œæ˜¾è‘—é™ä½äº†æ¨ç†æ‰€éœ€çš„æ˜¾å­˜ï¼ˆVRAMï¼‰ï¼Œå®ç°äº†åœ¨æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šå¯¹184MPç—…ç†åˆ‡ç‰‡å’Œä¸€åˆ†é’Ÿå¤–ç§‘æ‰‹æœ¯è§†é¢‘çš„å•æ­¥é«˜æ•ˆåˆ†å‰²ã€‚å®éªŒè¡¨æ˜ï¼ŒOctreeNCAåœ¨åˆ†å‰²ç²¾åº¦ä¸Šå¯åª²ç¾ç°æœ‰SOTAæ¨¡å‹ï¼ŒåŒæ—¶å¤§å¹…é™ä½å‚æ•°é‡å’Œæ¨ç†æ˜¾å­˜éœ€æ±‚ï¼Œé€‚åˆä½æˆæœ¬è®¾å¤‡éƒ¨ç½²ï¼Œæœ‰åŠ©äºç¼©å°å…¨çƒåŒ»ç–—ç¡¬ä»¶å·®è·ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="70-TADoc-Robust-Time-Aware-Document-Image-Dewarping"><a href="#70-TADoc-Robust-Time-Aware-Document-Image-Dewarping" class="headerlink" title="70. TADoc: Robust Time-Aware Document Image Dewarping"></a>70. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/TADoc__Robust_Time-Aware_Document_Image_Dewarping.pdf">TADoc: Robust Time-Aware Document Image Dewarping</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Institute of Information Engineering, Chinese Academy of Sciences</span></p>
<p>æœ¬æ–‡æå‡ºäº†TADocæ–¹æ³•ï¼Œå°†æ–‡æ¡£å›¾åƒå»ç•¸å˜ä»»åŠ¡é¦–æ¬¡å»ºæ¨¡ä¸ºä¸€ä¸ªå¤šæ­¥éª¤çš„åŠ¨æ€è¿‡ç¨‹ï¼Œé€šè¿‡æ—¶é—´åµŒå…¥å’Œè½»é‡çº§ç½‘ç»œé€æ­¥é¢„æµ‹ä¸åŒç¨‹åº¦çš„ç•¸å˜æ¢å¤ã€‚æå‡ºäº†æ–°çš„è¯„æµ‹æŒ‡æ ‡DLSç”¨äºè¯„ä¼°å»ç•¸å˜æ•ˆæœåœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTADocåœ¨å¤šä¸ªå…¬å¼€åŸºå‡†ä¸Šå…·æœ‰å¼ºé²æ£’æ€§å’Œé¢†å…ˆæ€§èƒ½ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="71-WeatherDiffusion-Weather-Guided-Diffusion-Model-for-Forward-and-Inverse-Rendering"><a href="#71-WeatherDiffusion-Weather-Guided-Diffusion-Model-for-Forward-and-Inverse-Rendering" class="headerlink" title="71. WeatherDiffusion: Weather-Guided Diffusion Model for Forward and Inverse Rendering"></a>71. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/WeatherDiffusion__Weather-Guided_Diffusion_Model_for_Forward_and_Inverse_Rendering.pdf">WeatherDiffusion: Weather-Guided Diffusion Model for Forward and Inverse Rendering</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Nanjing University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºWeatherDiffusionï¼Œä¸€ç§åŸºäºå¤§è§„æ¨¡æ‰©æ•£æ¨¡å‹çš„è‡ªåŠ¨é©¾é©¶åœºæ™¯å‰å‘ä¸é€†å‘æ¸²æŸ“æ¡†æ¶ï¼Œé€šè¿‡å¤©æ°”æ§åˆ¶å™¨å’Œæ–‡æœ¬æç¤ºå®ç°å¤šå¤©æ°”ä¸ç…§æ˜æ¡ä»¶ä¸‹çš„é«˜è´¨é‡å›¾åƒç”Ÿæˆä¸åˆ†è§£ã€‚å¼•å…¥Intrinsic Map-Aware Attentionï¼ˆMAAï¼‰æ¨¡å—ï¼Œç»“åˆæ–°æ„å»ºçš„åˆæˆä¸çœŸå®æ•°æ®é›†ï¼Œæ˜¾è‘—æå‡é€†å‘æ¸²æŸ“ç²¾åº¦å’Œä¸‹æ¸¸ç›®æ ‡æ£€æµ‹ä¸åˆ†å‰²åœ¨æ¶åŠ£å¤©æ°”ä¸‹çš„é²æ£’æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="72-Beyond-Frequency-Seeing-Subtle-Cues-Through-the-Lens-of-Spatial-Decomposition-for-Fine-Grained-Visual-Classification"><a href="#72-Beyond-Frequency-Seeing-Subtle-Cues-Through-the-Lens-of-Spatial-Decomposition-for-Fine-Grained-Visual-Classification" class="headerlink" title="72. Beyond Frequency: Seeing Subtle Cues Through the Lens of Spatial Decomposition for Fine-Grained Visual Classification"></a>72. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Beyond_Frequency__Seeing_Subtle_Cues_Through_the_Lens_of_Spatial_Decomposition_for_Fine-Grained_Visu.pdf">Beyond Frequency: Seeing Subtle Cues Through the Lens of Spatial Decomposition for Fine-Grained Visual Classification</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Anhui University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§å…¨æ–°çš„ç»†ç²’åº¦è§†è§‰åˆ†ç±»æ–¹æ³•SCOPEï¼ˆSubtle-Cue Oriented Perception Engineï¼‰ï¼Œé€šè¿‡ç©ºé—´è‡ªé€‚åº”æ»¤æ³¢æ›¿ä»£ä¼ ç»Ÿé¢‘åŸŸå˜æ¢ï¼Œå…¶ä¸­åŒ…å«ç»†è‡´ç‰¹å¾æå–æ¨¡å—ï¼ˆSDEï¼‰å’Œæ˜¾è‘—è¯­ä¹‰ä¼˜åŒ–æ¨¡å—ï¼ˆSSRï¼‰ï¼Œé€å±‚å¢å¼ºå±€éƒ¨ç»†èŠ‚ä¸å…¨å±€ç»“æ„ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSCOPEåœ¨å››ä¸ªä¸»æµç»†ç²’åº¦åˆ†ç±»æ•°æ®é›†ä¸Šå–å¾—äº†æ–°çš„SOTAè¡¨ç°ï¼Œæ˜¾è‘—æå‡äº†å¯¹å¾®å°åˆ¤åˆ«çº¿ç´¢çš„è¯†åˆ«èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="73-CannyEdit-Selective-Canny-Control-and-Dual-Prompt-Guidance-for-Training-free-Image-Editing"><a href="#73-CannyEdit-Selective-Canny-Control-and-Dual-Prompt-Guidance-for-Training-free-Image-Editing" class="headerlink" title="73. CannyEdit: Selective Canny Control and Dual-Prompt Guidance for Training-free Image Editing"></a>73. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/CannyEdit__Selective_Canny_Control_and_Dual-Prompt_Guidance_for_Training-Free_Image_Editing.pdf">CannyEdit: Selective Canny Control and Dual-Prompt Guidance for Training-free Image Editing</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">The Hong Kong University of Science and Technology</span></p>
<p>æœ¬æ–‡æå‡ºäº†CannyEditï¼Œä¸€ç§åŸºäºè®­ç»ƒè‡ªç”±çš„åŒºåŸŸå›¾åƒç¼–è¾‘æ–¹æ³•ï¼Œç»“åˆSelective Canny Controlå’ŒDual-Prompt GuidanceæŠ€æœ¯ã€‚Selective Canny Controlé€šè¿‡å¯¹ç”¨æˆ·æŒ‡å®šçš„ç¼–è¾‘åŒºåŸŸå±è”½Canny ControlNetç»“æ„å¼•å¯¼ï¼ŒåŒæ—¶ä¸¥æ ¼ä¿ç•™æœªç¼–è¾‘åŒºåŸŸçš„åŸå§‹ç»†èŠ‚ï¼Œå®ç°ç²¾ç¡®çš„æ–‡æœ¬é©±åŠ¨ç¼–è¾‘ï¼›Dual-Prompt Guidanceåˆ™èåˆå±€éƒ¨å’Œå…¨å±€æ–‡æœ¬æç¤ºï¼Œç¡®ä¿ç¼–è¾‘åŒºåŸŸä¸æ•´ä½“åœºæ™¯çš„è¯­ä¹‰ä¸€è‡´æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCannyEditåœ¨æ–‡æœ¬åŒ¹é…åº¦ã€ä¸Šä¸‹æ–‡ä¿çœŸåº¦åŠç¼–è¾‘è‡ªç„¶åº¦ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œç”¨æˆ·ç ”ç©¶è¡¨æ˜å…¶ç¼–è¾‘ç»“æœæ›´éš¾è¢«è¾¨è¯†ä¸ºAIç”Ÿæˆã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="74-MMReID-Bench-Unleashing-the-Power-of-MLLMs-for-Effective-and-Versatile-Person-Re-identification"><a href="#74-MMReID-Bench-Unleashing-the-Power-of-MLLMs-for-Effective-and-Versatile-Person-Re-identification" class="headerlink" title="74. MMReID-Bench: Unleashing the Power of MLLMs for Effective and Versatile Person Re-identification"></a>74. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/MMReID-Bench__Unleashing_the_Power_of_MLLMs_for_Effective_and_Versatile_Person_Re-identification.pdf">MMReID-Bench: Unleashing the Power of MLLMs for Effective and Versatile Person Re-identification</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">East China Normal University</span></p>
<p>æœ¬è®ºæ–‡æå‡ºäº†MMReID-Benchï¼Œè¿™æ˜¯é¦–ä¸ªä¸“ä¸ºå¤šä»»åŠ¡å’Œå¤šæ¨¡æ€åœºæ™¯è®¾è®¡çš„äººä½“é‡è¯†åˆ«åŸºå‡†ï¼Œè¦†ç›–10ç±»å…¸å‹ä»»åŠ¡ï¼ˆå¦‚RGBã€çº¢å¤–ã€è‰å›¾ç­‰ï¼‰ï¼Œå¹¶ç³»ç»Ÿæ€§è¯„ä¼°äº†15ç§ä¸»æµå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨è¯¥åŸºå‡†ä¸Šçš„è¡¨ç°ã€‚ç»“æœè¡¨æ˜MLLMsåœ¨å¤§å¤šæ•°äººä½“é‡è¯†åˆ«ä»»åŠ¡ä¸­å–å¾—äº†ä¼˜å¼‚æˆç»©ï¼Œä½†åœ¨çƒ­æˆåƒå’Œçº¢å¤–ç­‰è·¨æ¨¡æ€ä»»åŠ¡ä¸Šå­˜åœ¨æ˜æ˜¾çŸ­æ¿ï¼ŒäºŸéœ€æå‡è·¨æ¨¡æ€ç†è§£èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="75-A-Simple-yet-Powerful-Instance-Aware-Prompting-Framework-for-Training-free-Camouflaged-Object-Segmentation"><a href="#75-A-Simple-yet-Powerful-Instance-Aware-Prompting-Framework-for-Training-free-Camouflaged-Object-Segmentation" class="headerlink" title="75. A Simple yet Powerful Instance-Aware Prompting Framework for Training-free Camouflaged Object Segmentation"></a>75. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/A_Simple_yet_Powerful_Instance-Aware_Prompting_Framework_for_Training-free_Camouflaged_Object_Segmen.pdf">A Simple yet Powerful Instance-Aware Prompting Framework for Training-free Camouflaged Object Segmentation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Shanghai University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†é¦–ä¸ªè®­ç»ƒè‡ªç”±çš„å®ä¾‹æ„ŸçŸ¥æç¤ºæ¡†æ¶ï¼ˆIAPFï¼‰ï¼Œç”¨äºä¼ªè£…ç‰©ä½“åˆ†å‰²ã€‚æ–¹æ³•åŒ…æ‹¬ä¸‰æ­¥ï¼šåˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆå‰æ™¯&#x2F;èƒŒæ™¯æ ‡ç­¾ï¼Œå€ŸåŠ©Grounding DINOäº§ç”Ÿå¤šå®ä¾‹çº§åˆ«çš„è¾¹ç•Œæ¡†å’ŒåŒºåŸŸç‚¹æç¤ºï¼Œå¹¶ç»“åˆè‡ªä¸€è‡´æ€§å®ä¾‹æ©ç æŠ•ç¥¨æœºåˆ¶æå‡å¤šå®ä¾‹åˆ†å‰²ç²¾åº¦ã€‚å®éªŒè¡¨æ˜ï¼ŒIAPFåœ¨å¤šä¸ªæ ‡å‡†ä¼ªè£…åˆ†å‰²æ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ç»“è®ºï¼šè¯¥æ–¹æ³•æ— éœ€è®­ç»ƒå³å¯å®ç°é«˜ç²¾åº¦å¤šå®ä¾‹ä¼ªè£…åˆ†å‰²ï¼Œæå‡äº†è®­ç»ƒè‡ªç”±åˆ†å‰²é¢†åŸŸçš„è¡¨ç°ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="76-MV-CoRe-Multimodal-Visual-Conceptual-Reasoning-for-Complex-Visual-Question-Answering"><a href="#76-MV-CoRe-Multimodal-Visual-Conceptual-Reasoning-for-Complex-Visual-Question-Answering" class="headerlink" title="76. MV-CoRe: Multimodal Visual-Conceptual Reasoning for Complex Visual Question Answering"></a>76. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/MV-CoRe__Multimodal_Visual-Conceptual_Reasoning_for_Complex_Visual_Question_Answering.pdf">MV-CoRe: Multimodal Visual-Conceptual Reasoning for Complex Visual Question Answering</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Shaanxi University of Technology</span></p>
<p>MV-CoReæå‡ºäº†ä¸€ç§å¤šæ¨¡æ€è§†è§‰-æ¦‚å¿µæ¨ç†æ¨¡å‹ï¼Œé€šè¿‡èåˆé¢„è®­ç»ƒè§†è§‰å¤§æ¨¡å‹å’Œè¯­è¨€å¤§æ¨¡å‹çš„å…¨å±€ç‰¹å¾ï¼Œä»¥åŠåŸºäºç›®æ ‡æ£€æµ‹å’Œåœºæ™¯å›¾çš„ç»†ç²’åº¦è¯­ä¹‰è§†è§‰ç‰¹å¾ï¼Œåˆ©ç”¨åˆ›æ–°çš„å¤šæ¨¡æ€èåˆTransformerè¿›è¡Œæ·±åº¦è·¨æ¨¡æ€èåˆå’Œæ¨ç†ã€‚åœ¨GQAã€A-OKVQAå’ŒOKVQAç­‰å¤æ‚VQAåŸºå‡†ä¸Šï¼ŒMV-CoReæ˜¾è‘—ä¼˜äºä¸»æµLVLMæ¨¡å‹ï¼Œæå‡äº†è§†è§‰ç†è§£å’Œå¤æ‚æ¨ç†èƒ½åŠ›ï¼Œå°¤å…¶åœ¨äººç±»è¯„ä¼°ä¸­å±•ç°æ›´é«˜äº‹å®æ­£ç¡®æ€§å’Œæ¨ç†æ·±åº¦ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="77-HiMat-DiT-based-Ultra-High-Resolution-SVBRDF-Generation"><a href="#77-HiMat-DiT-based-Ultra-High-Resolution-SVBRDF-Generation" class="headerlink" title="77. HiMat: DiT-based Ultra-High Resolution SVBRDF Generation"></a>77. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/HiMat__DiT-based_Ultra-High_Resolution_SVBRDF_Generation.pdf">HiMat: DiT-based Ultra-High Resolution SVBRDF Generation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Nankai University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºHiMatï¼Œä¸€ç§åŸºäºDiffusion Transformerï¼ˆDiTï¼‰çš„é«˜æ•ˆæ‰©æ•£æ¨¡å‹ï¼Œç”¨äºåŸç”Ÿ4Kè¶…é«˜åˆ†è¾¨ç‡SVBRDFï¼ˆç©ºé—´å˜åŒ–åŒå‘åå°„åˆ†å¸ƒå‡½æ•°ï¼‰ææ–™ç”Ÿæˆã€‚æ–¹æ³•ç»“åˆçº¿æ€§æ³¨æ„åŠ›DiTéª¨å¹²ä¸è½»é‡çº§CrossStitchå·ç§¯æ¨¡å—ï¼Œå®ç°å¤šé€šé“SVBRDFä¸€è‡´æ€§å’Œé«˜é¢‘ç»†èŠ‚ä¿ç•™ï¼Œå¹¶é‡‡ç”¨å°æ³¢åŸŸç›‘ç£æå‡å¾®ç»“æ„ç»†èŠ‚ç”Ÿæˆã€‚ç»“è®ºæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨è§†è§‰è´¨é‡ã€ç»“æ„ä¸€è‡´æ€§å’Œè®¡ç®—æ•ˆç‡æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå®ç°äº†é«˜è´¨é‡4Kææ–™ç”Ÿæˆï¼Œå¹¶å¯æ‰©å±•è‡³å†…åœ¨åˆ†è§£ç­‰ä»»åŠ¡ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="78-Spatio-Temporal-Conditional-Diffusion-Models-for-Forecasting-Future-Multiple-Sclerosis-Lesion-Masks-Conditioned-on-Treatments"><a href="#78-Spatio-Temporal-Conditional-Diffusion-Models-for-Forecasting-Future-Multiple-Sclerosis-Lesion-Masks-Conditioned-on-Treatments" class="headerlink" title="78. Spatio-Temporal Conditional Diffusion Models for Forecasting Future Multiple Sclerosis Lesion Masks Conditioned on Treatments"></a>78. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Spatio-Temporal_Conditional_Diffusion_Models_for_Forecasting_Future_Multiple_Sclerosis_Lesion_Masks_.pdf">Spatio-Temporal Conditional Diffusion Models for Forecasting Future Multiple Sclerosis Lesion Masks Conditioned on Treatments</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">McGill University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†é¦–ä¸ªç»“åˆControlNetçš„æ—¶ç©ºæ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºé¢„æµ‹å¤šå‘æ€§ç¡¬åŒ–ç—‡ï¼ˆMSï¼‰æ‚£è€…åœ¨ä¸åŒæ²»ç–—æ–¹æ¡ˆä¸‹æœªæ¥MRIä¸Šçš„æ–°å‘å’Œå¢å¤§T2ç—…ç¶æ©è†œã€‚æ–¹æ³•é€šè¿‡å°†3D MRIæ•°æ®é‡æ„ä¸ºä¼ª2Dç‰‡ï¼Œèåˆå¤šæ¨¡æ€å½±åƒå’Œæ²»ç–—ä¿¡æ¯ï¼Œå®ç°é«˜åˆ†è¾¨ç‡ã€ä½“ç´ çº§é¢„æµ‹ã€‚å®éªŒæ˜¾ç¤ºæ¨¡å‹åœ¨å…­ç§æ²»ç–—ç»„ä¸‹æ•ˆæœä¼˜äºåŸºäºç»Ÿè®¡çš„åŸºçº¿ï¼Œå¹¶èƒ½æ”¯æŒä¸´åºŠç›¸å…³ä»»åŠ¡å¦‚ç—…ç¶è®¡æ•°ã€ä½ç½®ä¼°è®¡åŠåäº‹å®ç”Ÿæˆã€‚ç»“è®ºï¼šæ¨¡å‹èƒ½å‡†ç¡®é¢„æµ‹æœªæ¥ç—…ç¶å¹¶è¾…åŠ©ä¸ªä½“åŒ–åŒ»ç–—å†³ç­–ï¼Œå±•ç°äº†ç”Ÿæˆå¼AIåœ¨åŒ»å­¦å½±åƒä¸ªæ€§åŒ–é¢„æµ‹ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="79-Can-Multitask-Learning-Enhance-Model-Explainability"><a href="#79-Can-Multitask-Learning-Enhance-Model-Explainability" class="headerlink" title="79. Can Multitask Learning Enhance Model Explainability?"></a>79. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Can_Multitask_Learning_Enhance_Model_Explainability_.pdf">Can Multitask Learning Enhance Model Explainability?</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Kaiserslautern-Landau University</span></p>
<p>æœ¬æ–‡æå‡ºä¸€ç§é€šè¿‡å¤šä»»åŠ¡å­¦ä¹ å¢å¼ºæ¨¡å‹å¯è§£é‡Šæ€§çš„æ¡†æ¶ï¼Œé’ˆå¯¹é¥æ„Ÿå¤šæ¨¡æ€æ•°æ®ï¼Œå°†éƒ¨åˆ†è¾“å…¥æ¨¡æ€è½¬ä¸ºè¾…åŠ©é¢„æµ‹ä»»åŠ¡ï¼Œä¸»å¹²é‡‡ç”¨å¤šæ¨¡æ€ç¼–ç å™¨èåˆå«æ˜Ÿã€æ°”è±¡ç­‰ä¿¡æ¯ï¼Œåˆ†åˆ«åœ¨åˆ†å‰²ã€åˆ†ç±»å’Œå›å½’ä»»åŠ¡ä¸Šè¿›è¡Œå®éªŒã€‚ç»“æœæ˜¾ç¤ºè¯¥æ–¹æ³•åœ¨ä¸»ä»»åŠ¡æ€§èƒ½åŸºæœ¬æŒå¹³ç”šè‡³ä¼˜äºå¤šæ¨¡æ€åŸºçº¿ï¼ŒåŒæ—¶æ— éœ€åœ¨éƒ¨ç½²é˜¶æ®µå¢åŠ è¾“å…¥æ•°æ®ï¼Œå¹¶é€šè¿‡åˆ†æä¸»ä»»åŠ¡ä¸è¾…åŠ©ä»»åŠ¡çš„è¯¯å·®ç›¸å…³æ€§ï¼Œæå‡äº†æ¨¡å‹è¡Œä¸ºçš„å†…åœ¨è§£é‡Šæ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="80-Intrinsic-Explainability-of-Multimodal-Learning-for-Crop-Yield-Prediction"><a href="#80-Intrinsic-Explainability-of-Multimodal-Learning-for-Crop-Yield-Prediction" class="headerlink" title="80. Intrinsic Explainability of Multimodal Learning for Crop Yield Prediction"></a>80. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Intrinsic_Explainability_of_Multimodal_Learning_for_Crop_Yield_Prediction.pdf">Intrinsic Explainability of Multimodal Learning for Crop Yield Prediction</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">RPTU Kaiserslautern-Landau</span></p>
<p>æœ¬æ–‡æå‡ºåŸºäºTransformerçš„å¤šæ¨¡æ€å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºä½œç‰©äº§é‡é¢„æµ‹ï¼Œèåˆå¤šæ—¶åºå«æ˜Ÿã€æ°”è±¡ã€åœŸå£¤å’Œåœ°å½¢ç­‰å››ç±»æ•°æ®ï¼Œå¹¶ç³»ç»Ÿæ€§æ¯”è¾ƒäº†Attention Rolloutï¼ˆARï¼‰ã€Generic Attentionï¼ˆGAï¼‰å’ŒShapley Value Samplingï¼ˆSVSï¼‰ä¸‰ç§ç‰¹å¾å½’å› æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTransformeråœ¨å­ç”°å—å’Œç”°å—å±‚é¢å‡ä¼˜äºå·ç§¯å’Œå¾ªç¯ç½‘ç»œï¼ŒARæ–¹æ³•å½’å› ç»“æœæ›´ç¨³å®šä¸”æ›´å…·ä¸€è‡´æ€§ï¼Œæ­ç¤ºå…³é”®ä½œç‰©ç”Ÿé•¿é˜¶æ®µä¸æ¨¡å‹å†³ç­–é«˜åº¦ç›¸å…³ã€‚æ¨¡å‹åœ¨å¤šåŒºåŸŸå¤šä½œç‰©æ•°æ®ä¸ŠéªŒè¯äº†è§£é‡Šæ€§æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼ŒåŒæ—¶æå‡ºçš„WMAæ–¹æ³•å¯¹å¤šæ¨¡æ€é‡è¦æ€§åˆ†ææ˜¾ç¤ºä¸Shapleyä¼°è®¡å­˜åœ¨è¾ƒå¤§å·®å¼‚ï¼Œéœ€è¿›ä¸€æ­¥ç ”ç©¶ã€‚ç»“è®ºè®¤ä¸ºï¼ŒTransformerå†…åœ¨å¯è§£é‡Šæ€§å’ŒARæ–¹æ³•èƒ½æå‡å¤šæ¨¡æ€ç½‘ç»œçš„é€æ˜åº¦ï¼Œæ¨åŠ¨å†œä¸šé¥æ„Ÿç­‰æ•°æ®å¯†é›†é¢†åŸŸçš„å¯è§£é‡ŠAIå‘å±•ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="81-eMotions-A-Large-Scale-Dataset-and-Audio-Visual-Fusion-Network-for-Emotion-Analysis-in-Short-form-Videos"><a href="#81-eMotions-A-Large-Scale-Dataset-and-Audio-Visual-Fusion-Network-for-Emotion-Analysis-in-Short-form-Videos" class="headerlink" title="81. eMotions: A Large-Scale Dataset and Audio-Visual Fusion Network for Emotion Analysis in Short-form Videos"></a>81. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/eMotions__A_Large-Scale_Dataset_and_Audio-Visual_Fusion_Network_for_Emotion_Analysis_in_Short-form_V.pdf">eMotions: A Large-Scale Dataset and Audio-Visual Fusion Network for Emotion Analysis in Short-form Videos</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Xiâ€™an Jiaotong University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†eMotionsâ€”â€”é¦–ä¸ªä¸“ä¸ºçŸ­è§†é¢‘æƒ…æ„Ÿåˆ†æçš„å¤§è§„æ¨¡æ•°æ®é›†ï¼ŒåŒ…å«27,996ä¸ªè§†é¢‘å¹¶é…æœ‰å…­ç§æƒ…ç»ªæ ‡ç­¾ï¼ŒåŒæ—¶å‘å¸ƒäº†AV-CANetæ¨¡å‹ï¼ˆåŸºäºVideo Swin-Transformerå’ŒResNet34ï¼‰å®ç°éŸ³è§†é¢‘ç‰¹å¾èåˆï¼Œé€šè¿‡è®¾è®¡Local-Global Fusionæ¨¡å—å’ŒEP-CEæŸå¤±å‡½æ•°æå‡æƒ…æ„Ÿè¯†åˆ«æ€§èƒ½ã€‚å®éªŒè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†å’Œå…¬å¼€æ•°æ®é›†ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶ä¸ºæœªæ¥çŸ­è§†é¢‘æƒ…æ„Ÿåˆ†æç ”ç©¶æä¾›äº†åŸºç¡€ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="82-VSI-Visualâ€“Subtitle-Integration-for-Keyframe-Selection-to-Enhance-Long-Video-Understanding"><a href="#82-VSI-Visualâ€“Subtitle-Integration-for-Keyframe-Selection-to-Enhance-Long-Video-Understanding" class="headerlink" title="82. VSI: Visualâ€“Subtitle Integration for Keyframe Selection to Enhance Long Video Understanding"></a>82. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/VSI__Visual_Subtitle_Integration_for_Keyframe_Selection_to_enhance_Long_Video_Understanding.pdf">VSI: Visualâ€“Subtitle Integration for Keyframe Selection to Enhance Long Video Understanding</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">HKUST(GZ)</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†VISUAL-SUBTITLE INTEGRATION (VSI)æ–¹æ³•ï¼Œé€šè¿‡è§†è§‰å¯¹è±¡æ£€æµ‹å’Œå­—å¹•è¯­ä¹‰åŒ¹é…çš„åŒæµèåˆæœºåˆ¶ï¼Œå®ç°é•¿è§†é¢‘å…³é”®å¸§æ£€ç´¢ã€‚è¯¥æ–¹æ³•æ— éœ€é¢å¤–è®­ç»ƒï¼Œèƒ½é«˜æ•ˆæ•´åˆè§†è§‰ä¸æ–‡æœ¬ä¿¡æ¯ï¼Œæå‡å…³é”®å¸§å®šä½å’Œé•¿è§†é¢‘é—®ç­”å‡†ç¡®ç‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒVSIåœ¨LONGVIDEOBENCHæ•°æ®é›†ä¸Šå…³é”®å¸§æ£€ç´¢å’Œè§†é¢‘é—®ç­”ä»»åŠ¡å‡å–å¾—äº†é¢†å…ˆæ€§èƒ½ï¼Œå…·å¤‡è‰¯å¥½é€šç”¨æ€§å’Œå¯æ‰©å±•æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="83-Low-Rank-Expert-Merging-for-Multi-Source-Domain-Adaptation-in-Person-Re-Identification"><a href="#83-Low-Rank-Expert-Merging-for-Multi-Source-Domain-Adaptation-in-Person-Re-Identification" class="headerlink" title="83. Low-Rank Expert Merging for Multi-Source Domain Adaptation in Person Re-Identification"></a>83. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Low-Rank_Expert_Merging_for_Multi-Source_Domain_Adaptation_in_Person_Re-Identification.pdf">Low-Rank Expert Merging for Multi-Source Domain Adaptation in Person Re-Identification</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">ETS Montreal</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†SAGE-reIDï¼Œä¸€ç§æ— éœ€æºæ•°æ®çš„å¤šæºåŸŸè‡ªé€‚åº”æ–¹æ³•ï¼Œä¸“ä¸ºè¡Œäººå†è¯†åˆ«ä»»åŠ¡è®¾è®¡ã€‚æ–¹æ³•åŒ…æ‹¬ä¸¤é˜¶æ®µæµç¨‹ï¼šé¦–å…ˆå¯¹æ¯ä¸ªæºåŸŸæ¨¡å‹ä»…å¾®è°ƒä½ç§©é€‚é…å™¨ï¼ˆLoRAï¼‰ï¼Œç„¶åé€šè¿‡è½»é‡çº§é—¨æ§ç½‘ç»œåŠ¨æ€èåˆå¤šä¸ªLoRAä¸“å®¶ä»¥å®ç°è·¨åŸŸçŸ¥è¯†è¿ç§»ã€‚å®éªŒåœ¨Market-1501ã€DukeMTMC-reIDå’ŒMSMT17ç­‰åŸºå‡†æ•°æ®é›†ä¸Šæ˜¾ç¤ºï¼ŒSAGE-reIDåœ¨å‡†ç¡®æ€§å’Œè®¡ç®—æ•ˆç‡ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ç»“è®ºï¼šSAGE-reIDå¯é«˜æ•ˆå®ç°å¤šæºçŸ¥è¯†èåˆï¼Œæå‡è·¨åŸŸè¡Œäººè¯†åˆ«è¡¨ç°ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="84-Dual-Resolution-Residual-Architecture-with-Artifact-Suppression-for-Melanocytic-Lesion-Segmentation"><a href="#84-Dual-Resolution-Residual-Architecture-with-Artifact-Suppression-for-Melanocytic-Lesion-Segmentation" class="headerlink" title="84. Dual-Resolution Residual Architecture with Artifact Suppression for Melanocytic Lesion Segmentation"></a>84. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/DualResolution_Residual_Architecture_with_Artifact_Suppression_for_Melanocytic_Lesion_Segmentation.pdf">Dual-Resolution Residual Architecture with Artifact Suppression for Melanocytic Lesion Segmentation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">SNAIT Research</span></p>
<p>è¯¥è®ºæ–‡æå‡ºä¸€ç§é’ˆå¯¹çš®è‚¤é•œå›¾åƒä¸­é»‘è‰²ç´ ç˜¤ç—…å˜åˆ†å‰²çš„æ–°å‹ResNeté£æ ¼åŒåˆ†è¾¨ç‡æ¶æ„ï¼ŒåŒ…æ‹¬é«˜åˆ†è¾¨ç‡è¾¹ç•Œæµå’Œå¤šå°ºåº¦ä¸Šä¸‹æ–‡æµï¼Œç»“åˆè¾¹ç•Œæ„ŸçŸ¥æ®‹å·®è¿æ¥ã€é€šé“æ³¨æ„åŠ›å’Œè½»é‡ä¼ªå½±æŠ‘åˆ¶æ¨¡å—ï¼Œå¹¶é‡‡ç”¨Diceâ€“Tverskyåˆ†å‰²æŸå¤±ã€è¾¹ç•ŒæŸå¤±å’Œå¯¹æ¯”æ­£åˆ™åŒ–çš„å¤šä»»åŠ¡è®­ç»ƒç›®æ ‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å…¬å¼€æ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†åˆ†å‰²ç²¾åº¦å’Œè¾¹ç•Œè´´åˆåº¦ï¼Œä¼˜äºå¸¸è§„ç¼–ç å™¨-è§£ç å™¨åŸºçº¿ï¼Œæœ‰åŠ©äºè‡ªåŠ¨åŒ–çš®è‚¤ç™Œè¯„ä¼°ç³»ç»Ÿã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="85-Hardness-Aware-Dynamic-Curriculum-Learning-for-Robust-Multimodal-Emotion-Recognition-with-Missing-Modalities"><a href="#85-Hardness-Aware-Dynamic-Curriculum-Learning-for-Robust-Multimodal-Emotion-Recognition-with-Missing-Modalities" class="headerlink" title="85. Hardness-Aware Dynamic Curriculum Learning for Robust Multimodal Emotion Recognition with Missing Modalities"></a>85. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Hardness-Aware_Dynamic_Curriculum_Learning_for_Robust_Multimodal_Emotion_Recognition_with_Missing_Mo.pdf">Hardness-Aware Dynamic Curriculum Learning for Robust Multimodal Emotion Recognition with Missing Modalities</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Inner Mongolia University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†HARDY-MERæ¡†æ¶ï¼Œé€šè¿‡å¤šè§†è§’éš¾åº¦è¯„ä¼°ï¼ˆç»“åˆæ¨¡æ€é‡å»ºè¯¯å·®ä¸è·¨æ¨¡æ€äº’ä¿¡æ¯ï¼‰é‡åŒ–æ ·æœ¬éš¾åº¦ï¼Œå¹¶åˆ©ç”¨æ£€ç´¢å¢å¼ºåŠ¨æ€è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ä¸ºé«˜éš¾åº¦æ ·æœ¬æ£€ç´¢è¯­ä¹‰ç›¸å…³æ”¯æŒæ ·æœ¬ï¼ŒåŠ¨æ€è°ƒæ•´è®­ç»ƒé‡ç‚¹ï¼Œä»è€Œæå‡æ¨¡å‹åœ¨ç¼ºå¤±æ¨¡æ€ä¸‹çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨IEMOCAPå’ŒCMU-MOSEIç­‰åŸºå‡†æ•°æ®é›†çš„å¤šç§ç¼ºå¤±æ¨¡æ€è®¾å®šä¸‹å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="86-SafePLUG-Empowering-Multimodal-LLMs-with-Pixel-Level-Insight-and-Temporal-Grounding-for-Traffic-Accident-Understanding"><a href="#86-SafePLUG-Empowering-Multimodal-LLMs-with-Pixel-Level-Insight-and-Temporal-Grounding-for-Traffic-Accident-Understanding" class="headerlink" title="86. SafePLUG: Empowering Multimodal LLMs with Pixel-Level Insight and Temporal Grounding for Traffic Accident Understanding"></a>86. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/SafePLUG__Empowering_Multimodal_LLMs_with_Pixel-Level_Insight_and_Temporal_Grounding_for_Traffic_Acc.pdf">SafePLUG: Empowering Multimodal LLMs with Pixel-Level Insight and Temporal Grounding for Traffic Accident Understanding</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Wisconsinâ€“Madison</span></p>
<p>SafePLUGæå‡ºäº†ä¸€ç§å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æ¡†æ¶ï¼Œç»“åˆè§†è§‰æç¤ºç¼–ç å™¨ä¸SAMåŸºç¡€çš„åƒç´ çº§åˆ†å‰²è§£ç å™¨ï¼Œå®ç°äº¤é€šäº‹æ•…çš„åŒºåŸŸæ„ŸçŸ¥ã€åƒç´ çº§ç†è§£å’ŒåŸºäºæ•°å­—æ ‡è®°çš„æ—¶åºå®šä½ã€‚é€šè¿‡æ„å»ºå¤šæ¨¡æ€é—®ç­”æ•°æ®é›†ï¼ŒSafePLUGåœ¨åŒºåŸŸé—®ç­”ã€åƒç´ åˆ†å‰²ã€äº‹æ•…æè¿°ä¸æ—¶åºå®šä½ç­‰ä»»åŠ¡ä¸Šå‡è¶…è¶Šç°æœ‰æ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†å¤æ‚äº¤é€šåœºæ™¯ä¸‹çš„ç»†ç²’åº¦ç†è§£èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="87-FoundBioNet-A-Foundation-Based-Model-for-IDH-Genotyping-of-Glioma-from-Multi-Parametric-MRI"><a href="#87-FoundBioNet-A-Foundation-Based-Model-for-IDH-Genotyping-of-Glioma-from-Multi-Parametric-MRI" class="headerlink" title="87. FoundBioNet: A Foundation-Based Model for IDH Genotyping of Glioma from Multi-Parametric MRI"></a>87. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/FoundBioNet__A_Foundation-Based_Model_for_IDH_Genotyping_of_Glioma_from_Multi-Parametric_MRI.pdf">FoundBioNet: A Foundation-Based Model for IDH Genotyping of Glioma from Multi-Parametric MRI</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Tehran University of Medical Sciences</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºç¡€æ¨¡å‹FoundBioNetï¼ŒåŸºäºSWIN-UNETRæ¶æ„ï¼Œç»“åˆè‚¿ç˜¤æ„ŸçŸ¥ç‰¹å¾ç¼–ç ï¼ˆTAFEï¼‰å’Œè·¨æ¨¡æ€å·®å¼‚ï¼ˆCMDï¼‰æ¨¡å—ï¼Œä»å¤šå‚æ•°MRIä¸­æ— åˆ›é¢„æµ‹èƒ¶è´¨ç˜¤IDHçªå˜çŠ¶æ€ã€‚æ¨¡å‹åœ¨å…­ä¸ªå¤šä¸­å¿ƒå…¬å¼€æ•°æ®é›†ä¸Šè®­ç»ƒï¼Œè¡¨ç°å‡ºè¾ƒå¼ºæ³›åŒ–èƒ½åŠ›ï¼ŒAUCæœ€é«˜è¾¾90.58%ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿå·ç§¯å’ŒTransformeråŸºçº¿æ–¹æ³•ï¼Œç»“æœå…·å¤‡è¾ƒé«˜å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ï¼Œæœ‰æœ›ç”¨äºä¸´åºŠä¸ªä½“åŒ–ç®¡ç†ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="88-FormCoach-Lift-Smarter-Not-Harder"><a href="#88-FormCoach-Lift-Smarter-Not-Harder" class="headerlink" title="88. FormCoach: Lift Smarter, Not Harder"></a>88. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/FormCoach__Lift_Smarter,_Not_Harder.pdf">FormCoach: Lift Smarter, Not Harder</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Pennsylvania</span></p>
<p>FormCoachæå‡ºäº†ä¸€ç§åŸºäºè§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰çš„å®æ—¶AIå¥èº«æ•™ç»ƒç³»ç»Ÿï¼Œåˆ©ç”¨æ‘„åƒå¤´å¯¹ç”¨æˆ·åŠ¨ä½œä¸ä¸“å®¶å‚è€ƒè§†é¢‘è¿›è¡Œå¯¹æ¯”åˆ†æï¼Œç”Ÿæˆä¸ªæ€§åŒ–ã€ç®€æ˜çš„åŠ¨ä½œçº æ­£å»ºè®®ã€‚ä½œè€…æ„å»ºå¹¶å…¬å¼€äº†åŒ…å«1,700ç»„ä¸“å®¶æ ‡æ³¨è§†é¢‘å¯¹çš„æ•°æ®é›†ï¼Œç³»ç»Ÿæ€§è¯„æµ‹äº†å¤šç§ä¸»æµVLMæ¨¡å‹åœ¨äººä½“è¿åŠ¨å·®å¼‚åˆ†æä¸åé¦ˆç”Ÿæˆä¸Šçš„æ€§èƒ½ã€‚å®éªŒå‘ç°ï¼ŒVLMsåœ¨è¡ŒåŠ¨æŒ‡å¯¼æ€§ä¸Šè¡¨ç°è‰¯å¥½ä½†åœ¨å‡†ç¡®è¯†åˆ«ç»†å¾®åŠ¨ä½œå¤±è¯¯ä¸Šä»æœ‰è¾ƒå¤§æå‡ç©ºé—´ï¼Œç°æœ‰æ¨¡å‹æ˜“å‡ºç°é—æ¼æˆ–å¹»è§‰åé¦ˆã€‚ç»“è®ºè®¤ä¸ºï¼Œè¯¥å·¥ä½œæ¨åŠ¨äº†AIå¥èº«è¾…å¯¼è¿ˆå‘äº’åŠ¨ã€ç²¾å‡†å’Œå¤šæ¨¡æ€èåˆçš„æ–°æ–¹å‘ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="89-VisR-Bench-An-Empirical-Study-on-Visual-Retrieval-Augmented-Generation-for-Multilingual-Long-Document-Understanding"><a href="#89-VisR-Bench-An-Empirical-Study-on-Visual-Retrieval-Augmented-Generation-for-Multilingual-Long-Document-Understanding" class="headerlink" title="89. VisR-Bench: An Empirical Study on Visual Retrieval-Augmented Generation for Multilingual Long Document Understanding"></a>89. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/VisR-Bench__An_Empirical_Study_on_Visual_Retrieval-Augmented_Generation_for_Multilingual_Long_Docume.pdf">VisR-Bench: An Empirical Study on Visual Retrieval-Augmented Generation for Multilingual Long Document Understanding</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University at Buffalo</span></p>
<p>æœ¬æ–‡æå‡ºäº†VisR-Benchï¼Œè¿™æ˜¯é¦–ä¸ªé¢å‘å¤šè¯­è¨€é•¿æ–‡æ¡£çš„è§†è§‰æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰åŸºå‡†ï¼Œæ¶µç›–16ç§è¯­è¨€ã€1,286ä»½å¤šæ¨¡æ€æ–‡æ¡£å’Œ35,000+é«˜è´¨é‡é—®ç­”å¯¹ï¼Œæ”¯æŒæ–‡æœ¬ã€è¡¨æ ¼å’Œå›¾åƒå¤šè¯æ®ç±»å‹çš„ç»†ç²’åº¦è¯„æµ‹ã€‚ç³»ç»Ÿæ€§å®éªŒæ¯”è¾ƒäº†æ–‡æœ¬æ£€ç´¢ã€å¤šæ¨¡æ€ç¼–ç å™¨å’Œå¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆMLLMsï¼‰ï¼Œç»“æœæ˜¾ç¤ºMLLMsåœ¨æ£€ç´¢ä»»åŠ¡ä¸Šä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œä½†åœ¨ç»“æ„åŒ–è¡¨æ ¼å†…å®¹å’Œä½èµ„æºè¯­è¨€ä¸Šè¡¨ç°ä»æœ‰é™ï¼Œæ­ç¤ºäº†å¤šè¯­è¨€å¤šæ¨¡æ€æ£€ç´¢çš„å…³é”®æŒ‘æˆ˜ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="90-Noise-Aware-Generative-Microscopic-Traffic-Simulation"><a href="#90-Noise-Aware-Generative-Microscopic-Traffic-Simulation" class="headerlink" title="90. Noise-Aware Generative Microscopic Traffic Simulation"></a>90. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Noise-Aware_Generative_Microscopic_Traffic_Simulation.pdf">Noise-Aware Generative Microscopic Traffic Simulation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Massachusetts Institute of Technology</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†I-24 MOTION Scenario Dataset (I24-MSD)ï¼Œä¿ç•™åŸºç¡€è®¾æ–½æ‘„åƒå¤´é‡‡é›†çš„äº¤é€šè½¨è¿¹ä¸­çš„çœŸå®å™ªå£°ï¼Œå¹¶å°†å…¶ä½œä¸ºå­¦ä¹ é—®é¢˜çš„ä¸€éƒ¨åˆ†ã€‚ä½œè€…åŸºäºè¯¥æ•°æ®é›†ï¼Œä½¿ç”¨GPTé£æ ¼çš„Transformeræ¨¡å‹ï¼ˆSMARTï¼‰ï¼Œå¹¶å¼•å…¥äº†æ ‡ç­¾å¹³æ»‘ã€focal losså’Œå¯¹ç§°äº¤å‰ç†µç­‰å™ªå£°æ„ŸçŸ¥æŸå¤±å‡½æ•°ä»¥æå‡æ¨¡å‹åœ¨å™ªå£°ç¯å¢ƒä¸‹çš„ç”Ÿæˆæ•ˆæœã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå™ªå£°æ„ŸçŸ¥ä¼˜åŒ–æ˜¾è‘—æå‡äº†å¾®è§‚äº¤é€šä»¿çœŸçš„çœŸå®åº¦å’Œé²æ£’æ€§ã€‚ç»“è®ºè®¤ä¸ºï¼Œæ˜¾å¼å»ºæ¨¡æ•°æ®å™ªå£°å¯æå‡ä»¿çœŸè´¨é‡ï¼Œå¹¶ä¿ƒè¿›æ™ºèƒ½äº¤é€šç³»ç»Ÿç ”ç©¶ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="91-CLUE-Leveraging-Low-Rank-Adaptation-to-Capture-Latent-Uncovered-Evidence-for-Image-Forgery-Localization"><a href="#91-CLUE-Leveraging-Low-Rank-Adaptation-to-Capture-Latent-Uncovered-Evidence-for-Image-Forgery-Localization" class="headerlink" title="91. CLUE: Leveraging Low-Rank Adaptation to Capture Latent Uncovered Evidence for Image Forgery Localization"></a>91. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/CLUE__Leveraging_Low-Rank_Adaptation_to_Capture_Latent_Uncovered_Evidence_for_Image_Forgery_Localiza.pdf">CLUE: Leveraging Low-Rank Adaptation to Capture Latent Uncovered Evidence for Image Forgery Localization</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Shenzhen University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†CLUEæ¡†æ¶ï¼Œé€šè¿‡ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰å¯¹Stable Diffusion 3ï¼ˆSD3ï¼‰å’ŒSegment Anything Modelï¼ˆSAMï¼‰è¿›è¡Œå‚æ•°é«˜æ•ˆçš„è”åˆå¾®è°ƒï¼Œåˆ©ç”¨SD3çš„Rectified Flowå™ªå£°æœºåˆ¶åœ¨æ½œç©ºé—´æ”¾å¤§ä¼ªé€ åŒºåŸŸçš„å¾®å¼±ç‰¹å¾ï¼Œå¹¶èåˆSAMå›¾åƒç¼–ç å™¨çš„ç©ºé—´è¯­ä¹‰çº¿ç´¢ï¼Œå®ç°ç²¾ç¡®çš„ä¼ªé€ åŒºåŸŸå®šä½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCLUEåœ¨å¤šç§å…¬å¼€æ•°æ®é›†ä¸Šçš„ä¼ªé€ å®šä½è¡¨ç°å’Œå¯¹åå¤„ç†æ”»å‡»çš„é²æ£’æ€§å‡æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå…·å¤‡ä¼˜å¼‚çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="92-VA-Blueprint-Uncovering-Building-Blocks-for-Visual-Analytics-System-Design"><a href="#92-VA-Blueprint-Uncovering-Building-Blocks-for-Visual-Analytics-System-Design" class="headerlink" title="92. VA-Blueprint: Uncovering Building Blocks for Visual Analytics System Design"></a>92. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/VA-Blueprint__Uncovering_Building_Blocks_for_Visual_Analytics_System_Design.pdf">VA-Blueprint: Uncovering Building Blocks for Visual Analytics System Design</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Illinois Chicago</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€å¥—ç³»ç»Ÿæ–¹æ³•ï¼ˆVA-Blueprintï¼‰ï¼Œé€šè¿‡äººå·¥å’Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¾…åŠ©ï¼Œä»101ç¯‡åŸå¸‚è§†è§‰åˆ†æï¼ˆVAï¼‰ç³»ç»Ÿè®ºæ–‡ä¸­è‡ªåŠ¨æŠ½å–ã€å½’ç±»å¹¶ç»“æ„åŒ–ç³»ç»Ÿç»„ä»¶ã€æ“ä½œå’Œä¾èµ–ï¼Œå½¢æˆå¤šå±‚æ¬¡ã€å¯æŸ¥è¯¢çš„çŸ¥è¯†åº“ã€‚ç»“è®ºè¡¨æ˜ï¼ŒVA-Blueprintèƒ½å¤Ÿæ­ç¤ºVAç³»ç»Ÿé€šç”¨è®¾è®¡æ¨¡å¼å’Œæ¼”åŒ–è¶‹åŠ¿ï¼Œæå‡ç³»ç»Ÿå¤ç”¨æ€§ä¸å¼€å‘æ•ˆç‡ï¼ŒåŒæ—¶ä¸“å®¶è¯„ä¼°éªŒè¯äº†æ–¹æ³•çš„å‡†ç¡®æ€§å’Œå®ç”¨æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="93-ForensicsSAM-Toward-Robust-and-Unified-Image-Forgery-Detection-and-Localization-Resisting-to-Adversarial-Attack"><a href="#93-ForensicsSAM-Toward-Robust-and-Unified-Image-Forgery-Detection-and-Localization-Resisting-to-Adversarial-Attack" class="headerlink" title="93. ForensicsSAM: Toward Robust and Unified Image Forgery Detection and Localization Resisting to Adversarial Attack"></a>93. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/ForensicsSAM__Toward_Robust_and_Unified_Image_Forgery_Detection_and_Localization_Resisting_to_Advers.pdf">ForensicsSAM: Toward Robust and Unified Image Forgery Detection and Localization Resisting to Adversarial Attack</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Shenzhen University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºForensicsSAMï¼Œä¸€ç§é¢å‘å›¾åƒç¯¡æ”¹æ£€æµ‹ä¸å®šä½çš„ç»Ÿä¸€æ¡†æ¶ï¼Œå…·æœ‰å†…ç½®çš„å¯¹æŠ—é²æ£’æ€§ã€‚æ–¹æ³•é€šè¿‡åœ¨SAMä¸»å¹²çš„æ¯ä¸ªtransformer blockä¸­æ³¨å…¥å…±äº«çš„forgery expertsæå‡ç¯¡æ”¹ç‰¹å¾æå–èƒ½åŠ›ï¼Œå¹¶è®¾è®¡è½»é‡çº§adversary detectorè¯†åˆ«å¯¹æŠ—æ ·æœ¬ï¼Œå†åˆ©ç”¨è‡ªé€‚åº”adversary expertså¯¹ç‰¹å¾æ¼‚ç§»è¿›è¡Œä¿®æ­£ï¼Œä¸‰é˜¶æ®µè®­ç»ƒå®ç°å¯¹å¹²å‡€ä¸å¯¹æŠ—å›¾åƒçš„ç‹¬ç«‹ä¼˜åŒ–ã€‚å®éªŒè¡¨æ˜ï¼ŒForensicsSAMåœ¨å¤šç§æ•°æ®é›†ä¸å¯¹æŠ—æ”»å‡»ä¸‹å‡è¾¾åˆ°äº†å›¾åƒçº§æ£€æµ‹å’Œåƒç´ çº§å®šä½çš„æœ€æ–°æ€§èƒ½å’Œé²æ£’æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="94-Tight-Bounds-for-Schrodinger-Potential-Estimation-in-Unpaired-Image-to-Image-Translation-Problems"><a href="#94-Tight-Bounds-for-Schrodinger-Potential-Estimation-in-Unpaired-Image-to-Image-Translation-Problems" class="headerlink" title="94. Tight Bounds for SchrÃ¶dinger Potential Estimation in Unpaired Image-to-Image Translation Problems"></a>94. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Tight_Bounds_for_Schr%C3%B6dinger_Potential_Estimation_in_Unpaired_Image-to-Image_Translation_Problems.pdf">Tight Bounds for SchrÃ¶dinger Potential Estimation in Unpaired Image-to-Image Translation Problems</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">HSE University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºOrnstein-Uhlenbeckè¿‡ç¨‹çš„SchrÃ¶dingeræ¡¥ç†è®ºï¼Œç”¨äºæ— é…å¯¹çš„å›¾åƒåˆ°å›¾åƒè½¬æ¢é—®é¢˜ï¼Œé€šè¿‡ä¼˜åŒ–ç»éªŒé£é™©æœ€å°åŒ–å™¨ä¼°è®¡SchrÃ¶dingeræ½œåŠ›ï¼Œå¹¶é¦–æ¬¡ç»™å‡ºäº†è¯¥æ–¹æ³•åœ¨æœ‰é™æ ·æœ¬ä¸‹çš„éæ¸è¿‘é«˜æ¦‚ç‡æ³›åŒ–è¯¯å·®ç•Œã€‚å®éªŒè¯æ˜è¯¥ç†è®ºåœ¨ç”Ÿæˆå»ºæ¨¡å’Œé£æ ¼è¿ç§»ä»»åŠ¡ä¸­å…·æœ‰æ›´å¿«çš„æ”¶æ•›é€Ÿåº¦å’Œæ›´å¥½çš„æ€§èƒ½ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="95-Invert4TVG-A-Temporal-Video-Grounding-Framework-with-Inversion-Tasks-for-Enhanced-Action-Understanding"><a href="#95-Invert4TVG-A-Temporal-Video-Grounding-Framework-with-Inversion-Tasks-for-Enhanced-Action-Understanding" class="headerlink" title="95. Invert4TVG: A Temporal Video Grounding Framework with Inversion Tasks for Enhanced Action Understanding"></a>95. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Invert4TVG__A_Temporal_Video_Grounding_Framework_with_Inversion_Tasks_for_Enhanced_Action_Understand.pdf">Invert4TVG: A Temporal Video Grounding Framework with Inversion Tasks for Enhanced Action Understanding</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Xiamen University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºInvert4TVGæ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥ä¸‰ç§åè½¬ä»»åŠ¡ï¼ˆåŠ¨è¯è¡¥å…¨ã€åŠ¨ä½œè¯†åˆ«ã€è§†é¢‘æè¿°ï¼‰ï¼Œåˆ©ç”¨TVGåŸå§‹æ ‡æ³¨ï¼Œåœ¨ä¸ä¾èµ–é¢å¤–æ•°æ®çš„å‰æä¸‹æå‡æ¨¡å‹å¯¹è§†é¢‘åŠ¨ä½œè¯­ä¹‰çš„ç†è§£ã€‚æ–¹æ³•å°†TVGä¸Invert-TVGå¤šä»»åŠ¡æ•´åˆè¿›å¼ºåŒ–å­¦ä¹ è®­ç»ƒæµç¨‹ï¼Œé€šè¿‡åŠ¨æ€é‡‡æ ·å’Œä¸“é—¨å¥–åŠ±è®¾è®¡ï¼Œå…¼é¡¾å®šä½ç²¾åº¦ä¸åŠ¨ä½œç†è§£ï¼Œå®éªŒåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œè¡¨æ˜å¢å¼ºåŠ¨ä½œè¯­ä¹‰å¯¹æå‡æ—¶åºè§†é¢‘å®šä½ä¸Šé™å…·æœ‰å…³é”®ä½œç”¨ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="96-KLASSify-to-Verify-Audio-Visual-Deepfake-Detection-Using-SSL-based-Audio-and-Handcrafted-Visual-Features"><a href="#96-KLASSify-to-Verify-Audio-Visual-Deepfake-Detection-Using-SSL-based-Audio-and-Handcrafted-Visual-Features" class="headerlink" title="96. KLASSify to Verify: Audio-Visual Deepfake Detection Using SSL-based Audio and Handcrafted Visual Features"></a>96. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/KLASSify_to_Verify__Audio-Visual_Deepfake_Detection_Using_SSL-based_Audio_and_Handcrafted_Visual_Fea.pdf">KLASSify to Verify: Audio-Visual Deepfake Detection Using SSL-based Audio and Handcrafted Visual Features</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">KLASS Engineering and Solutions</span></p>
<p>æœ¬æ–‡æå‡ºKLASSifyç³»ç»Ÿï¼Œé€šè¿‡æ‰‹å·¥è§†è§‰ç‰¹å¾ä¸åŸºäºè‡ªç›‘ç£å­¦ä¹ çš„éŸ³é¢‘ç‰¹å¾ï¼Œç»“åˆå›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆGATï¼‰ä¸æ—¶åºå·ç§¯ç½‘ç»œï¼ˆTCNï¼‰ï¼Œå®ç°éŸ³è§†é¢‘å¤šæ¨¡æ€æ·±åº¦ä¼ªé€ æ£€æµ‹ä¸å®šä½ã€‚æ–¹æ³•åœ¨AV-Deepfake1M++æ•°æ®é›†ä¸Šï¼Œåˆ†ç±»ä»»åŠ¡AUCè¾¾92.78%ï¼ŒéŸ³é¢‘å®šä½IoUè¾¾0.3536ï¼Œå±•ç°äº†é«˜æ•ˆã€é²æ£’ä¸”å¯è§£é‡Šçš„æ€§èƒ½ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="97-RORPCap-Retrieval-based-Objects-and-Relations-Prompt-for-Image-Captioning"><a href="#97-RORPCap-Retrieval-based-Objects-and-Relations-Prompt-for-Image-Captioning" class="headerlink" title="97. RORPCap: Retrieval-based Objects and Relations Prompt for Image Captioning"></a>97. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/RORPCap__Retrieval-based_Objects_and_Relations_Prompt_for_Image_Captioning.pdf">RORPCap: Retrieval-based Objects and Relations Prompt for Image Captioning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Yunnan University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å›¾åƒæè¿°æ–¹æ³•RORPCapï¼Œé€šè¿‡è®¾è®¡çš„å¯¹è±¡ä¸å…³ç³»æŠ½å–æ¨¡å—ï¼ˆOREMï¼‰ä»æ£€ç´¢åˆ°çš„ç›¸ä¼¼æè¿°å¥ä¸­æå–å…³é”®å¯¹è±¡å’Œå…³ç³»è¯ï¼Œå¡«å……åˆ°æ¨¡æ¿å½¢æˆpromptï¼Œå¹¶ç»“åˆCLIPè§†è§‰ç‰¹å¾ç»è¿‡Mambaæ˜ å°„ç½‘ç»œè½¬åŒ–ä¸ºè§†è§‰-æ–‡æœ¬ç‰¹å¾ï¼Œå†ä¸promptæ‹¼æ¥åè¾“å…¥GPT-2ç”Ÿæˆæè¿°ã€‚å®éªŒè¡¨æ˜ï¼ŒRORPCapåœ¨MS-COCOç­‰æ•°æ®é›†ä¸Šå®ç°äº†ä¸ä¸»æµæ£€æµ‹å™¨å’ŒGCNæ–¹æ³•å¯æ¯”çš„æè¿°è´¨é‡ï¼Œä½†è®­ç»ƒæ—¶é—´æ˜¾è‘—ç¼©çŸ­ï¼Œä»…éœ€2.6å°æ—¶ï¼Œå…·å¤‡è‰¯å¥½é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½æœ‰æ•ˆé™ä½è®­ç»ƒæˆæœ¬ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="98-BEVANet-Bilateral-Efficient-Visual-Attention-Network-for-Real-Time-Semantic-Segmentation"><a href="#98-BEVANet-Bilateral-Efficient-Visual-Attention-Network-for-Real-Time-Semantic-Segmentation" class="headerlink" title="98. BEVANet: Bilateral Efficient Visual Attention Network for Real-Time Semantic Segmentation"></a>98. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/BEVANet__Bilateral_Efficient_Visual_Attention_Network_for_Real-Time_Semantic_Segmentation.pdf">BEVANet: Bilateral Efficient Visual Attention Network for Real-Time Semantic Segmentation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">National Taiwan University</span></p>
<p>BEVANetæå‡ºäº†ä¸€ç§åŒåˆ†æ”¯é«˜æ•ˆè§†è§‰æ³¨æ„åŠ›ç½‘ç»œï¼Œç»“åˆSparse Decomposed Large Separable Kernel Attentions (SDLSKA)ã€Comprehensive Kernel Selection (CKS)å’ŒDeep Large Kernel Pyramid Pooling Module (DLKPPM)ï¼Œå®ç°äº†å¤§æ„Ÿå—é‡è¯­ä¹‰ç†è§£ä¸ç²¾ç»†è½®å»“åˆ†å‰²ã€‚å…¶åˆ›æ–°çš„æ³¨æ„åŠ›æœºåˆ¶å’Œè¾¹ç•Œå¼•å¯¼è‡ªé€‚åº”èåˆæ¨¡å—å®ç°äº†åœ¨Cityscapeså’ŒCamVidæ•°æ®é›†ä¸Šçš„å®æ—¶è¯­ä¹‰åˆ†å‰²ï¼Œè¾¾åˆ°äº†81.0% mIoUå’Œ33 FPSçš„ä¼˜å¼‚æ€§èƒ½ï¼Œæ˜¾è‘—æå‡äº†åˆ†å‰²ç²¾åº¦ä¸æ•ˆç‡ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="99-Understanding-Dynamic-Scenes-in-Ego-Centric-4D-Point-Clouds"><a href="#99-Understanding-Dynamic-Scenes-in-Ego-Centric-4D-Point-Clouds" class="headerlink" title="99. Understanding Dynamic Scenes in Ego Centric 4D Point Clouds"></a>99. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Understanding_Dynamic_Scenes_in_Ego_Centric_4D_Point_Clouds.pdf">Understanding Dynamic Scenes in Ego Centric 4D Point Clouds</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Zhejiang University</span></p>
<p>æœ¬æ–‡æå‡ºEgoDynamic4DåŸºå‡†ï¼Œæ¶µç›–927Ké—®ç­”å¯¹å’Œ12ç±»ä»»åŠ¡ï¼Œé›†æˆRGB-Dè§†é¢‘ã€ç›¸æœºå§¿æ€ã€å…¨å±€å®ä¾‹æ©ç å’Œ4DåŒ…å›´ç›’ï¼Œå®ç°é«˜å¯†åº¦åŠ¨æ€åœºæ™¯æ³¨é‡Šã€‚ä½œè€…æå‡ºç«¯åˆ°ç«¯æ—¶ç©ºæ¨ç†æ¡†æ¶ï¼Œé€šè¿‡å®ä¾‹æ„ŸçŸ¥ç‰¹å¾ç¼–ç ã€æ—¶é—´ä¸ç›¸æœºåµŒå…¥å’Œè‡ªé€‚åº”ä¸‹é‡‡æ ·ï¼Œå°†å¤§è§„æ¨¡4Dåœºæ™¯å‹ç¼©ä¸ºLLMå¯å¤„ç†çš„åºåˆ—ï¼›å®éªŒè¡¨æ˜è¯¥æ–¹æ³•åœ¨å¤šæ¨¡æ€åŠ¨æ€åœºæ™¯ç†è§£ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿ï¼Œæ¨è¿›äº†è‡ªæˆ‘ä¸­å¿ƒåŠ¨æ€è§†è§‰ç†è§£çš„å‘å±•ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="100-HaDM-ST-Histology-Assisted-Differential-Modeling-for-Spatial-Transcriptomics-Generation"><a href="#100-HaDM-ST-Histology-Assisted-Differential-Modeling-for-Spatial-Transcriptomics-Generation" class="headerlink" title="100. HaDM-ST: Histology-Assisted Differential Modeling for Spatial Transcriptomics Generation"></a>100. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/HaDM-ST__Histology-Assisted_Differential_Modeling_for_Spatial_Transcriptomics_Generation.pdf">HaDM-ST: Histology-Assisted Differential Modeling for Spatial Transcriptomics Generation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Cambridge</span></p>
<p>æœ¬æ–‡æå‡ºäº†HaDM-STï¼Œä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„é«˜åˆ†è¾¨ç‡ç©ºé—´è½¬å½•ç»„å›¾åƒç”Ÿæˆæ¡†æ¶ï¼Œé€šè¿‡æ¡ä»¶åŒ–H&amp;Eç»„ç»‡åˆ‡ç‰‡å’Œä½åˆ†è¾¨ç‡STæ•°æ®ï¼Œå®ç°é«˜åˆ†è¾¨ç‡STå›¾åƒç”Ÿæˆã€‚æ–¹æ³•åˆ›æ–°åŒ…æ‹¬H&amp;Eé©±åŠ¨çš„è¯­ä¹‰è’¸é¦ç½‘ç»œã€è·¨æ¨¡æ€ç©ºé—´å¯¹é½æ¨¡å—ä»¥åŠåŸºäºå›¾ç¥ç»ç½‘ç»œçš„åŸºå› é€šé“åˆ¤åˆ«å­¦ä¹ ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒHaDM-STåœ¨ç©ºé—´ä¿çœŸåº¦å’ŒåŸºå› å±‚é¢è¡¨ç°ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸ºç²¾å‡†åŒ»ç–—å’Œç»„ç»‡åˆ†å­æœºåˆ¶ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="101-Unsupervised-Real-World-Super-Resolution-via-Rectified-Flow-Degradation-Modelling"><a href="#101-Unsupervised-Real-World-Super-Resolution-via-Rectified-Flow-Degradation-Modelling" class="headerlink" title="101. Unsupervised Real-World Super-Resolution via Rectified Flow Degradation Modelling"></a>101. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Unsupervised_Real-World_Super-Resolution_via_Rectified_Flow_Degradation_Modelling.pdf">Unsupervised Real-World Super-Resolution via Rectified Flow Degradation Modelling</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Science and Technology Beijing</span></p>
<p>æœ¬æ–‡æå‡ºäº†æ— ç›‘ç£çš„çœŸå®ä¸–ç•Œè¶…åˆ†è¾¨ç‡æ–¹æ³•ï¼Œæ ¸å¿ƒåœ¨äºå¼•å…¥Rectified Flow Degradation Module (RFDM)å’ŒFourier Prior Guided Degradation Module (FGDM)ã€‚RFDMé€šè¿‡å»ºæ¨¡é€€åŒ–è½¨è¿¹å®ç°å¯¹å¤æ‚çœŸå®é€€åŒ–çš„å»ºæ¨¡ï¼ŒFGDMåˆ©ç”¨å‚…é‡Œå¶ç›¸ä½ç»“æ„ä¿¡æ¯æå‡é€€åŒ–å»ºæ¨¡ç²¾åº¦ï¼ŒäºŒè€…ç»“åˆç”Ÿæˆé«˜ä»¿çœŸä½åˆ†è¾¨ç‡å›¾åƒä¸é«˜åˆ†è¾¨ç‡å›¾åƒå¯¹ï¼Œç”¨äºè®­ç»ƒä»»æ„è¶…åˆ†æ¨¡å‹ï¼Œå®éªŒè¯æ˜å¯¹çœŸå®åœºæ™¯çš„SRæ€§èƒ½æå‡æ˜¾è‘—ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="102-SODiff-Semantic-Oriented-Diffusion-Model-for-JPEG-Compression-Artifacts-Removal"><a href="#102-SODiff-Semantic-Oriented-Diffusion-Model-for-JPEG-Compression-Artifacts-Removal" class="headerlink" title="102. SODiff: Semantic-Oriented Diffusion Model for JPEG Compression Artifacts Removal"></a>102. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/SODiff__Semantic-Oriented_Diffusion_Model_for_JPEG_Compression_Artifacts_Removal.pdf">SODiff: Semantic-Oriented Diffusion Model for JPEG Compression Artifacts Removal</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Shanghai Jiao Tong Univercity</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†SODiffï¼Œä¸€ç§åŸºäºè¯­ä¹‰å¯¹é½çš„å›¾åƒæç¤ºæå–å™¨ï¼ˆSAIPEï¼‰å’Œè´¨é‡å› å­æ„ŸçŸ¥æ—¶é—´é¢„æµ‹å™¨çš„å•æ­¥æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºJPEGå‹ç¼©ä¼ªå½±å»é™¤ã€‚æ–¹æ³•é€šè¿‡æå–ä½è´¨é‡å›¾åƒçš„ä¸°å¯Œè¯­ä¹‰ç‰¹å¾å¹¶ä¸æ–‡æœ¬ç¼–ç å™¨å¯¹é½ï¼Œå®ç°é«˜æ•ˆçš„è¯­ä¹‰æŒ‡å¯¼æ‰©æ•£å»ä¼ªå½±ï¼ŒåŒæ—¶æ ¹æ®å‹ç¼©è´¨é‡è‡ªé€‚åº”é€‰æ‹©é™å™ªæ—¶åˆ»ã€‚å®éªŒç»“æœæ˜¾ç¤ºSODiffåœ¨å¤šä¸ªæ•°æ®é›†å’ŒæŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰ä¸»æµæ–¹æ³•ï¼Œå°¤å…¶åœ¨æç«¯å‹ç¼©æ¡ä»¶ä¸‹è¡¨ç°å‡ºè‰²ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="103-CoAR-Concept-Injection-into-Autoregressive-Models-for-Personalized-Text-to-Image-Generation"><a href="#103-CoAR-Concept-Injection-into-Autoregressive-Models-for-Personalized-Text-to-Image-Generation" class="headerlink" title="103. CoAR: Concept Injection into Autoregressive Models for Personalized Text-to-Image Generation"></a>103. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/CoAR__Concept_Injection_into_Autoregressive_Models_for_Personalized_Text-to-Image_Generation.pdf">CoAR: Concept Injection into Autoregressive Models for Personalized Text-to-Image Generation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Zhejiang University</span></p>
<p>æœ¬æ–‡æå‡ºäº†CoARæ¡†æ¶ï¼Œé€šè¿‡å±‚çº§å¤šæ¨¡æ€ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆLayerwise Multimodal Context Learning, LMCLï¼‰ã€åŒé‡å…ˆéªŒä¿æŒæŸå¤±ï¼ˆDual Prior Preservation, DPPï¼‰å’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥è‡ªæ­£åˆ™åŒ–ï¼ˆContext-Aware Self-Regularization, CASRï¼‰ï¼Œåœ¨å®Œå…¨å†»ç»“é¢„è®­ç»ƒå‚æ•°çš„æƒ…å†µä¸‹ï¼Œå°†ä¸ªæ€§åŒ–ä¸»ä½“æˆ–é£æ ¼æ¦‚å¿µé«˜æ•ˆæ³¨å…¥å¤šæ¨¡æ€è‡ªå›å½’ï¼ˆARï¼‰æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹ä¸­ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCoARåœ¨ä¸»ä½“å’Œé£æ ¼å®šåˆ¶ä»»åŠ¡ä¸Šå®ç°äº†æ›´é«˜çš„ä¸»ä½“ä¿çœŸåº¦ã€æŒ‡ä»¤å¯¹é½å’Œé£æ ¼è¿˜åŸï¼Œä¸”æ‰€éœ€å¯è®­ç»ƒå‚æ•°å°‘äº0.1Mï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="104-EndoAgent-A-Memory-Guided-Reflective-Agent-for-Intelligent-Endoscopic-Vision-to-Decision-Reasoning"><a href="#104-EndoAgent-A-Memory-Guided-Reflective-Agent-for-Intelligent-Endoscopic-Vision-to-Decision-Reasoning" class="headerlink" title="104. EndoAgent: A Memory-Guided Reflective Agent for Intelligent Endoscopic Vision-to-Decision Reasoning"></a>104. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/EndoAgent__A_Memory-Guided_Reflective_Agent_for_Intelligent_Endoscopic_Vision-to-Decision_Reasoning.pdf">EndoAgent: A Memory-Guided Reflective Agent for Intelligent Endoscopic Vision-to-Decision Reasoning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Southeast University</span></p>
<p>EndoAgentæå‡ºäº†ä¸€ä¸ªå¤šæ¨¡å—ã€åŒè®°å¿†æœºåˆ¶çš„æ™ºèƒ½ä»£ç†æ¡†æ¶ï¼Œç»“åˆçŸ­æœŸè¡ŒåŠ¨è¿½è¸ªå’Œé•¿æœŸç»éªŒåæ€ï¼Œæ”¯æŒå¤šè½®æ¨ç†ä¸å·¥å…·åä½œï¼Œå®ç°å†…é•œå›¾åƒåˆ†æçš„è§†è§‰åˆ°å†³ç­–æµç¨‹ã€‚é€šè¿‡EndoAgentBenchå¤§è§„æ¨¡å†…é•œåŸºå‡†æµ‹è¯•ï¼Œå®éªŒè¯æ˜EndoAgentåœ¨ç»†ç²’åº¦è§†è§‰ç†è§£å’Œå¼€æ”¾å¼è¯­è¨€ç”Ÿæˆä»»åŠ¡ä¸Šå‡è¶…è¶Šç°æœ‰åŒ»å­¦å’Œé€šç”¨å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼Œæå‡ä¸´åºŠå†³ç­–æ”¯æŒå‡†ç¡®æ€§å’Œçµæ´»æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="105-Representation-Understanding-via-Activation-Maximization"><a href="#105-Representation-Understanding-via-Activation-Maximization" class="headerlink" title="105. Representation Understanding via Activation Maximization"></a>105. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Representation_Understanding_via_Activation_Maximization.pdf">Representation Understanding via Activation Maximization</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">The University of Manchester</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„ç‰¹å¾å¯è§†åŒ–æ¡†æ¶ï¼ŒåŸºäºæ¿€æ´»æœ€å¤§åŒ–ï¼ˆActivation Maximization, AMï¼‰ï¼Œé€‚ç”¨äºå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNsï¼‰å’Œè§†è§‰Transformerï¼ˆViTï¼‰ï¼Œèƒ½å¤Ÿå¯¹è¾“å‡ºå±‚åŠä¸­é—´å±‚è¿›è¡Œå¯è§£é‡Šæ€§åˆ†æï¼Œå¹¶é€šè¿‡åœ¨é¢‘åŸŸä¼˜åŒ–æå‡å¯è§†åŒ–çš„è‡ªç„¶æ€§å’Œè¯­ä¹‰ä¸€è‡´æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¸ä»…æœ‰æ•ˆæ­ç¤ºäº†ä¸åŒæ¨¡å‹æ¶æ„çš„è¡¨å¾å·®å¼‚ï¼Œè¿˜å¯ç”Ÿæˆç»“æ„åŒ–çš„å¯¹æŠ—æ ·æœ¬ï¼Œä»è€Œå…¼é¡¾æ¨¡å‹å¯è§£é‡Šæ€§ä¸é²æ£’æ€§åˆ†æã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="106-Small-Large-Collaboration-Training-efficient-Concept-Personalization-for-Large-VLM-using-a-Meta-Personalized-Small-VLM"><a href="#106-Small-Large-Collaboration-Training-efficient-Concept-Personalization-for-Large-VLM-using-a-Meta-Personalized-Small-VLM" class="headerlink" title="106. Small-Large Collaboration: Training-efficient Concept Personalization for Large VLM using a Meta Personalized Small VLM"></a>106. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Small-Large_Collaboration__Training-efficient_Concept_Personalization_for_Large_VLM_using_a_Meta_Per.pdf">Small-Large Collaboration: Training-efficient Concept Personalization for Large VLM using a Meta Personalized Small VLM</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Peking University</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ä¸ªæ€§åŒ–æ–°èŒƒå¼SLCï¼ˆSmall-Large Collaborationï¼‰ï¼Œåˆ©ç”¨å°å‹VLMè¿›è¡Œç”¨æˆ·æ¦‚å¿µæ£€æµ‹å’Œç»“æ„åŒ–çº¿ç´¢ç”Ÿæˆï¼Œå¤§å‹VLMè´Ÿè´£åæ€æ ¡éªŒä¸æœ€ç»ˆç­”æ¡ˆç”Ÿæˆã€‚è¯¥æ–¹æ³•é€šè¿‡å…ƒè®­ç»ƒå°æ¨¡å‹å¹¶è®¾è®¡æµ‹è¯•æ—¶åæ€æœºåˆ¶ï¼Œå¤§å¹…é™ä½è®­ç»ƒæˆæœ¬å¹¶å‡å°‘å¹»è§‰ï¼Œå®ç°å¯¹å¼€æºå’Œé—­æºå¤§æ¨¡å‹çš„é«˜æ•ˆä¸ªæ€§åŒ–ï¼Œå®éªŒæ˜¾ç¤ºåœ¨å¤šä¸ªåŸºå‡†ä¸Šæ€§èƒ½ä¼˜å¼‚ä¸”æ˜“äºå®é™…éƒ¨ç½²ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="107-SUIT-Spatial-Spectral-Union-Intersection-Interaction-Network-for-Hyperspectral-Object-Tracking"><a href="#107-SUIT-Spatial-Spectral-Union-Intersection-Interaction-Network-for-Hyperspectral-Object-Tracking" class="headerlink" title="107. SUIT: Spatial-Spectral Union-Intersection Interaction Network for Hyperspectral Object Tracking"></a>107. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/SUIT__Spatial-Spectral_Union-Intersection_Interaction_Network_for_Hyperspectral_Object_Tracking.pdf">SUIT: Spatial-Spectral Union-Intersection Interaction Network for Hyperspectral Object Tracking</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Nanjing University of Science and Technology</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†SUITï¼ˆSpatial-Spectral Union-Intersection Interaction Networkï¼‰ï¼Œä¸€ç§ä¸“ä¸ºé«˜å…‰è°±è§†é¢‘ç›®æ ‡è·Ÿè¸ªè®¾è®¡çš„ç©ºé—´-å…‰è°±è”åˆäº¤äº’ç½‘ç»œã€‚æ–¹æ³•ä¸Šï¼ŒSUITåˆ©ç”¨Transformerå®ç°æ¨¡æ¿å’Œæœç´¢åŒºåŸŸåœ¨å„æ³¢æ®µé—´çš„ç©ºé—´é•¿è·ç¦»å…³ç³»å»ºæ¨¡ï¼Œå¹¶é¦–æ¬¡å¼•å…¥é›†åˆè®ºåŒ…å®¹-æ’æ–¥åŸç†å°†ç©ºé—´äº¤äº’çš„è”åˆä¸äº¤é›†åŒºåˆ†ä¸ºæ³¢æ®µå…±äº«ä¸æ³¢æ®µç‰¹æœ‰ä¿¡æ¯è¿›è¡Œèåˆï¼Œæœ€åæå‡ºå…‰è°±æŸå¤±ä»¥ä¿è¯æ¨¡æ¿ä¸é¢„æµ‹åŒºåŸŸçš„ç‰©è´¨åˆ†å¸ƒä¸€è‡´æ€§ï¼Œæå‡å¯¹å˜å½¢ã€é®æŒ¡ç­‰å¤æ‚åœºæ™¯çš„é²æ£’æ€§ã€‚å¤§è§„æ¨¡å®éªŒè¯æ˜ï¼ŒSUITåœ¨å¤šä¸ªé«˜å…‰è°±è·Ÿè¸ªæ•°æ®é›†ä¸Šå–å¾—äº†æœ€æ–°æœ€ä¼˜æ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="108-Consistent-and-Controllable-Image-Animation-with-Motion-Linear-Diffusion-Transformers"><a href="#108-Consistent-and-Controllable-Image-Animation-with-Motion-Linear-Diffusion-Transformers" class="headerlink" title="108. Consistent and Controllable Image Animation with Motion Linear Diffusion Transformers"></a>108. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Consistent_and_Controllable_Image_Animation_with_Motion_Linear_Diffusion_Transformers.pdf">Consistent and Controllable Image Animation with Motion Linear Diffusion Transformers</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Monash University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†MiraMoæ¡†æ¶ï¼Œé€šè¿‡å°†çº¿æ€§æ³¨æ„åŠ›æœºåˆ¶èå…¥Transformeræ¶æ„ï¼Œå®ç°äº†é«˜æ•ˆã€å¤–è§‚ä¸€è‡´ä¸”è¿åŠ¨å¹³æ»‘çš„å›¾åƒåŠ¨ç”»ç”Ÿæˆã€‚MiraMoé‡‡ç”¨è‡ªå»ºçš„æ–‡æœ¬åˆ°è§†é¢‘ï¼ˆT2Vï¼‰çº¿æ€§Transformerä½œä¸ºåŸºç¡€ï¼Œç»“åˆè¿åŠ¨æ®‹å·®å­¦ä¹ ã€åŸºäºDCTçš„å™ªå£°åˆå§‹åŒ–ä¸åŠ¨æ€åº¦æ§åˆ¶ï¼Œæœ‰æ•ˆæå‡äº†åŠ¨ç”»çš„ä¸€è‡´æ€§å’Œå¯æ§æ€§ï¼Œå¹¶æ˜¾è‘—å‡å°‘äº†è®¡ç®—èµ„æºæ¶ˆè€—ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMiraMoåœ¨å¤–è§‚ä¸€è‡´æ€§ã€è¿åŠ¨å¹³æ»‘æ€§åŠæ¨ç†é€Ÿåº¦ç­‰æ–¹é¢å‡è¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œå¹¶å¯æ‰©å±•è‡³è¿åŠ¨è¿ç§»å’Œè§†é¢‘ç¼–è¾‘ç­‰ä»»åŠ¡ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="109-Bridging-Semantic-Logic-Gaps-A-Cognition-Inspired-Multimodal-Boundary-Preserving-Network-for-Image-Manipulation-Localization"><a href="#109-Bridging-Semantic-Logic-Gaps-A-Cognition-Inspired-Multimodal-Boundary-Preserving-Network-for-Image-Manipulation-Localization" class="headerlink" title="109. Bridging Semantic Logic Gaps: A Cognition-Inspired Multimodal Boundary-Preserving Network for Image Manipulation Localization"></a>109. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Bridging_Semantic_Logic_Gaps__A_Cognition-Inspired_Multimodal_Boundary-Preserving_Network_for_Image_.pdf">Bridging Semantic Logic Gaps: A Cognition-Inspired Multimodal Boundary-Preserving Network for Image Manipulation Localization</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Xinjiang University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§è®¤çŸ¥å¯å‘çš„å¤šæ¨¡æ€è¾¹ç•Œä¿æŒç½‘ç»œï¼ˆCMB-Netï¼‰ï¼Œç”¨äºå›¾åƒç¯¡æ”¹åŒºåŸŸå®šä½ã€‚æ–¹æ³•ä¸Šï¼Œæ¨¡å‹ç»“åˆäº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆçš„æ–‡æœ¬æç¤ºä¸è§†è§‰ç‰¹å¾ï¼Œé€šè¿‡å›¾åƒ-æ–‡æœ¬ä¸­å¿ƒæ­§ä¹‰æ¨¡å—ï¼ˆITCAMï¼‰æƒé‡åŒ–æ–‡æœ¬ç‰¹å¾ï¼Œåˆ©ç”¨å›¾åƒ-æ–‡æœ¬äº¤äº’æ¨¡å—ï¼ˆITIMï¼‰å®ç°ç»†ç²’åº¦èåˆï¼Œå¹¶å¼•å…¥å¯é€†ç¥ç»ç½‘ç»œçš„è¾¹ç•Œè§£ç å™¨ï¼ˆREDï¼‰ä»¥æ— æŸä¿ç•™ç¯¡æ”¹åŒºåŸŸè¾¹ç•Œã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCMB-Netåœ¨å¤šä¸ªå…¬å¼€æ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰SOTAæ–¹æ³•ï¼Œä¸”æ–‡æœ¬ä¿¡æ¯èƒ½æœ‰æ•ˆæå‡å¤æ‚åœºæ™¯ä¸‹çš„ç¯¡æ”¹å®šä½ç²¾åº¦ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="110-Intention-Aware-Diffusion-Model-for-Pedestrian-Trajectory-Prediction"><a href="#110-Intention-Aware-Diffusion-Model-for-Pedestrian-Trajectory-Prediction" class="headerlink" title="110. Intention-Aware Diffusion Model for Pedestrian Trajectory Prediction"></a>110. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Intention-Aware_Diffusion_Model_for_Pedestrian_Trajectory_Prediction.pdf">Intention-Aware Diffusion Model for Pedestrian Trajectory Prediction</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Southern University of Science and Technology</span></p>
<p>è¯¥è®ºæ–‡æå‡ºä¸€ç§ç»“åˆçŸ­æœŸå’Œé•¿æœŸæ„å›¾çš„æ‰©æ•£æ¨¡å‹ç”¨äºè¡Œäººè½¨è¿¹é¢„æµ‹ï¼šçŸ­æœŸæ„å›¾é€šè¿‡æ®‹å·®æåæ ‡è¡¨ç¤ºæ•æ‰ç»†ç²’åº¦è¿åŠ¨è¶‹åŠ¿ï¼Œé•¿æœŸæ„å›¾é‡‡ç”¨å¯å­¦ä¹ çš„tokenç«¯ç‚¹é¢„æµ‹å™¨ä»¥æ¦‚ç‡æ–¹å¼ç”Ÿæˆå¤šæ¨¡æ€ç›®æ ‡ã€‚æ¨¡å‹è¿˜å¼•å…¥è½¯æ©ç æŒ‡å¯¼å’Œæ®‹å·®å™ªå£°é¢„æµ‹ï¼Œé€šè¿‡åœ¨ETHã€UCYå’ŒSDDæ•°æ®é›†ä¸Šå®éªŒè¯æ˜ï¼Œæ–¹æ³•åœ¨ADEå’ŒFDEæŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå®ç°äº†æ›´ç²¾ç¡®çš„è½¨è¿¹é¢„æµ‹ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="111-Large-scale-Multi-sequence-Pretraining-for-Generalizable-MRI-Analysis-in-Versatile-Clinical-Applications"><a href="#111-Large-scale-Multi-sequence-Pretraining-for-Generalizable-MRI-Analysis-in-Versatile-Clinical-Applications" class="headerlink" title="111. Large-scale Multi-sequence Pretraining for Generalizable MRI Analysis in Versatile Clinical Applications"></a>111. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Large-scale_Multi-sequence_Pretraining_for_Generalizable_MRI_Analysis_in_Versatile_Clinical_Applicat.pdf">Large-scale Multi-sequence Pretraining for Generalizable MRI Analysis in Versatile Clinical Applications</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">The Hong Kong University of Science and Technology</span></p>
<p>æœ¬æ–‡æå‡ºPRISMï¼Œä¸€ç§åŸºäºSwin Transformerçš„å¤§è§„æ¨¡å¤šåºåˆ—MRIè‡ªç›‘ç£é¢„è®­ç»ƒåŸºç¡€æ¨¡å‹ï¼Œé€šè¿‡è§£è€¦è§£å‰–å­¦ä¸å˜ç‰¹å¾ä¸åºåˆ—ç‰¹å¼‚æ€§å˜åŒ–ï¼Œç»“åˆæ©ç å›¾åƒé‡å»ºã€å›¾åƒç¿»è¯‘ã€å…ƒæ•°æ®é¢„æµ‹å’Œå¯¹æ¯”å­¦ä¹ ç­‰å¤šä»»åŠ¡æ¡†æ¶ï¼Œè·å¾—å¯¹å¤šç§ä¸´åºŠä¸‹æ¸¸ä»»åŠ¡ï¼ˆåˆ†å‰²ã€åˆ†ç±»ã€å›å½’ã€é…å‡†ã€æŠ¥å‘Šç”Ÿæˆï¼‰çš„å¼ºæ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPRISMåœ¨44é¡¹ä¸‹æ¸¸ä»»åŠ¡ä¸­æœ‰39é¡¹å–å¾—æœ€ä¼˜ç»“æœï¼Œæœ‰æ•ˆæå‡äº†å¤šåºåˆ—MRIåˆ†æçš„å‡†ç¡®æ€§ã€é²æ£’æ€§å’Œä¸´åºŠé€‚ç”¨æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="112-SketchAnimator-Animate-Sketch-via-Motion-Customization-of-Text-to-Video-Diffusion-Models"><a href="#112-SketchAnimator-Animate-Sketch-via-Motion-Customization-of-Text-to-Video-Diffusion-Models" class="headerlink" title="112. SketchAnimator: Animate Sketch via Motion Customization of Text-to-Video Diffusion Models"></a>112. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/SketchAnimator__Animate_Sketch_via_Motion_Customization_of_Text-to-Video_Diffusion_Models.pdf">SketchAnimator: Animate Sketch via Motion Customization of Text-to-Video Diffusion Models</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Beijing University of Posts and Telecommunications</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†SketchAnimatoræ–¹æ³•ï¼Œå®ç°äº†é€šè¿‡ä¸‰é˜¶æ®µæµç¨‹ï¼ˆå¤–è§‚å­¦ä¹ ã€è¿åŠ¨å­¦ä¹ å’Œè§†é¢‘å…ˆéªŒè’¸é¦ï¼‰ï¼Œåˆ©ç”¨LoRAå¾®è°ƒå’Œå¯å¾®åˆ†è´å¡å°”æ›²çº¿æ¸²æŸ“ï¼Œå°†é™æ€æ‰‹ç»˜è‰å›¾å’Œå‚è€ƒè§†é¢‘ä¸­çš„è¿åŠ¨ä¿¡å·ç»“åˆï¼Œç”Ÿæˆé«˜è´¨é‡ä¸”è¿åŠ¨ä¸€è‡´çš„è‰å›¾åŠ¨ç”»ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤–è§‚ä¿æŒå’Œè¿åŠ¨ä¼ é€’å‡†ç¡®æ€§ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæ”¯æŒé«˜åº¦è‡ªå®šä¹‰å’Œåˆ›æ„åŠ¨ç”»ç”Ÿæˆã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="113-Perceptual-Evaluation-of-GANs-and-Diffusion-Models-for-Generating-X-rays"><a href="#113-Perceptual-Evaluation-of-GANs-and-Diffusion-Models-for-Generating-X-rays" class="headerlink" title="113. Perceptual Evaluation of GANs and Diffusion Models for Generating X-rays"></a>113. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Perceptual_Evaluation_of_GANs_and_Diffusion_Models_for_Generating_X-rays.pdf">Perceptual Evaluation of GANs and Diffusion Models for Generating X-rays</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Pontificia Universidad CatÃ³lica de Chile</span></p>
<p>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºäººç±»ä¸“å®¶è¯„ä¼°çš„æ¡†æ¶ï¼Œç³»ç»Ÿæ¯”è¾ƒäº†GANå’ŒDiffusion Modelsåœ¨åˆæˆèƒ¸éƒ¨Xå…‰ç‰‡çš„çœŸå®æ€§å’Œå¼‚å¸¸è¡¨ç°åŠ›ï¼Œä¸»è¦é’ˆå¯¹å››ç§å¼‚å¸¸ï¼ˆè‚ºä¸å¼ ã€è‚ºéƒ¨ä¸é€æ˜ã€èƒ¸è…”ç§¯æ¶²ã€å¿ƒå½±å¢å¤§ï¼‰ã€‚ç ”ç©¶å‘ç°ï¼ŒDiffusion Modelsæ•´ä½“ç”Ÿæˆçš„å›¾åƒæ›´é€¼çœŸï¼Œä½†åœ¨æŸäº›æ¡ä»¶ä¸‹GANè¡¨ç°æ›´ä¼˜ï¼Œä¸”ä¸¤è€…åœ¨æ¡ä»¶å‡†ç¡®æ€§æ–¹é¢å„æœ‰ä¼˜åŠ¿ï¼Œè¡¨æ˜ç°æœ‰ç”Ÿæˆæ¨¡å‹å°šæœªå®Œå…¨è§£å†³åŒ»å­¦å›¾åƒçœŸå®æ€§é—®é¢˜ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="114-Cut2Next-Generating-Next-Shot-via-In-Context-Tuning"><a href="#114-Cut2Next-Generating-Next-Shot-via-In-Context-Tuning" class="headerlink" title="114. Cut2Next: Generating Next Shot via In-Context Tuning"></a>114. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Cut2Next__Generating_Next_Shot_via_In-Context_Tuning.pdf">Cut2Next: Generating Next Shot via In-Context Tuning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">The Chinese University of Hong Kong</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†Next Shot Generationï¼ˆNSGï¼‰ä»»åŠ¡ï¼Œæ—¨åœ¨ç”Ÿæˆç¬¦åˆä¸“ä¸šå‰ªè¾‘æ¨¡å¼å’Œä¸¥æ ¼ç”µå½±è¿ç»­æ€§çš„é«˜è´¨é‡ä¸‹ä¸€é•œå¤´ã€‚æ–¹æ³•ä¸Šï¼ŒCut2Nextæ¡†æ¶åŸºäºDiffusion Transformerï¼Œé‡‡ç”¨åˆ†å±‚å¤šæç¤ºç­–ç•¥å’Œæ— å‚æ•°æ–°æ¶æ„ï¼ˆCACIä¸HAMï¼‰ï¼Œç»“åˆå¤§è§„æ¨¡å’Œç²¾ç»†åŒ–æ•°æ®é›†ï¼ˆRawCutsä¸CuratedCutsï¼‰ï¼Œå®ç°å¯¹å¤šæ ·åŒ–ç¼–è¾‘æ¨¡å¼çš„æœ‰æ•ˆå»ºæ¨¡ã€‚ç»“è®ºæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨è§†è§‰ä¸€è‡´æ€§å’Œæ–‡æœ¬å¯¹é½ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿ï¼Œå¹¶åœ¨ç”¨æˆ·ç ”ç©¶ä¸­è·å¾—æé«˜åå¥½ï¼Œå°¤å…¶åœ¨å‰ªè¾‘æ¨¡å¼éµå¾ªå’Œç”µå½±è¿è´¯æ€§æ–¹é¢è¡¨ç°çªå‡ºã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="115-Learning-User-Preferences-for-Image-Generation-Models"><a href="#115-Learning-User-Preferences-for-Image-Generation-Models" class="headerlink" title="115. Learning User Preferences for Image Generation Models"></a>115. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Learning_User_Preferences_for_Image_Generation_Model.pdf">Learning User Preferences for Image Generation Models</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Renmin University of China</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰çš„ç”¨æˆ·åå¥½å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥å¯¹æ¯”åå¥½æŸå¤±å’Œå¯å­¦ä¹ åå¥½tokenï¼Œåˆ©ç”¨ç”¨æˆ·å†å²äº¤äº’æ•°æ®å»ºæ¨¡ä¸ªæ€§åŒ–è§†è§‰åå¥½ã€‚æ–¹æ³•æœ‰æ•ˆåŒºåˆ†ç”¨æˆ·â€œå–œæ¬¢â€ä¸â€œä¸å–œæ¬¢â€çš„å†…å®¹ï¼Œå¹¶é€šè¿‡åå¥½tokenæ•æ‰ç”¨æˆ·é—´å…±äº«å…´è¶£ï¼Œå®ç°åˆ†ç»„ç»“æ„å’Œæ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åå¥½é¢„æµ‹å‡†ç¡®ç‡å’Œç”Ÿæˆå†…å®¹ä¸ªæ€§åŒ–æŒ‡å¯¼æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¯å‡†ç¡®è¯†åˆ«ç”¨æˆ·å®¡ç¾å€¾å‘å¹¶æå‡ç”Ÿæˆæ•ˆæœã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="116-THAT-Token-wise-High-frequency-Augmentation-Transformer-for-Hyperspectral-Pansharpening"><a href="#116-THAT-Token-wise-High-frequency-Augmentation-Transformer-for-Hyperspectral-Pansharpening" class="headerlink" title="116. THAT: Token-wise High-frequency Augmentation Transformer for Hyperspectral Pansharpening"></a>116. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/THAT__Token-wise_High-frequency_Augmentation_Transformer_for_Hyperspectral_Pansharpening.pdf">THAT: Token-wise High-frequency Augmentation Transformer for Hyperspectral Pansharpening</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">JPMorgan Chase</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„Token-wise High-frequency Augmentation Transformer (THAT)æ¡†æ¶ï¼Œç”¨äºé«˜å…‰è°±å›¾åƒèåˆï¼ˆpansharpeningï¼‰ã€‚æ–¹æ³•åˆ›æ–°æ€§åœ°å¼•å…¥äº†Pivotal Token Selective Attention (PTSA)æ¨¡å—ä»¥åŠ¨æ€ç­›é€‰å’Œèšç„¦äºä¿¡æ¯é‡å¤§çš„tokenï¼Œå¹¶é€šè¿‡Multi-level Variance-aware Feed-forward Network (MVFN)å¢å¼ºé«˜é¢‘ç»†èŠ‚å­¦ä¹ ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTHATåœ¨å¤šä¸ªå…¬å¼€æ•°æ®é›†å’Œä¸åŒæ”¾å¤§å€æ•°ä¸‹å‡å–å¾—äº†ä¼˜å¼‚çš„é‡å»ºè´¨é‡å’Œæ•ˆç‡ï¼Œæ˜¾è‘—æå‡äº†é«˜å…‰è°±å½±åƒçš„ç©ºé—´å’Œå…‰è°±ä¿çœŸåº¦ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="117-Mitigating-Biases-in-Surgical-Operating-Rooms-with-Geometry"><a href="#117-Mitigating-Biases-in-Surgical-Operating-Rooms-with-Geometry" class="headerlink" title="117. Mitigating Biases in Surgical Operating Rooms with Geometry"></a>117. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Mitigating_Biases_in_Surgical_Operating_Rooms_with_Geometry.pdf">Mitigating Biases in Surgical Operating Rooms with Geometry</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">TU Munich</span></p>
<p>è¯¥è®ºæ–‡é€šè¿‡å¯¹æ‰‹æœ¯å®¤äººå‘˜å†è¯†åˆ«ä»»åŠ¡ä¸­çš„æ·±åº¦ç¥ç»ç½‘ç»œè¿›è¡Œæ¢¯åº¦å‹æ˜¾è‘—æ€§åˆ†æï¼Œå‘ç°æ¨¡å‹å®¹æ˜“ä¾èµ–äºæœè£…ç­‰éæœ¬è´¨è§†è§‰ç‰¹å¾è€Œäº§ç”Ÿåè§ã€‚ä½œè€…æå‡ºåˆ©ç”¨3Dç‚¹äº‘åºåˆ—ç¼–ç äººå‘˜èº«ä»½ï¼Œå°†å‡ ä½•ä¿¡æ¯ï¼ˆå¦‚å½¢æ€å’ŒåŠ¨ä½œæ¨¡å¼ï¼‰ä¸å¤–è§‚æ··æ·†å› ç´ åˆ†ç¦»ï¼Œå®éªŒè¡¨æ˜å‡ ä½•è¡¨ç¤ºåœ¨çœŸå®ä¸´åºŠç¯å¢ƒä¸‹èƒ½æœ‰æ•ˆæå‡è¯†åˆ«å‡†ç¡®æ€§å¹¶å‡å°‘åè§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="118-StableAvatar-Infinite-Length-Audio-Driven-Avatar-Video-Generation"><a href="#118-StableAvatar-Infinite-Length-Audio-Driven-Avatar-Video-Generation" class="headerlink" title="118. StableAvatar: Infinite-Length Audio-Driven Avatar Video Generation"></a>118. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/StableAvatar__Infinite-Length_Audio-Driven_Avatar_Video_Generation.pdf">StableAvatar: Infinite-Length Audio-Driven Avatar Video Generation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Fudan University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºStableAvatarï¼Œä¸€ç§ç«¯åˆ°ç«¯è§†é¢‘æ‰©æ•£Transformeræ¡†æ¶ï¼Œå®ç°äº†åŸºäºéŸ³é¢‘é©±åŠ¨çš„æ— é™æ—¶é•¿é«˜è´¨é‡è™šæ‹Ÿäººè§†é¢‘ç”Ÿæˆã€‚æ–¹æ³•æ ¸å¿ƒåœ¨äºå¼•å…¥Timestep-aware Audio Adapterè¿›è¡Œæ­¥é•¿æ„ŸçŸ¥çš„éŸ³é¢‘è°ƒåˆ¶ï¼Œé˜²æ­¢æ½œåœ¨åˆ†å¸ƒè¯¯å·®ç´¯ç§¯ï¼Œå¹¶åœ¨æ¨ç†é˜¶æ®µé€šè¿‡Audio Native Guidanceæå‡éŸ³é¢‘åŒæ­¥å’Œè¡¨æƒ…è‡ªç„¶åº¦ï¼Œé‡‡ç”¨åŠ¨æ€åŠ æƒæ»‘åŠ¨çª—å£æå‡é•¿è§†é¢‘å¹³æ»‘æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒStableAvataræ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œåœ¨èº«ä»½ä¸€è‡´æ€§ã€éŸ³é¢‘åŒæ­¥å’Œè§†é¢‘è´¨é‡æ–¹é¢å‡è¾¾åˆ°æ–°SOTAï¼Œæ”¯æŒé•¿è§†é¢‘æ— æ˜æ˜¾è´¨é‡è¡°å‡ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="119-VGGSounder-Audio-Visual-Evaluations-for-Foundation-Models"><a href="#119-VGGSounder-Audio-Visual-Evaluations-for-Foundation-Models" class="headerlink" title="119. VGGSounder: Audio-Visual Evaluations for Foundation Models"></a>119. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/VGGSounder__Audio-Visual_Evaluations_for_Foundation_Models.pdf">VGGSounder: Audio-Visual Evaluations for Foundation Models</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Technical University of Munich</span></p>
<p>æœ¬è®ºæ–‡æå‡ºVGGSounderï¼Œä¸€ä¸ªå…¨é¢é‡æ³¨é‡Šçš„å¤šæ ‡ç­¾éŸ³è§†é¢‘åˆ†ç±»æµ‹è¯•é›†ï¼Œä¸“ä¸ºè¯„ä¼°éŸ³è§†é¢‘åŸºç¡€æ¨¡å‹è®¾è®¡ã€‚æ–¹æ³•åŒ…æ‹¬å¯¹VGGSoundæ•°æ®é›†è¿›è¡Œå¤šæ ‡ç­¾å’Œæ¨¡æ€ï¼ˆå¯å¬&#x2F;å¯è§&#x2F;å¯å¬ä¸”å¯è§ï¼‰äººå·¥æ ‡æ³¨ï¼Œæ·»åŠ èƒŒæ™¯éŸ³ä¹ã€ç”»å¤–éŸ³å’Œé™æ€å›¾ç‰‡ç­‰å…ƒæ ‡ç­¾ï¼Œå¹¶å¼•å…¥â€œæ¨¡æ€æ··æ·†â€æ–°æŒ‡æ ‡ä»¥é‡åŒ–å¤šæ¨¡æ€è¾“å…¥å¯¹æ¨¡å‹æ€§èƒ½çš„è´Ÿé¢å½±å“ã€‚å®éªŒè¯„æµ‹è¡¨æ˜ï¼Œç°æœ‰çš„éŸ³è§†é¢‘åŸºç¡€æ¨¡å‹åœ¨è¯¥æ•°æ®é›†ä¸Šçš„è¡¨ç°æ™®éè¾ƒå·®ï¼Œå°¤å…¶åœ¨å¤šæ¨¡æ€è¾“å…¥ä¸‹æ˜“å‡ºç°æ€§èƒ½ä¸‹é™ï¼Œä¸”æ¨¡å‹å®¹æ˜“åå‘è§†è§‰æˆ–å¬è§‰ä¿¡æ¯ã€‚ç»“è®ºï¼šVGGSounderèƒ½å¤Ÿæ›´ç²¾ç¡®åœ°æ­ç¤ºå¤šæ¨¡æ€æ¨¡å‹çš„èƒ½åŠ›çŸ­æ¿ï¼Œä¸ºéŸ³è§†é¢‘åŸºç¡€æ¨¡å‹çš„å…¬å¹³è¯„æµ‹å’Œæœªæ¥æ”¹è¿›æä¾›äº†é‡è¦å·¥å…·ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="120-SAGOnline-Segment-Any-Gaussians-Online"><a href="#120-SAGOnline-Segment-Any-Gaussians-Online" class="headerlink" title="120. SAGOnline: Segment Any Gaussians Online"></a>120. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/SAGOnline__Segment_Any_Gaussians_Online.pdf">SAGOnline: Segment Any Gaussians Online</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Waterloo</span></p>
<p>SAGOnlineæå‡ºäº†ä¸€ç§è½»é‡çº§ã€é›¶è®­ç»ƒçš„å®æ—¶3Dé«˜æ–¯åœºåˆ†å‰²æ¡†æ¶ï¼Œé€šè¿‡è§†é¢‘åŸºç¡€æ¨¡å‹ï¼ˆå¦‚SAM 2ï¼‰å®ç°è§†å›¾ä¸€è‡´çš„2Dåˆ†å‰²ï¼Œå¹¶åˆ©ç”¨GPUåŠ é€Ÿç®—æ³•å°†2Dæ©ç è½¬ä¸º3Då®ä¾‹æ ‡ç­¾ï¼Œå®ç°é«˜æ•ˆçš„å¤šå¯¹è±¡è¿½è¸ªä¸åˆ†å‰²ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨NVOSå’ŒSpin-NeRFåŸºå‡†ä¸Šè¾¾åˆ°æœ€æ–°SOTAç²¾åº¦ï¼Œå¹¶ä»¥27ms&#x2F;å¸§å–å¾—æå¿«æ¨ç†é€Ÿåº¦ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="121-KARMA-Efficient-Structural-Defect-Segmentation-via-Kolmogorov-Arnold-Representation-Learning"><a href="#121-KARMA-Efficient-Structural-Defect-Segmentation-via-Kolmogorov-Arnold-Representation-Learning" class="headerlink" title="121. KARMA: Efficient Structural Defect Segmentation via Kolmogorov-Arnold Representation Learning"></a>121. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/KARMA__Efficient_Structural_Defect_Segmentation_via_Kolmogorov-Arnold_Representation_Learning.pdf">KARMA: Efficient Structural Defect Segmentation via Kolmogorov-Arnold Representation Learning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of New Orleans</span></p>
<p>æœ¬æ–‡æå‡ºKARMAï¼Œä¸€ç§åŸºäºKolmogorov-Arnoldè¡¨ç¤ºå­¦ä¹ çš„é«˜æ•ˆç»“æ„æ€§ç¼ºé™·åˆ†å‰²æ¡†æ¶ï¼Œæ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬å‚æ•°é«˜æ•ˆçš„Tiny Kolmogorov-Arnold Network (TiKAN)æ¨¡å—ã€èåˆå¯åˆ†ç¦»å·ç§¯çš„å¤šå°ºåº¦ç‰¹å¾é‡‘å­—å¡”ç»“æ„ï¼Œä»¥åŠé™-åŠ¨æ€åŸå‹æœºåˆ¶ã€‚KARMAåœ¨ç»“æ„ç¼ºé™·æ•°æ®é›†ä¸Šä»¥ä¸åˆ°ç™¾ä¸‡å‚æ•°å®ç°ä¸å…ˆè¿›æ¨¡å‹ç›¸å½“æˆ–æ›´ä¼˜çš„åˆ†å‰²æ€§èƒ½ï¼Œä¸”æ˜¾è‘—å‡å°‘97%çš„æ¨¡å‹å‚æ•°å’Œè®¡ç®—é‡ï¼Œé€‚åˆå®æ—¶éƒ¨ç½²äºåŸºç¡€è®¾æ–½è‡ªåŠ¨å·¡æ£€ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="122-REDDINO-A-FOUNDATION-MODEL-FOR-RED-BLOOD-CELL-ANALYSIS"><a href="#122-REDDINO-A-FOUNDATION-MODEL-FOR-RED-BLOOD-CELL-ANALYSIS" class="headerlink" title="122. REDDINO: A FOUNDATION MODEL FOR RED BLOOD CELL ANALYSIS"></a>122. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/RedDino__A_foundation_model_for_red_blood_cell_analysis.pdf">REDDINO: A FOUNDATION MODEL FOR RED BLOOD CELL ANALYSIS</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Cagliari</span></p>
<p>æœ¬æ–‡æå‡ºRedDinoï¼Œä¸€ç§åŸºäºè‡ªç›‘ç£å­¦ä¹ ä¸”ä¸“ä¸ºçº¢ç»†èƒå›¾åƒåˆ†æè®¾è®¡çš„åŸºç¡€æ¨¡å‹ï¼Œé€šè¿‡æ”¹è¿›DINOv2æ¡†æ¶å¹¶åœ¨å¤§è§„æ¨¡å¤šæºçº¢ç»†èƒæ•°æ®é›†ä¸Šè®­ç»ƒï¼Œé‡‡ç”¨ç‰¹å®šå¢å¼ºå’Œæ­£åˆ™åŒ–ç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRedDinoåœ¨çº¢ç»†èƒå½¢æ€åˆ†ç±»ä»»åŠ¡ä¸Šè¾ƒç°æœ‰æ–¹æ³•æœ‰æ˜¾è‘—æå‡ï¼Œå…·æœ‰å¼ºæ³›åŒ–èƒ½åŠ›å’Œé€‚åº”ä¸åŒæ•°æ®æºçš„é²æ£’æ€§ï¼Œä¸ºè‡ªåŠ¨åŒ–è¡€æ¶²ç—…è¯Šæ–­æä¾›äº†å¯é å·¥å…·ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="123-MedReasoner-Reinforcement-Learning-Drives-Reasoning-Grounding-from-Clinical-Thought-to-Pixel-Level-Precision"><a href="#123-MedReasoner-Reinforcement-Learning-Drives-Reasoning-Grounding-from-Clinical-Thought-to-Pixel-Level-Precision" class="headerlink" title="123. MedReasoner: Reinforcement Learning Drives Reasoning Grounding from Clinical Thought to Pixel-Level Precision"></a>123. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/MedReasoner__Reinforcement_Learning_Drives_Reasoning_Grounding_from_Clinical_Thought_to_Pixel-Level_.pdf">MedReasoner: Reinforcement Learning Drives Reasoning Grounding from Clinical Thought to Pixel-Level Precision</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Beijing University of Posts and Telecommunications</span></p>
<p>æœ¬æ–‡æå‡ºUMRGä»»åŠ¡ä¸U-MRG-14Kæ•°æ®é›†ï¼Œè¦æ±‚æ¨¡å‹å°†éšå«ä¸´åºŠé—®é¢˜è½¬åŒ–ä¸ºåŒ»å­¦å½±åƒçš„åƒç´ çº§å®šä½ã€‚æ–¹æ³•ä¸Šï¼ŒMedReasoneré‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œå°†ä¸´åºŠæ¨ç†ä¸åˆ†å‰²è§£è€¦ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æ¨ç†æ¨¡å—ï¼Œåˆ©ç”¨å¥–åŠ±å‡½æ•°å¯¹è¾“å‡ºæ ¼å¼å’Œç©ºé—´ç²¾åº¦è¿›è¡Œçº¦æŸï¼Œå¹¶ç”¨å†»ç»“åˆ†å‰²ä¸“å®¶å®ç°ç©ºé—´æç¤ºåˆ°æ©ç çš„è½¬æ¢ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMedReasoneråœ¨U-MRG-14Kä¸Šæ€§èƒ½æ˜¾è‘—ä¼˜äºåŒç±»æ¨¡å‹ï¼Œèƒ½å‡†ç¡®å¤„ç†éšå«åŒ»å­¦é—®é¢˜ï¼Œå®ç°é«˜ç²¾åº¦å®šä½ã€‚ç»“è®ºï¼šRLæ–¹æ³•æœ‰æ•ˆæå‡äº†åŒ»å­¦å½±åƒè¯­ä¹‰ä¸åƒç´ çº§å®šä½çš„è§£é‡Šæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="124-Integrating-Task-Specific-and-Universal-Adapters-for-Pre-Trained-Model-based-Class-Incremental-Learning"><a href="#124-Integrating-Task-Specific-and-Universal-Adapters-for-Pre-Trained-Model-based-Class-Incremental-Learning" class="headerlink" title="124. Integrating Task-Specific and Universal Adapters for Pre-Trained Model-based Class-Incremental Learning"></a>124. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Integrating_Task-Specific_and_Universal_Adapters_for_Pre-Trained_Model-based_Class-Incremental_Learn.pdf">Integrating Task-Specific and Universal Adapters for Pre-Trained Model-based Class-Incremental Learning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">School of Artificial Intelligence, Nanjing University</span></p>
<p>æœ¬æ–‡æå‡ºTUNAæ–¹æ³•ï¼Œå°†ä»»åŠ¡ä¸“å±adapterä¸é€šç”¨adapterç»“åˆï¼Œç”¨äºé¢„è®­ç»ƒæ¨¡å‹çš„ç±»å¢é‡å­¦ä¹ ã€‚æ–¹æ³•åŒ…æ‹¬åˆ©ç”¨æ­£äº¤æŸå¤±è®­ç»ƒä»»åŠ¡ä¸“å±adapterï¼Œé€šè¿‡ç†µæœºåˆ¶é€‰æ‹©æœ€åˆé€‚çš„adapterï¼Œå¹¶èåˆå„adapteræƒé‡æ„å»ºé€šç”¨adapterï¼Œæ¨ç†æ—¶é›†æˆä¸“å±ä¸é€šç”¨adapteré¢„æµ‹ã€‚å®éªŒç»“æœåœ¨CIFAR100ã€ImageNet-R&#x2F;Aã€ObjectNetç­‰æ•°æ®é›†ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæœ‰æ•ˆå‡ç¼“ç¾éš¾æ€§é—å¿˜å¹¶æå‡åˆ†ç±»å‡†ç¡®ç‡ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="125-FantasyStyle-Controllable-Stylized-Distillation-for-3D-Gaussian-Splatting"><a href="#125-FantasyStyle-Controllable-Stylized-Distillation-for-3D-Gaussian-Splatting" class="headerlink" title="125. FantasyStyle: Controllable Stylized Distillation for 3D Gaussian Splatting"></a>125. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/FantasyStyle__Controllable_Stylized_Distillation_for_3D_Gaussian_Splatting.pdf">FantasyStyle: Controllable Stylized Distillation for 3D Gaussian Splatting</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">School of Computing and Artificial Intelligence, Shanghai University of Finance and Economics</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†FantasyStyleï¼Œä¸€ç§åŸºäº3Dé«˜æ–¯æ³¼æº…çš„å¯æ§é£æ ¼è¿ç§»æ¡†æ¶ï¼Œæ ¸å¿ƒæ–¹æ³•åŒ…æ‹¬å¤šè§†è§’é¢‘ç‡ä¸€è‡´æ€§ï¼ˆMVFCï¼‰å’Œå¯æ§é£æ ¼åŒ–è’¸é¦ï¼ˆCSDï¼‰ï¼Œåˆ†åˆ«é€šè¿‡3Dé¢‘åŸŸæ»¤æ³¢æå‡é£æ ¼è·¨è§†è§’ä¸€è‡´æ€§ï¼Œå¹¶å¼•å…¥è´Ÿå‘å¼•å¯¼æŠ‘åˆ¶å†…å®¹æ³„æ¼ï¼Œä»…ç”¨æ‰©æ•£æ¨¡å‹è’¸é¦å®ç°2Dåˆ°3Dçš„çµæ´»é£æ ¼è¿ç§»ã€‚å®éªŒè¡¨æ˜è¯¥æ–¹æ³•åœ¨å¤šåœºæ™¯ã€å¤šé£æ ¼ä¸‹é£æ ¼è¿ç§»è´¨é‡å’Œå†…å®¹ä¿æŒæ€§å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="126-Hyperspectral-Imaging"><a href="#126-Hyperspectral-Imaging" class="headerlink" title="126. Hyperspectral Imaging"></a>126. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Hyperspectral_Imaging.pdf">Hyperspectral Imaging</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Southeast University</span></p>
<p>æœ¬æ–‡ç³»ç»Ÿç»¼è¿°äº†é«˜å…‰è°±æˆåƒï¼ˆHSIï¼‰çš„ç‰©ç†åŸç†ã€ä¼ æ„Ÿå™¨æ¶æ„åŠæ•°æ®é‡‡é›†ã€æ ¡å‡†å’Œå¤„ç†æµç¨‹ï¼Œé‡ç‚¹ä»‹ç»äº†é™ç»´ã€åˆ†ç±»ã€å…‰è°±è§£æ··ç­‰ä¼ ç»Ÿä¸æ·±åº¦å­¦ä¹ åˆ†ææ–¹æ³•ï¼Œå¹¶æ€»ç»“äº†å…¶åœ¨ç¯å¢ƒè§‚æµ‹ã€å†œä¸šã€åŒ»å­¦ã€å·¥ä¸šæ£€æµ‹ç­‰é¢†åŸŸçš„ä»£è¡¨æ€§åº”ç”¨ã€‚ç»“è®ºæŒ‡å‡ºï¼Œéšç€ä¼ æ„Ÿå™¨å°å‹åŒ–ã€è‡ªç›‘ç£å­¦ä¹ å’ŒåŸºç¡€æ¨¡å‹çš„å‘å±•ï¼Œé«˜å…‰è°±æˆåƒæ­£é€æ­¥æˆä¸ºè·¨å­¦ç§‘é€šç”¨å¹³å°ï¼Œæœªæ¥æœ‰æœ›å®ç°å¯æ‰©å±•ã€å®æ—¶å’ŒåµŒå…¥å¼åº”ç”¨ï¼Œæ¨åŠ¨ç§‘å­¦ä¸ç¤¾ä¼šçš„æ·±åˆ»å˜é©ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="127-Matrix-3D-Omnidirectional-Explorable-3D-World-Generation"><a href="#127-Matrix-3D-Omnidirectional-Explorable-3D-World-Generation" class="headerlink" title="127. Matrix-3D: Omnidirectional Explorable 3D World Generation"></a>127. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Matrix-3D__Omnidirectional_Explorable_3D_World_Generation.pdf">Matrix-3D: Omnidirectional Explorable 3D World Generation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Skywork AI</span></p>
<p>è¯¥è®ºæ–‡æå‡ºMatrix-3Dæ¡†æ¶ï¼Œå®ç°ä»å•å¼ å›¾ç‰‡æˆ–æ–‡æœ¬æç¤ºç”Ÿæˆå¯å…¨æ–¹ä½è‡ªç”±æ¢ç´¢çš„3Dä¸–ç•Œã€‚æ–¹æ³•åŒ…æ‹¬åŸºäºå…¨æ™¯è¡¨ç¤ºçš„è½¨è¿¹å¼•å¯¼å…¨æ™¯è§†é¢‘æ‰©æ•£æ¨¡å‹ä¸å…¨æ™¯3Dé‡å»ºä¸¤ç§æµç¨‹ï¼Œå¹¶è‡ªå»ºäº†Matrix-Panoå¤§è§„æ¨¡åˆæˆå…¨æ™¯è§†é¢‘æ•°æ®é›†ã€‚ç»“è®ºè¡¨æ˜ï¼ŒMatrix-3Dåœ¨å…¨æ™¯è§†é¢‘ç”Ÿæˆå’Œ3Dä¸–ç•Œé‡å»ºä¸Šå‡è¾¾åˆ°äº†ä¸šç•Œæœ€ä¼˜çš„æ€§èƒ½ï¼Œå®ç°äº†é«˜è´¨é‡ã€å¹¿è¦†ç›–ã€å¯æ§çš„3Dåœºæ™¯ç”Ÿæˆã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="128-BadPromptFL-A-Novel-Backdoor-Threat-to-Prompt-based-Federated-Learning-in-Multimodal-Models"><a href="#128-BadPromptFL-A-Novel-Backdoor-Threat-to-Prompt-based-Federated-Learning-in-Multimodal-Models" class="headerlink" title="128. BadPromptFL: A Novel Backdoor Threat to Prompt-based Federated Learning in Multimodal Models"></a>128. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/BadPromptFL__A_Novel_Backdoor_Threat_to_Prompt-based_Federated_Learning_in_Multimodal_Models.pdf">BadPromptFL: A Novel Backdoor Threat to Prompt-based Federated Learning in Multimodal Models</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Dalian University of Technology</span></p>
<p>æœ¬æ–‡æå‡ºBadPromptFLï¼Œä¸€ç§é’ˆå¯¹å¤šæ¨¡æ€æ¨¡å‹ä¸­åŸºäºæç¤ºï¼ˆPromptï¼‰çš„è”é‚¦å­¦ä¹ çš„æ–°å‹åé—¨æ”»å‡»æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡æ¶æ„å®¢æˆ·ç«¯è”åˆä¼˜åŒ–æœ¬åœ°åé—¨è§¦å‘å™¨å’Œæç¤ºåµŒå…¥ï¼Œå¹¶å°†ä¸­æ¯’æç¤ºæ³¨å…¥å…¨å±€èšåˆæµç¨‹ï¼Œå®ç°æ— éœ€ä¿®æ”¹æ¨¡å‹å‚æ•°å³å¯åœ¨æ¨ç†æ—¶æ¿€æ´»åé—¨ã€‚å®éªŒè¡¨æ˜ï¼ŒBadPromptFLåœ¨å¤šç§æ•°æ®é›†å’Œèšåˆåè®®ä¸‹å‡èƒ½ä»¥æé«˜çš„æ”»å‡»æˆåŠŸç‡ï¼ˆ&gt;90%ï¼‰ï¼Œä¸”å¯¹æ­£å¸¸ä»»åŠ¡æ€§èƒ½å½±å“æå°ï¼Œæš´éœ²äº†åŸºäºæç¤ºçš„å¤šæ¨¡æ€è”é‚¦å­¦ä¹ çš„å®‰å…¨éšæ‚£ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="129-CD-TVD-Contrastive-Diffusion-for-3D-Super-Resolution-with-Scarce-High-Resolution-Time-Varying-Data"><a href="#129-CD-TVD-Contrastive-Diffusion-for-3D-Super-Resolution-with-Scarce-High-Resolution-Time-Varying-Data" class="headerlink" title="129. CD-TVD: Contrastive Diffusion for 3D Super-Resolution with Scarce High-Resolution Time-Varying Data"></a>129. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/CD-TVD__Contrastive_Diffusion_for_3D_Super-Resolution_with_Scarce_High-Resolution_Time-Varying_Data.pdf">CD-TVD: Contrastive Diffusion for 3D Super-Resolution with Scarce High-Resolution Time-Varying Data</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Tianjin University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†CD-TVDæ¡†æ¶ï¼Œé€šè¿‡å¯¹å†å²ç§‘å­¦ä»¿çœŸæ•°æ®çš„å¯¹æ¯”å­¦ä¹ ï¼Œç»“åˆå¸¦å±€éƒ¨æ³¨æ„åŠ›æœºåˆ¶çš„æ‰©æ•£è¶…åˆ†è¾¨ç‡æ¨¡å‹ï¼Œå®ç°äº†åœ¨é«˜åˆ†è¾¨ç‡æ—¶åºæ•°æ®ç¨€ç¼ºçš„æƒ…å†µä¸‹çš„3Dè¶…åˆ†è¾¨ç‡é‡å»ºã€‚æ–¹æ³•åˆ†ä¸ºé¢„è®­ç»ƒå’Œå¾®è°ƒä¸¤ä¸ªé˜¶æ®µï¼Œé¢„è®­ç»ƒé˜¶æ®µè”åˆå¯¹æ¯”ç¼–ç æ¨¡å—å’Œæ‰©æ•£è¶…åˆ†è¾¨ç‡æ¨¡å—å…±åŒå­¦ä¹ é€€åŒ–æ¨¡å¼å’Œç»†èŠ‚ç‰¹å¾ï¼Œå¾®è°ƒé˜¶æ®µä»…å†»ç»“ç¼–ç æ¨¡å—ï¼Œç”¨æå°‘é‡é«˜åˆ†è¾¨ç‡æ ·æœ¬å³å¯é€‚åº”æ–°åœºæ™¯ï¼Œå®ç°å¯¹æ‰€æœ‰ä½åˆ†è¾¨ç‡æ—¶åˆ»çš„å‡†ç¡®é‡æ„ã€‚å®éªŒç»“æœåœ¨å¤šç»„ç§‘å­¦ä»¿çœŸæ•°æ®ä¸Šå‡ä¼˜äºä¸»æµæ–¹æ³•ï¼Œæ˜¾è‘—é™ä½äº†å¯¹é«˜åˆ†è¾¨ç‡æ•°æ®çš„ä¾èµ–ï¼Œæå‡äº†ç§‘å­¦å¯è§†åŒ–ä»»åŠ¡ä¸­çš„å®é™…åº”ç”¨ä»·å€¼ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="130-Follow-Your-Shape-Shape-Aware-Image-Editing-via-Trajectory-Guided-Region-Control"><a href="#130-Follow-Your-Shape-Shape-Aware-Image-Editing-via-Trajectory-Guided-Region-Control" class="headerlink" title="130. Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control"></a>130. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Follow-Your-Shape__Shape-Aware_Image_Editing_via_Trajectory-Guided_Region_Control.pdf">Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">HKUST</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†Follow-Your-Shapeï¼Œä¸€ä¸ªæ— éœ€è®­ç»ƒå’Œæ©ç çš„å½¢çŠ¶æ„ŸçŸ¥å›¾åƒç¼–è¾‘æ¡†æ¶ï¼Œé€šè¿‡è½¨è¿¹å‘æ•£å›¾ï¼ˆTDMï¼‰åŠ¨æ€å®šä½å¯ç¼–è¾‘åŒºåŸŸï¼Œå¹¶ç»“åˆåˆ†é˜¶æ®µKey-Valueç‰¹å¾æ³¨å…¥ï¼Œå®ç°å¯¹ç›®æ ‡å¯¹è±¡å½¢çŠ¶çš„å¤§å¹…å˜åŒ–åŒæ—¶ç²¾å‡†ä¿ç•™èƒŒæ™¯å†…å®¹ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ–°è®¾è®¡çš„ReShapeBenchåŸºå‡†ä¸Šå½¢çŠ¶ç¼–è¾‘èƒ½åŠ›å’Œè§†è§‰ä¸€è‡´æ€§å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå®ç°äº†é«˜è´¨é‡çš„å›¾åƒç¼–è¾‘ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="131-MDD-Net-Multimodal-Depression-Detection-through-Mutual-Transformer"><a href="#131-MDD-Net-Multimodal-Depression-Detection-through-Mutual-Transformer" class="headerlink" title="131. MDD-Net: Multimodal Depression Detection through Mutual Transformer"></a>131. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/MDD-Net__Multimodal_Depression_Detection_through_Mutual_Transformer.pdf">MDD-Net: Multimodal Depression Detection through Mutual Transformer</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Waterloo</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºäº’å˜æ¢å™¨ï¼ˆMutual Transformer, MTï¼‰çš„å¤šæ¨¡æ€æŠ‘éƒæ£€æµ‹ç½‘ç»œMDD-Netï¼Œèåˆäº†éŸ³é¢‘å’Œè§†é¢‘ä¸¤ç§ç¤¾äº¤åª’ä½“æ•°æ®ã€‚æ–¹æ³•åŒ…æ‹¬å£°å­¦å’Œè§†è§‰ç‰¹å¾æå–æ¨¡å—ã€äº’å˜æ¢å™¨å®ç°è·¨æ¨¡æ€ç›¸å…³æ€§å»ºæ¨¡å’Œç‰¹å¾èåˆï¼Œæœ€ç»ˆé€šè¿‡æ£€æµ‹å±‚åˆ†ç±»ã€‚å®éªŒåœ¨D-Vlogæ•°æ®é›†ä¸Šè¡¨æ˜ï¼ŒMDD-Netåœ¨F1-Scoreä¸Šæ¯”ç°æœ‰æ–¹æ³•æå‡1.82%~17.37%ï¼Œæœ‰æ•ˆæå‡æŠ‘éƒæ£€æµ‹æ€§èƒ½ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="132-Sample-aware-RandAugment-Search-free-Automatic-Data-Augmentation-for-Effective-Image-Recognition"><a href="#132-Sample-aware-RandAugment-Search-free-Automatic-Data-Augmentation-for-Effective-Image-Recognition" class="headerlink" title="132. Sample-aware RandAugment: Search-free Automatic Data Augmentation for Effective Image Recognition"></a>132. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Sample-aware_RandAugment__Search-free_Automatic_Data_Augmentation_for_Effective_Image_Recognition.pdf">Sample-aware RandAugment: Search-free Automatic Data Augmentation for Effective Image Recognition</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Chinese Academy of Sciences</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ— éœ€æœç´¢çš„è‡ªåŠ¨æ•°æ®å¢å¼ºæ–¹æ³•Sample-aware RandAugment (SRA)ï¼Œé€šè¿‡è®¾è®¡å¯å‘å¼è¯„åˆ†æ¨¡å—ï¼ˆMagnitude Instructor Score, MISï¼‰å¯¹è®­ç»ƒæ ·æœ¬éš¾åº¦è¿›è¡ŒåŠ¨æ€è¯„ä¼°ï¼Œå¹¶é‡‡ç”¨ä¸å¯¹ç§°å¢å¼ºç­–ç•¥ï¼Œåˆ†åˆ«é’ˆå¯¹æ ·æœ¬æ¢ç´¢å’Œç²¾ç»†åŒ–è®­ç»ƒï¼Œè‡ªåŠ¨è°ƒæ•´å¢å¼ºç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSRAåœ¨ImageNetã€CIFARç­‰å¤šé¡¹è§†è§‰ä»»åŠ¡ä¸Šç¼©å°äº†ä¼ ç»Ÿæœç´¢å‹å’Œæ— æœç´¢å‹è‡ªåŠ¨å¢å¼ºæ–¹æ³•çš„æ€§èƒ½å·®è·ï¼Œæå‡äº†æ¨¡å‹æ³›åŒ–èƒ½åŠ›ï¼Œä¸”æ˜“äºé›†æˆè‡³ç°æœ‰è§†è§‰è®­ç»ƒæµç¨‹ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="133-Prompt-Guided-Relational-Reasoning-for-Social-Behavior-Understanding-with-Vision-Foundation-Models"><a href="#133-Prompt-Guided-Relational-Reasoning-for-Social-Behavior-Understanding-with-Vision-Foundation-Models" class="headerlink" title="133. Prompt-Guided Relational Reasoning for Social Behavior Understanding with Vision Foundation Models"></a>133. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Prompt-Guided_Relational_Reasoning_for_Social_Behavior_Understanding_with_Vision_Foundation_Models.pdf">Prompt-Guided Relational Reasoning for Social Behavior Understanding with Vision Foundation Models</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Stuttgart</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºProGraDçš„Prompté©±åŠ¨å‹ç¾¤ä½“æ´»åŠ¨æ£€æµ‹æ–¹æ³•ï¼Œé€šè¿‡åœ¨å†»ç»“çš„è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆå¦‚DINOv2ï¼‰ä¸Šæ³¨å…¥å¯å­¦ä¹ çš„ç¾¤ä½“æç¤ºï¼Œå¹¶è®¾è®¡äº†ä¸¤å±‚è½»é‡çº§GroupContext Transformerï¼Œå®ç°äº†å¯¹ç¤¾ä¼šè¡Œä¸ºä¸­ç¾¤ä½“æˆå‘˜å…³ç³»ä¸é›†ä½“æ´»åŠ¨çš„é«˜æ•ˆå»ºæ¨¡ã€‚å®éªŒè¯æ˜ï¼ŒProGraDåœ¨Cafeå’ŒSocial-CADä¸¤ä¸ªç¾¤ä½“æ´»åŠ¨æ£€æµ‹åŸºå‡†ä¸Šå‡å–å¾—æœ€æ–°æœ€ä¼˜æ€§èƒ½ï¼Œä»…éœ€çº¦1,000ä¸‡å¯è®­ç»ƒå‚æ•°ï¼Œå°¤å…¶åœ¨å¤šç»„å¤æ‚åœºæ™¯ä¸‹è¡¨ç°çªå‡ºï¼ŒåŒæ—¶å…·å¤‡è¾ƒå¼ºå¯è§£é‡Šæ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="134-Omni-Effects-Unified-and-Spatially-Controllable-Visual-Effects-Generation"><a href="#134-Omni-Effects-Unified-and-Spatially-Controllable-Visual-Effects-Generation" class="headerlink" title="134. Omni-Effects: Unified and Spatially Controllable Visual Effects Generation"></a>134. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Omni-Effects__Unified_and_Spatially-Controllable_Visual_Effects_Generation.pdf">Omni-Effects: Unified and Spatially Controllable Visual Effects Generation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">AMAP, Alibaba Group</span></p>
<p>Omni-Effectsæå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„è§†è§‰ç‰¹æ•ˆï¼ˆVFXï¼‰ç”Ÿæˆæ¡†æ¶ï¼Œæ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬åŸºäºLoRAçš„ä¸“å®¶æ··åˆï¼ˆLoRA-MoEï¼‰æ¨¡å—ï¼Œç”¨äºå‡å°‘å¤šç‰¹æ•ˆæ··è®­æ—¶çš„ç›¸äº’å¹²æ‰°ï¼Œä»¥åŠç»“åˆç©ºé—´æ„ŸçŸ¥æç¤ºï¼ˆSAPï¼‰ä¸ç‹¬ç«‹ä¿¡æ¯æµï¼ˆIIFï¼‰ï¼Œå®ç°å¯¹å¤šç‰¹æ•ˆåœ¨æŒ‡å®šåŒºåŸŸçš„ç²¾ç¡®æ§åˆ¶ã€‚å®éªŒå’Œæ–°å»ºOmni-VFXæ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†å¤šç‰¹æ•ˆåœ¨ç©ºé—´å’Œç±»åˆ«ä¸Šçš„å¯æ§æ€§ä¸ç”Ÿæˆè´¨é‡ï¼Œä¼˜äºç°æœ‰ä¸»æµæ–¹æ³•ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="135-Score-Augmentation-for-Diffusion-Models"><a href="#135-Score-Augmentation-for-Diffusion-Models" class="headerlink" title="135. Score Augmentation for Diffusion Models"></a>135. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Score_Augmentation_for_Diffusion_Models.pdf">Score Augmentation for Diffusion Models</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Kuaishou Technology</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†Score Augmentationï¼ˆScoreAugï¼‰ï¼Œä¸€ç§é’ˆå¯¹æ‰©æ•£æ¨¡å‹çš„åˆ›æ–°æ•°æ®å¢å¼ºæ¡†æ¶ã€‚æ–¹æ³•æ ¸å¿ƒåœ¨äºå¯¹å™ªå£°æ•°æ®è¿›è¡Œçº¿æ€§å’Œéçº¿æ€§å˜æ¢ï¼Œå¹¶è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„å»å™ªå™¨é¢„æµ‹å˜æ¢åçš„ç›®æ ‡ï¼Œä»è€Œå®ç°åˆ†æ•°ç©ºé—´çš„ç­‰å˜å­¦ä¹ ï¼ŒåŒæ—¶ç†è®ºåˆ†æäº†ä¸åŒå˜æ¢ç©ºé—´ä¸‹åˆ†æ•°çš„å¯¹åº”å…³ç³»ã€‚å®éªŒè¯æ˜ï¼ŒScoreAugåœ¨CIFAR-10ã€FFHQã€AFHQv2å’ŒImageNetç­‰å¤šä¸ªå›¾åƒç”ŸæˆåŸºå‡†ä¸Šæ˜¾è‘—ç¼“è§£äº†æ‰©æ•£æ¨¡å‹çš„è¿‡æ‹Ÿåˆï¼Œæå‡äº†ç”Ÿæˆè´¨é‡ä¸”ä¸å¸¸è§„å¢å¼ºæ–¹æ³•å…¼å®¹ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="136-Diffusing-the-Blind-Spot-Uterine-MRI-Synthesis-with-Diffusion-Models"><a href="#136-Diffusing-the-Blind-Spot-Uterine-MRI-Synthesis-with-Diffusion-Models" class="headerlink" title="136. Diffusing the Blind Spot: Uterine MRI Synthesis with Diffusion Models"></a>136. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Diffusing_the_Blind_Spot__Uterine_MRI_Synthesis_with_Diffusion_Models.pdf">Diffusing the Blind Spot: Uterine MRI Synthesis with Diffusion Models</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Friedrichâ€“Alexander University Erlangenâ€“NÃ¼rnberg</span></p>
<p>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹ï¼ˆåŒ…æ‹¬DDPMå’ŒLDMï¼‰çš„2Då’Œ3Då­å®«MRIå›¾åƒåˆæˆæ¡†æ¶ï¼Œç»“åˆæ— æ¡ä»¶å’Œæ¡ä»¶ï¼ˆç±»åˆ«æ ‡ç­¾åŠæ–‡æœ¬æè¿°ï¼‰ç”Ÿæˆé«˜ä¿çœŸã€è§£å‰–ç»“æ„å‡†ç¡®çš„åŒ»å­¦å½±åƒã€‚è¯¥æ–¹æ³•é€šè¿‡å¤šç§å…ˆè¿›æ„ŸçŸ¥ä¸åˆ†å¸ƒåº¦é‡è¯„ä¼°ç”Ÿæˆè´¨é‡ï¼Œæ˜¾è‘—æå‡äº†ä¸‹æ¸¸è¯Šæ–­æ¨¡å‹çš„å‡†ç¡®ç‡ï¼Œç‰¹åˆ«åœ¨å¼±ç›‘ç£æ•°æ®ç¨€ç¼ºåœºæ™¯ä¸‹ï¼Œåˆæˆæ•°æ®åœ¨åˆ†ç±»ä»»åŠ¡ä¸Šè¶…è¶ŠçœŸå®æ•°æ®ã€‚è®ºæ–‡æœ€ç»ˆå°†æ¨¡å‹å’Œæ•°æ®å…¬å¼€ï¼ŒåŠ©åŠ›å¦‡ç§‘AIç ”ç©¶çš„æ•°æ®å¯å¤ç°ä¸éšç§ä¿æŠ¤ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="137-Architectural-Co-Design-for-Zero-Shot-Anomaly-Detection-Decoupling-Representation-and-Dynamically-Fusing-Features-in-CLIP"><a href="#137-Architectural-Co-Design-for-Zero-Shot-Anomaly-Detection-Decoupling-Representation-and-Dynamically-Fusing-Features-in-CLIP" class="headerlink" title="137. Architectural Co-Design for Zero-Shot Anomaly Detection: Decoupling Representation and Dynamically Fusing Features in CLIP"></a>137. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Architectural_Co-Design_for_Zero-Shot_Anomaly_Detection__Decoupling_Representation_and_Dynamically_F.pdf">Architectural Co-Design for Zero-Shot Anomaly Detection: Decoupling Representation and Dynamically Fusing Features in CLIP</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Big Data Institute, Central South University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ACD-CLIPæ¡†æ¶ï¼Œç»“åˆå‚æ•°é«˜æ•ˆçš„Conv-LoRAé€‚é…å™¨ä¸åŠ¨æ€èåˆç½‘å…³ï¼ˆDFGï¼‰ï¼Œåˆ†åˆ«æ³¨å…¥å±€éƒ¨å½’çº³åç½®å¹¶å®ç°åŸºäºè§†è§‰å†…å®¹çš„çµæ´»åŒå‘æ–‡æœ¬ç‰¹å¾èåˆï¼Œä»è€Œæå‡å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹åœ¨é›¶æ ·æœ¬å¼‚å¸¸æ£€æµ‹ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚å®éªŒè¡¨æ˜è¯¥æ–¹æ³•åœ¨å·¥ä¸šå’ŒåŒ»å­¦æ•°æ®é›†ä¸Šè¶…è¶Šäº†ä¸»æµæ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†åˆ†å‰²ä¸åˆ†ç±»çš„å‡†ç¡®æ€§å’Œç¨³å®šæ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="138-MIND-A-Noise-Adaptive-Denoising-Framework-for-Medical-Images-Integrating-Multi-Scale-Transformer"><a href="#138-MIND-A-Noise-Adaptive-Denoising-Framework-for-Medical-Images-Integrating-Multi-Scale-Transformer" class="headerlink" title="138. MIND: A Noise-Adaptive Denoising Framework for Medical Images Integrating Multi-Scale Transformer"></a>138. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/MIND__A_Noise-Adaptive_Denoising_Framework_for_Medical_Images_Integrating_Multi-Scale_Transformer.pdf">MIND: A Noise-Adaptive Denoising Framework for Medical Images Integrating Multi-Scale Transformer</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Electronic Science and Technology of China</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§é›†æˆå¤šå°ºåº¦å·ç§¯ä¸Transformerç»“æ„çš„åŒ»å­¦å›¾åƒè‡ªé€‚åº”å»å™ªæ¨¡å‹MINDï¼Œå¼•å…¥å™ªå£°æ°´å¹³ä¼°è®¡å™¨ï¼ˆNLEï¼‰å’Œå™ªå£°è‡ªé€‚åº”æ³¨æ„åŠ›æ¨¡å—ï¼ˆNAABï¼‰ï¼Œå®ç°åŸºäºå™ªå£°æ„ŸçŸ¥çš„é€šé“-ç©ºé—´æ³¨æ„åŠ›è°ƒèŠ‚å’Œè·¨æ¨¡æ€ç‰¹å¾èåˆã€‚è¯¥æ–¹æ³•åœ¨å¤šæ¨¡æ€åŒ»å­¦å›¾åƒå…¬å¼€æ•°æ®é›†ä¸Šç³»ç»ŸéªŒè¯ï¼Œæ˜¾è‘—æå‡äº†PSNRã€SSIMã€LPIPSç­‰æŒ‡æ ‡ï¼Œå¹¶å¢å¼ºäº†ç»“æ„è¿˜åŸå’Œè¯Šæ–­æ•æ„Ÿæ€§ï¼Œå…·æœ‰å¼ºæ³›åŒ–èƒ½åŠ›å’Œå®é™…åº”ç”¨ä»·å€¼ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="139-DiTVR-Zero-Shot-Diffusion-Transformer-for-Video-Restoration"><a href="#139-DiTVR-Zero-Shot-Diffusion-Transformer-for-Video-Restoration" class="headerlink" title="139. DiTVR: Zero-Shot Diffusion Transformer for Video Restoration"></a>139. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/DiTVR__Zero-Shot_Diffusion_Transformer_for_Video_Restoration.pdf">DiTVR: Zero-Shot Diffusion Transformer for Video Restoration</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Wurzburg</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†DiTVRï¼Œä¸€ç§åŸºäºDiffusion Transformerï¼ˆDiTï¼‰çš„é›¶æ ·æœ¬è§†é¢‘ä¿®å¤æ¡†æ¶ï¼Œç»“åˆäº†è½¨è¿¹æ„ŸçŸ¥æ³¨æ„åŠ›æœºåˆ¶ã€å…‰æµå¼•å¯¼çš„æ‰©æ•£é‡‡æ ·å™¨å’Œæ—¶ç©ºé‚»å±…ç¼“å­˜ã€‚æ–¹æ³•é€šè¿‡å¯¹å…‰æµè½¨è¿¹çš„å»ºæ¨¡å’Œå…³é”®å±‚çš„æ—¶ç©ºæ³¨æ„åŠ›ï¼Œæœ‰æ•ˆæå‡äº†è§†é¢‘æ¢å¤çš„ç»†èŠ‚ä¿ç•™å’Œæ—¶åºä¸€è‡´æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒDiTVRåœ¨å¤šé¡¹è§†é¢‘ä¿®å¤åŸºå‡†ä¸Šè¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶åœ¨æ—¶åºä¸€è‡´æ€§ä¸é«˜ä¿çœŸæ¢å¤æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œæ— éœ€é’ˆå¯¹ç‰¹å®šä»»åŠ¡è®­ç»ƒã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="140-MambaTrans-Multimodal-Fusion-Image-Translation-via-Large-Language-Model-Priors-for-Downstream-Visual-Tasks"><a href="#140-MambaTrans-Multimodal-Fusion-Image-Translation-via-Large-Language-Model-Priors-for-Downstream-Visual-Tasks" class="headerlink" title="140. MambaTrans: Multimodal Fusion Image Translation via Large Language Model Priors for Downstream Visual Tasks"></a>140. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/MambaTrans__Multimodal_Fusion_Image_Translation_via_Large_Language_Model_Priors_for_Downstream_Visua.pdf">MambaTrans: Multimodal Fusion Image Translation via Large Language Model Priors for Downstream Visual Tasks</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Foshan University</span></p>
<p>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¤šæ¨¡æ€èåˆå›¾åƒæ¨¡æ€ç¿»è¯‘æ¡†æ¶MambaTransï¼Œé€šè¿‡å¼•å…¥å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬æè¿°ä¸åˆ†å‰²æ©ç ï¼Œè”åˆ3D-Selective Scan Moduleå’Œmask-image-text cross-attentionï¼Œæœ‰æ•ˆå®ç°äº†èåˆå›¾åƒåˆ°å¯è§å…‰åˆ†å¸ƒçš„è½¬æ¢ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMambaTransåœ¨æ— éœ€å¯¹ä¸‹æ¸¸æ¨¡å‹å‚æ•°è°ƒæ•´çš„æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡å¤šæ¨¡æ€èåˆå›¾åƒåœ¨ç›®æ ‡æ£€æµ‹å’Œè¯­ä¹‰åˆ†å‰²ç­‰ä¸‹æ¸¸è§†è§‰ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œä¸”ä¿æŒç”šè‡³æå‡äº†è§†è§‰è´¨é‡ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="141-RSVLM-QA-A-Benchmark-Dataset-for-Remote-Sensing-Vision-Language-Model-based-Question-Answering"><a href="#141-RSVLM-QA-A-Benchmark-Dataset-for-Remote-Sensing-Vision-Language-Model-based-Question-Answering" class="headerlink" title="141. RSVLM-QA: A Benchmark Dataset for Remote Sensing Vision Language Model-based Question Answering"></a>141. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/RSVLM-QA__A_Benchmark_Dataset_for_Remote_Sensing_Vision_Language_Model-based_Question_Answering.pdf">RSVLM-QA: A Benchmark Dataset for Remote Sensing Vision Language Model-based Question Answering</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Technology Sydney</span></p>
<p>æœ¬æ–‡æå‡ºRSVLM-QAæ•°æ®é›†ï¼Œé€šè¿‡é›†æˆå››ä¸ªä¸»æµé¥æ„Ÿåˆ†å‰²å’Œæ£€æµ‹æ•°æ®é›†ï¼ˆWHUã€LoveDAã€INRIAã€iSAIDï¼‰ï¼Œé‡‡ç”¨GPT-4.1é©±åŠ¨çš„åŒè½¨æ³¨é‡Šç”Ÿæˆæµç¨‹ï¼Œè‡ªåŠ¨ç”Ÿæˆä¸°å¯Œçš„å›¾åƒæè¿°ã€ç©ºé—´å…³ç³»ã€è¯­ä¹‰æ ‡ç­¾åŠå¤šæ ·åŒ–VQAå¯¹ã€‚è¯¥æ•°æ®é›†åŒ…æ‹¬13820å¼ å›¾ç‰‡å’Œ162373æ¡VQAå¯¹ï¼Œè¦†ç›–å…­å¤§ç±»é—®é¢˜ï¼Œæ”¯æŒå¤æ‚æ¨ç†ä¸ç²¾ç¡®è®¡æ•°ï¼Œå¹¶é€šè¿‡å…­ä¸ªä¸»æµVLMæ¨¡å‹çš„åŸºå‡†å®éªŒï¼ŒéªŒè¯äº†å…¶å¯¹é¥æ„Ÿè§†è§‰è¯­è¨€æ¨¡å‹ç†è§£å’Œæ¨ç†èƒ½åŠ›è¯„æµ‹çš„æœ‰æ•ˆæ€§ã€‚ç»“è®ºè¡¨æ˜ï¼ŒRSVLM-QAä¸ºé¥æ„ŸVQAå’Œå¤šæ¨¡æ€ç†è§£ç ”ç©¶æä¾›äº†é«˜è´¨é‡èµ„æºï¼Œèƒ½æœ‰æ•ˆæ¨åŠ¨é¢†åŸŸå‘å±•ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="142-Generative-Video-Matting"><a href="#142-Generative-Video-Matting" class="headerlink" title="142. Generative Video Matting"></a>142. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Generative_Video_Matting.pdf">Generative Video Matting</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">The University of Adelaide</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºç”Ÿæˆæ‰©æ•£æ¨¡å‹çš„è§†é¢‘æŠ åƒæ–¹æ³•ï¼ˆGVMï¼‰ï¼Œé€šè¿‡å¤§è§„æ¨¡åˆæˆä¸ä¼ªæ ‡æ³¨åˆ†å‰²æ•°æ®è¿›è¡Œå¤šé˜¶æ®µè®­ç»ƒï¼Œå¹¶ç»“åˆç»†ç²’åº¦åˆæˆæŠ åƒæ•°æ®ã€‚æ ¸å¿ƒæµç¨‹åŒ…æ‹¬åˆ©ç”¨Stable Video Diffusionæ¨¡å‹é¢„è®­ç»ƒã€æµåŒ¹é…ç›‘ç£åŠ é€Ÿæ¨ç†ã€å¤šç©ºé—´æ··åˆæŸå¤±æå‡ç»†èŠ‚ä¿ç•™ä¸æ—¶åºä¸€è‡´æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•é›†ä¸Šå¤§å¹…ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå…·å¤‡æå¼ºçš„æ³›åŒ–èƒ½åŠ›ä¸ç»†èŠ‚æ¢å¤èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="143-Segmenting-and-Understanding-Region-aware-Semantic-Attention-for-Fine-grained-Image-Quality-Assessment-with-Large-Language-Models"><a href="#143-Segmenting-and-Understanding-Region-aware-Semantic-Attention-for-Fine-grained-Image-Quality-Assessment-with-Large-Language-Models" class="headerlink" title="143. Segmenting and Understanding: Region-aware Semantic Attention for Fine-grained Image Quality Assessment with Large Language Models"></a>143. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Segmenting_and_Understanding__Region-aware_Semantic_Attention_for_Fine-grained_Image_Quality_Assessm.pdf">Segmenting and Understanding: Region-aware Semantic Attention for Fine-grained Image Quality Assessment with Large Language Models</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Harbin Institute of Technology</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†RSFIQAæ¨¡å‹ï¼Œç”¨äºæ— å‚è€ƒå›¾åƒè´¨é‡è¯„ä¼°ã€‚æ–¹æ³•é€šè¿‡SAMæ¨¡å‹å¯¹å›¾åƒè¿›è¡Œè¯­ä¹‰åˆ†å‰²ï¼Œç»“åˆå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLM)å¯¹æ¯ä¸ªåˆ†å‰²åŒºåŸŸè¿›è¡Œå¤šç»´å¤±çœŸåˆ†æï¼Œå¹¶é€šè¿‡åŒºåŸŸè¯­ä¹‰æ³¨æ„åŠ›æœºåˆ¶ï¼ˆRSAï¼‰èåˆåŒºåŸŸç‰¹å¾ï¼Œå®ç°å¯¹ä¸åŒè¯­ä¹‰åŒºåŸŸçš„ç»†ç²’åº¦è´¨é‡æ„ŸçŸ¥ã€‚å®éªŒç»“æœè¡¨æ˜RSFIQAåœ¨å¤šé¡¹IQAæ•°æ®é›†ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå…·æœ‰å¼ºæ³›åŒ–æ€§å’Œé²æ£’æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="144-Dream4D-Lifting-Camera-Controlled-I2V-towards-Spatiotemporally-Consistent-4D-Generation"><a href="#144-Dream4D-Lifting-Camera-Controlled-I2V-towards-Spatiotemporally-Consistent-4D-Generation" class="headerlink" title="144. Dream4D: Lifting Camera-Controlled I2V towards Spatiotemporally Consistent 4D Generation"></a>144. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Dream4D__Lifting_Camera-Controlled_I2V_towards_Spatiotemporally_Consistent_4D_Generation.pdf">Dream4D: Lifting Camera-Controlled I2V towards Spatiotemporally Consistent 4D Generation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">The Chinese University of Hong Kong</span></p>
<p>è¯¥è®ºæ–‡æå‡ºDream4Dæ¡†æ¶ï¼Œé€šè¿‡å°†å¯æ§å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆä¸ç¥ç»4Dé‡å»ºç›¸ç»“åˆï¼Œå®ç°äº†ä»å•å¼ å›¾åƒåŠæ–‡æœ¬æç¤ºç”Ÿæˆæ—¶ç©ºä¸€è‡´çš„4Dåœºæ™¯ã€‚å…¶æ–¹æ³•åŒ…æ‹¬é€šè¿‡è§†è§‰è¯­è¨€æ¨¡å‹é¢„æµ‹æœ€ä½³æ‘„åƒæœºè½¨è¿¹ï¼Œé‡‡ç”¨å§¿æ€æ¡ä»¶æ‰©æ•£æ¨¡å‹ç”Ÿæˆå¤šè§†è§’è§†é¢‘åºåˆ—ï¼Œæœ€ç»ˆä»¥4Dç”Ÿæˆå™¨æ¨¡å—æ˜ å°„ä¸ºæŒä¹…4Dè¡¨ç¤ºã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDream4Dåœ¨åŠ¨æ€åœºæ™¯çš„å‡ ä½•ç²¾åº¦å’Œæ—¶ç©ºä¸€è‡´æ€§æ–¹é¢æ˜¾è‘—è¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œæœ‰æ•ˆå‡å°‘äº†æ—¶åºé—ªçƒå’Œå½¢çŠ¶æ¼‚ç§»ï¼Œæå‡äº†åŠ¨æ€åœºæ™¯ç†è§£èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="145-Sea-Undistort-A-Dataset-for-Through-Water-Image-Restoration-in-High-Resolution-Airborne-Bathymetric-Mapping"><a href="#145-Sea-Undistort-A-Dataset-for-Through-Water-Image-Restoration-in-High-Resolution-Airborne-Bathymetric-Mapping" class="headerlink" title="145. Sea-Undistort: A Dataset for Through-Water Image Restoration in High Resolution Airborne Bathymetric Mapping"></a>145. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Sea-Undistort__A_Dataset_for_Through-Water_Image_Restoration_in_High_Resolution_Airborne_Bathymetric.pdf">Sea-Undistort: A Dataset for Through-Water Image Restoration in High Resolution Airborne Bathymetric Mapping</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Technische Universitat Berlin</span></p>
<p>æœ¬æ–‡æå‡ºäº†Sea-Undistortï¼Œä¸€ä¸ªåŒ…å«1200å¯¹é«˜åˆ†è¾¨ç‡æ°´ä¸‹åˆæˆå›¾åƒï¼ˆæœ‰&#x2F;æ— å…‰å­¦ç•¸å˜ï¼‰çš„æ•°æ®é›†ï¼Œç”¨äºè®­ç»ƒå’Œè¯„ä¼°æ·±åº¦å­¦ä¹ å›¾åƒæ¢å¤æ¨¡å‹ã€‚é€šè¿‡å¯¹ResShiftã€NDR-RestoreåŠå…¶æ”¹è¿›ç‰ˆResShift+EFï¼ˆèåˆå¤ªé˜³åå…‰æ©ç ï¼‰è¿›è¡Œå®éªŒï¼Œç»“æœæ˜¾ç¤ºåŸºäºè¯¥æ•°æ®é›†è®­ç»ƒçš„æ¨¡å‹åœ¨çœŸå®èˆªæ‹æ°´ä¸‹å½±åƒä¸Šæå‡äº†æµ·åº•å¯è§†æ€§ä¸æµ‹æ·±äº§å“è´¨é‡ï¼Œå°¤å…¶åœ¨æ·±æ°´åŒºåŸŸç»†èŠ‚æ¢å¤å’Œè¯¯å·®æŠ‘åˆ¶æ–¹é¢æ•ˆæœæ˜¾è‘—ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="146-Correspondence-as-Video-Test-Time-Adaption-on-SAM2-for-Reference-Segmentation-in-the-Wild"><a href="#146-Correspondence-as-Video-Test-Time-Adaption-on-SAM2-for-Reference-Segmentation-in-the-Wild" class="headerlink" title="146. Correspondence as Video: Test-Time Adaption on SAM2 for Reference Segmentation in the Wild"></a>146. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Correspondence_as_Video__Test-Time_Adaption_on_SAM2_for_Reference_Segmentation_in_the_Wild.pdf">Correspondence as Video: Test-Time Adaption on SAM2 for Reference Segmentation in the Wild</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Nanjing University</span></p>
<p>æœ¬æ–‡æå‡ºCAV-SAMæ–¹æ³•ï¼Œé€šè¿‡å°†å‚è€ƒ-ç›®æ ‡å›¾åƒå¯¹è½¬åŒ–ä¸ºä¼ªè§†é¢‘åºåˆ—ï¼Œå®ç°å¯¹SAM2æ¨¡å‹åœ¨ä¸‹æ¸¸ä»»åŠ¡çš„è½»é‡çº§é€‚åº”ã€‚æ–¹æ³•åŒ…æ‹¬DBSTæ¨¡å—åˆ©ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆè¯­ä¹‰å¹³æ»‘è¿‡æ¸¡åºåˆ—ï¼Œä»¥åŠTTGAæ¨¡å—é€šè¿‡æµ‹è¯•æ—¶å‡ ä½•å¯¹é½å¯¹SAM2è¿›è¡Œå¾®è°ƒå’Œé¢å¤–æç¤ºï¼Œå®ç°å‡ ä½•å˜å½¢çš„è‡ªé€‚åº”ã€‚å®éªŒè¡¨æ˜ï¼ŒCAV-SAMåœ¨CD-FSSåŸºå‡†ä¸Šåˆ†å‰²æ€§èƒ½è¶…è¿‡ç°æœ‰æ–¹æ³•çº¦5%ï¼Œåœ¨å¤æ‚çœŸå®åœºæ™¯å¦‚Chest X-Rayæ•°æ®ä¸Šè¡¨ç°çªå‡ºï¼ŒéªŒè¯äº†æ–¹æ³•çš„é«˜æ•ˆæ€§å’Œé²æ£’æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="147-Enhancing-Small-Scale-Dataset-Expansion-with-Triplet-Connection-based-Sample-Re-Weighting"><a href="#147-Enhancing-Small-Scale-Dataset-Expansion-with-Triplet-Connection-based-Sample-Re-Weighting" class="headerlink" title="147. Enhancing Small-Scale Dataset Expansion with Triplet-Connection-based Sample Re-Weighting"></a>147. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Enhancing_Small-Scale_Dataset_Expansion_with_Triplet-Connection-based_Sample_Re-Weighting.pdf">Enhancing Small-Scale Dataset Expansion with Triplet-Connection-based Sample Re-Weighting</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Hunan University</span></p>
<p>æœ¬æ–‡æå‡ºTriReWeightï¼Œä¸€ç§åŸºäºä¸‰å…ƒç»„è¿æ¥çš„æ ·æœ¬é‡åŠ æƒæ–¹æ³•ï¼Œç”¨äºæå‡ç”Ÿæˆå¼æ•°æ®æ‰©å¢åœ¨å°è§„æ¨¡å›¾åƒæ•°æ®é›†ä¸Šçš„æ•ˆæœã€‚è¯¥æ–¹æ³•é€šè¿‡ç†è®ºåˆ†æä¸‰ç±»ç”Ÿæˆå›¾åƒç›‘ç£æ–¹å¼ï¼Œç»“åˆä¸‰å…ƒç»„æŸå¤±å’Œä¸€è‡´æ€§æ­£åˆ™åŒ–ï¼Œæœ‰æ•ˆé™ä½å™ªå£°å›¾åƒå½±å“ï¼Œå¹¶è¯æ˜å¯ä¸ä»»æ„ç”Ÿæˆå¼æ•°æ®æ‰©å¢æ–¹æ³•ç»“åˆä¸”ä¸ä¼šé™ä½æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜TriReWeightåœ¨å…­ä¸ªè‡ªç„¶å›¾åƒå’Œä¸‰ä¸ªåŒ»å­¦å›¾åƒæ•°æ®é›†ä¸Šå¹³å‡æå‡åˆ†ç±»å‡†ç¡®ç‡ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œç†è®ºæ­£ç¡®æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="148-DoorDet-Semi-Automated-Multi-Class-Door-Detection-Dataset-via-Object-Detection-and-Large-Language-Models"><a href="#148-DoorDet-Semi-Automated-Multi-Class-Door-Detection-Dataset-via-Object-Detection-and-Large-Language-Models" class="headerlink" title="148. DoorDet: Semi-Automated Multi-Class Door Detection Dataset via Object Detection and Large Language Models"></a>148. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/DoorDet__Semi-Automated_Multi-Class_Door_Detection_Dataset_via_Object_Detection_and_Large_Language_M.pdf">DoorDet: Semi-Automated Multi-Class Door Detection Dataset via Object Detection and Large Language Models</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">The University of Melbourne</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»“åˆå…ˆè¿›ç›®æ ‡æ£€æµ‹å™¨ï¼ˆå¦‚Co-DETRï¼‰å’Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆå¦‚GPT-4.1ï¼‰ï¼Œå¹¶å¼•å…¥äººç±»æ ¡æ­£ç¯èŠ‚çš„åŠè‡ªåŠ¨åŒ–æµç¨‹ï¼Œç”¨äºæ„å»ºåŒ…å«é—¨å¤šç±»åˆ«åŠåŠŸèƒ½æ€§ç»†åˆ†çš„é«˜è´¨é‡é—¨æ£€æµ‹æ•°æ®é›†DoorDetã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æµç¨‹æ˜¾è‘—é™ä½äººå·¥æ ‡æ³¨æˆæœ¬ï¼Œæå‡æ ‡æ³¨æ•ˆç‡ï¼Œå¹¶ä¸”æ‰€æ„å»ºçš„æ•°æ®é›†å¯æœ‰æ•ˆæå‡å¤æ‚åœºæ™¯ä¸‹å¤šç±»é—¨æ£€æµ‹æ¨¡å‹çš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="149-Make-Your-MoVe-Make-Your-3D-Contents-by-Adapting-Multi-View-Diffusion-Models-to-External-Editing"><a href="#149-Make-Your-MoVe-Make-Your-3D-Contents-by-Adapting-Multi-View-Diffusion-Models-to-External-Editing" class="headerlink" title="149. Make Your MoVe: Make Your 3D Contents by Adapting Multi-View Diffusion Models to External Editing"></a>149. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Make_Your_MoVe__Make_Your_3D_Contents_by_Adapting_Multi-View_Diffusion_Models_to_External_Editing.pdf">Make Your MoVe: Make Your 3D Contents by Adapting Multi-View Diffusion Models to External Editing</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Tsinghua University</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ— é¡»å¾®è°ƒçš„ã€å³æ’å³ç”¨çš„æ–¹æ¡ˆï¼Œèƒ½å¤Ÿå°†å¤šè§†è§’æ‰©æ•£æ¨¡å‹ä¸å¤–éƒ¨2Dç¼–è¾‘å·¥å…·ç»“åˆï¼Œç”¨ä»¥ç”Ÿæˆé«˜ä¸€è‡´æ€§å’Œé«˜è´¨é‡çš„3Då†…å®¹ã€‚å…¶æ ¸å¿ƒæ–¹æ³•åŒ…æ‹¬å‡ ä½•ä¿æŒæ¨¡å—å’Œæ³¨å…¥å¼€å…³ï¼Œåˆ†åˆ«ç”¨äºåœ¨å•æ¬¡æ¨ç†ä¸­ä¿ç•™åŸå§‹å‡ ä½•ç»“æ„å¹¶çµæ´»æ§åˆ¶æ³•çº¿ç›‘ç£ç¨‹åº¦ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§ç¼–è¾‘å·¥å…·å’Œå¤šè§†è§’æ‰©æ•£æ¨¡å‹çš„ç»„åˆä¸‹æ˜¾è‘—æå‡äº†å¤šè§†è§’ä¸€è‡´æ€§å’Œç”Ÿæˆ3Dç½‘æ ¼çš„è´¨é‡ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="150-DiffVC-OSD-One-Step-Diffusion-based-Perceptual-Neural-Video-Compression-Framework"><a href="#150-DiffVC-OSD-One-Step-Diffusion-based-Perceptual-Neural-Video-Compression-Framework" class="headerlink" title="150. DiffVC-OSD: One-Step Diffusion-based Perceptual Neural Video Compression Framework"></a>150. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/DiffVC-OSD__One-Step_Diffusion-based_Perceptual_Neural_Video_Compression_Framework.pdf">DiffVC-OSD: One-Step Diffusion-based Perceptual Neural Video Compression Framework</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Wuhan University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºDiffVC-OSDçš„å•æ­¥æ‰©æ•£æ„ŸçŸ¥ç¥ç»è§†é¢‘å‹ç¼©æ¡†æ¶ï¼Œé€šè¿‡å°†é‡å»ºåçš„æ— å™ªå£°æ½œè¡¨ç¤ºç›´æ¥è¾“å…¥å•æ­¥æ‰©æ•£æ¨¡å‹ï¼Œå¹¶ç»“åˆæ—¶åºä¸Šä¸‹æ–‡è¿›è¡Œæ¡ä»¶å¼•å¯¼ï¼Œæ˜¾è‘—æå‡è§†é¢‘é‡å»ºçš„æ„ŸçŸ¥è´¨é‡ã€‚æ–¹æ³•è¿˜åŒ…æ‹¬æ—¶åºä¸Šä¸‹æ–‡é€‚é…å™¨å’Œç«¯åˆ°ç«¯å¾®è°ƒç­–ç•¥ï¼Œå®éªŒç»“æœè¡¨æ˜è¯¥æ–¹æ³•åœ¨ä¸»æµæ•°æ®é›†ä¸Šå®ç°äº†86.92%çš„ç ç‡ä¸‹é™å’Œçº¦20å€çš„è§£ç é€Ÿåº¦æå‡ï¼Œè¾¾åˆ°æœ€æ–°æ„ŸçŸ¥å‹ç¼©æ€§èƒ½ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="151-X2Edit-Revisiting-Arbitrary-Instruction-Image-Editing-through-Self-Constructed-Data-and-Task-Aware-Representation-Learning"><a href="#151-X2Edit-Revisiting-Arbitrary-Instruction-Image-Editing-through-Self-Constructed-Data-and-Task-Aware-Representation-Learning" class="headerlink" title="151. X2Edit: Revisiting Arbitrary-Instruction Image Editing through Self-Constructed Data and Task-Aware Representation Learning"></a>151. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/X2Edit__Revisiting_Arbitrary-Instruction_Image_Editing_through_Self-Constructed_Data_and_Task-Aware_.pdf">X2Edit: Revisiting Arbitrary-Instruction Image Editing through Self-Constructed Data and Task-Aware Representation Learning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">OPPO AI Center</span></p>
<p>æœ¬æ–‡æå‡ºäº†X2Edit Datasetï¼Œä¸€ä¸ªæ¶µç›–14ç±»ç¼–è¾‘ä»»åŠ¡ã€è§„æ¨¡è¾¾370ä¸‡çš„é«˜è´¨é‡å›¾åƒç¼–è¾‘æ•°æ®é›†ï¼Œå¹¶è®¾è®¡äº†åŸºäºFLUX.1çš„è½»é‡çº§ã€å¤šä¸“å®¶ï¼ˆMoE-LoRAï¼‰å’Œä»»åŠ¡æ„ŸçŸ¥å¯¹æ¯”å­¦ä¹ çš„X2Editæ¨¡å‹ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªå¼€æ”¾åŸºå‡†ä¸Šä¸SOTAæ¨¡å‹æ€§èƒ½ç›¸å½“ç”šè‡³ä¼˜äºéƒ¨åˆ†ä¸»æµæ–¹æ³•ï¼Œå…·å¤‡è‰¯å¥½çš„å¯æ‰©å±•æ€§ä¸æ’æ‹”èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="152-Separation-and-Collaboration-Two-Level-Routing-Grouped-Mixture-of-Experts-for-Multi-Domain-Continual-Learning"><a href="#152-Separation-and-Collaboration-Two-Level-Routing-Grouped-Mixture-of-Experts-for-Multi-Domain-Continual-Learning" class="headerlink" title="152. Separation and Collaboration: Two-Level Routing Grouped Mixture-of-Experts for Multi-Domain Continual Learning"></a>152. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Separation_and_Collaboration__Two-Level_Routing_Grouped_Mixture-of-Experts_for_Multi-Domain_Continua.pdf">Separation and Collaboration: Two-Level Routing Grouped Mixture-of-Experts for Multi-Domain Continual Learning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">National University of Defense Technology</span></p>
<p>è®ºæ–‡æå‡ºäº†Two-Level Routing Grouped Mixture-of-Experts (TRGE)æ–¹æ³•ï¼Œé’ˆå¯¹å¤šåŸŸè¿ç»­å­¦ä¹ ä¸­çš„ç¾éš¾æ€§é—å¿˜å’Œå‰å‘é—å¿˜é—®é¢˜ã€‚æ–¹æ³•é€šè¿‡åœ¨é¢„è®­ç»ƒçš„CLIPè§†è§‰è¯­è¨€æ¨¡å‹åŸºç¡€ä¸Šï¼Œä¸ºæ¯ä¸ªä»»åŠ¡æ‰©å±•ä¸“å®¶ç»„å¹¶å†»ç»“å†å²ä¸“å®¶ç»„ï¼Œç»“åˆç»„å†…é™æ€ä¸“å®¶æ•°å’Œç»„é—´åŠ¨æ€è·¯ç”±ç­–ç•¥ï¼Œæå‡ä»»åŠ¡åä½œä¸æŠ—é—å¿˜èƒ½åŠ›ï¼›åˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹å®ç°è¯­ä¹‰ä»»åŠ¡è¯†åˆ«ï¼Œå¹¶å¯¹æ¨¡å‹è¾“å‡ºè¿›è¡ŒåŠ¨æ€èåˆä»¥å¢å¼ºé›¶æ ·æœ¬æ³›åŒ–ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTRGEåœ¨å¤šåŸŸä»»åŠ¡å¢é‡å’Œç±»åˆ«å¢é‡åœºæ™¯ä¸‹å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸”å‚æ•°é‡æ›´å°‘ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="153-TAR-TVG-Enhancing-VLMs-with-Timestamp-Anchor-Constrained-Reasoning-for-Temporal-Video-Grounding"><a href="#153-TAR-TVG-Enhancing-VLMs-with-Timestamp-Anchor-Constrained-Reasoning-for-Temporal-Video-Grounding" class="headerlink" title="153. TAR-TVG: Enhancing VLMs with Timestamp Anchor-Constrained Reasoning for Temporal Video Grounding"></a>153. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/TAR-TVG__Enhancing_VLMs_with_Timestamp_Anchor-Constrained_Reasoning_for_Temporal_Video_Grounding.pdf">TAR-TVG: Enhancing VLMs with Timestamp Anchor-Constrained Reasoning for Temporal Video Grounding</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">South China University of Technology</span></p>
<p>è¯¥è®ºæ–‡æå‡ºTAR-TVGæ¡†æ¶ï¼Œåœ¨è§†é¢‘ç†è§£ä»»åŠ¡ä¸­åˆ©ç”¨æ—¶é—´æˆ³é”šç‚¹çº¦æŸæ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ï¼Œå®ç°é€æ­¥ç»†åŒ–çš„æ—¶åºå®šä½ã€‚æ–¹æ³•é‡‡ç”¨ä¸‰é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼ˆGRPOå¼ºåŒ–å­¦ä¹ ã€ç›‘ç£å¾®è°ƒã€å†å¼ºåŒ–å­¦ä¹ ï¼‰ï¼Œé€šè¿‡æ’å…¥æ—¶é—´æˆ³é”šç‚¹æå‡æ¨ç†å¯è§£é‡Šæ€§å’Œå®šä½ç²¾åº¦ã€‚å®éªŒè¡¨æ˜ï¼ŒTAR-TVGåœ¨Charades-STAç­‰åŸºå‡†æ•°æ®é›†å–å¾—äº†å½“å‰æœ€ä¼˜æ€§èƒ½ï¼Œæ˜¾è‘—æå‡äº†è§†é¢‘æ—¶åºå®šä½èƒ½åŠ›å’Œæ¨ç†é“¾æ¡çš„å¯éªŒè¯æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="154-LaRender-Training-Free-Occlusion-Control-in-Image-Generation-via-Latent-Rendering"><a href="#154-LaRender-Training-Free-Occlusion-Control-in-Image-Generation-via-Latent-Rendering" class="headerlink" title="154. LaRender: Training-Free Occlusion Control in Image Generation via Latent Rendering"></a>154. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/LaRender__Training-Free_Occlusion_Control_in_Image_Generation_via_Latent_Rendering.pdf">LaRender: Training-Free Occlusion Control in Image Generation via Latent Rendering</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Tencent</span></p>
<p>æœ¬æ–‡æå‡ºLaRenderï¼Œä¸€ç§æ— éœ€è®­ç»ƒçš„å›¾åƒç”Ÿæˆç®—æ³•ï¼Œèƒ½ç²¾å‡†æ§åˆ¶å›¾åƒä¸­ç‰©ä½“é—´çš„é®æŒ¡å…³ç³»ã€‚æ–¹æ³•é€šè¿‡åœ¨é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„æ½œç©ºé—´åº”ç”¨ä½“ç§¯æ¸²æŸ“åŸç†ï¼Œç»“åˆé®æŒ¡å›¾å’Œå¯¹è±¡é€å°„ç‡ï¼Œå®ç°ç‰©ä½“é®æŒ¡å’Œé€æ˜åº¦çš„ç‰©ç†ä¸€è‡´æ€§æ§åˆ¶ã€‚å®éªŒè¡¨æ˜ï¼ŒLaRenderåœ¨é®æŒ¡å‡†ç¡®æ€§ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶æ”¯æŒä¸°å¯Œçš„è§†è§‰æ•ˆæœå¦‚å¯¹è±¡é€æ˜åº¦å’Œå…‰æ•ˆè°ƒèŠ‚ã€‚ç»“è®ºï¼šLaRenderå®ç°äº†é«˜æ•ˆã€ç‰©ç†ä¸€è‡´çš„é®æŒ¡å’Œæ¦‚å¿µå¼ºåº¦æ§åˆ¶ï¼Œæ— éœ€é¢å¤–è®­ç»ƒã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="155-Breaking-Down-and-Building-Up-Mixture-of-Skill-Based-Vision-and-Language-Navigation-Agents"><a href="#155-Breaking-Down-and-Building-Up-Mixture-of-Skill-Based-Vision-and-Language-Navigation-Agents" class="headerlink" title="155. Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents"></a>155. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Breaking_Down_and_Building_Up__Mixture_of_Skill-Based_Vision-and-Language_Navigation_Agents.pdf">Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Michigan State University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºSkillNavï¼Œä¸€ç§å°†è§†è§‰-è¯­è¨€å¯¼èˆªä»»åŠ¡æ‹†è§£ä¸ºå¯è§£é‡Šçš„åŸå­æŠ€èƒ½ï¼ˆå¦‚æ–¹å‘è°ƒæ•´ã€å‚ç›´ç§»åŠ¨ã€åœ°æ ‡æ£€æµ‹ã€åŒºåŸŸè¯†åˆ«ç­‰ï¼‰çš„æ¨¡å—åŒ–æ¡†æ¶ã€‚é€šè¿‡LLMå¼•å¯¼çš„æŒ‡ä»¤é‡æ’åºå’ŒVLMé©±åŠ¨çš„è·¯ç”±å™¨åŠ¨æ€é€‰æ‹©æœ€åˆé€‚çš„æŠ€èƒ½ä»£ç†ï¼Œå®ç°å¯¹å¤æ‚ç¯å¢ƒå’Œæ–°æŒ‡ä»¤çš„å¼ºæ³›åŒ–èƒ½åŠ›ã€‚SkillNavåœ¨R2Rå’ŒGSA-R2Rç­‰ä¸»æµåŸºå‡†ä¸Šå–å¾—äº†SOTAæ€§èƒ½ï¼Œå®éªŒè¡¨æ˜å…¶æå‡äº†å¯¼èˆªæ•ˆç‡å’Œå¤šæ ·åœºæ™¯ä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h2 id="llm">Large Language Model</h2>


<h3 id="156-Surgical-Knowledge-Rewrite-in-Compact-LLMs-An-â€˜Unlearn-then-Learnâ€™-Strategy-with-IA3-for-Localized-Factual-Modulation-and-Catastrophic-Forgetting-Mitigation"><a href="#156-Surgical-Knowledge-Rewrite-in-Compact-LLMs-An-â€˜Unlearn-then-Learnâ€™-Strategy-with-IA3-for-Localized-Factual-Modulation-and-Catastrophic-Forgetting-Mitigation" class="headerlink" title="156. Surgical Knowledge Rewrite in Compact LLMs: An â€˜Unlearn-then-Learnâ€™ Strategy with (IA3) for Localized Factual Modulation and Catastrophic Forgetting Mitigation"></a>156. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Surgical_Knowledge_Rewrite_in_Compact_LLMs__An_'Unlearn-then-Learn'_Strategy_with_($IA%5E3$)_for_Local.pdf">Surgical Knowledge Rewrite in Compact LLMs: An â€˜Unlearn-then-Learnâ€™ Strategy with (IA3) for Localized Factual Modulation and Catastrophic Forgetting Mitigation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Stanford University</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§é’ˆå¯¹ç´§å‡‘å‹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„â€œunlearn-then-learnâ€çŸ¥è¯†ç¼–è¾‘ç­–ç•¥ï¼Œåˆ©ç”¨IA3å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯å’Œç”µè·¯å®šä½åˆ†æï¼Œåˆ†é˜¶æ®µå…ˆæŠ‘åˆ¶å†²çªæ—§çŸ¥è¯†å†æ³¨å…¥æ–°äº‹å®ï¼Œæœ‰æ•ˆå®ç°å±€éƒ¨åŒ–äº‹å®é‡å†™å¹¶æ˜¾è‘—ç¼“è§£ç¾éš¾æ€§é—å¿˜ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•å¯ç²¾ç¡®åœ°å°†æ–°äº‹å®èå…¥æ¨¡å‹ï¼ˆ98.5%å‡†ç¡®ç‡ï¼‰ï¼ŒåŒæ—¶å¤§å¹…æŠ‘åˆ¶åŸæœ‰å†²çªäº‹å®ï¼ˆ96%é—å¿˜ç‡ï¼‰ï¼Œä¸”ä¿ç•™äº†72%æ— å…³çŸ¥è¯†ï¼Œä¸ºå®‰å…¨ã€å¯æ§çš„åŠ¨æ€çŸ¥è¯†ç®¡ç†å¸¦æ¥çªç ´ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="157-Towards-Safer-AI-Moderation-Evaluating-LLM-Moderators-Through-a-Unified-Benchmark-Dataset-and-Advocating-a-Human-First-Approach"><a href="#157-Towards-Safer-AI-Moderation-Evaluating-LLM-Moderators-Through-a-Unified-Benchmark-Dataset-and-Advocating-a-Human-First-Approach" class="headerlink" title="157. Towards Safer AI Moderation: Evaluating LLM Moderators Through a Unified Benchmark Dataset and Advocating a Human-First Approach"></a>157. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Towards_Safer_AI_Moderation__Evaluating_LLM_Moderators_Through_a_Unified_Benchmark_Dataset_and_Advoc.pdf">Towards Safer AI Moderation: Evaluating LLM Moderators Through a Unified Benchmark Dataset and Advocating a Human-First Approach</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Fordham University</span></p>
<p>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„äººç±»æ ‡æ³¨æ•°æ®é›†ï¼Œæ¶µç›–49ç±»æƒ…æ„Ÿã€æ”»å‡»æ€§è¨€è®ºåŠåè§å†…å®¹ï¼Œå¹¶æ®æ­¤è¯„ä¼°äº†ä¸»æµLLMå†…å®¹å®¡æ ¸å™¨çš„èƒ½åŠ›ã€‚åŒæ—¶ï¼Œä½œè€…æå‡ºå¹¶å¾®è°ƒäº†SafePhiæ¨¡å‹ï¼ˆåŸºäºPhi-4ã€é‡‡ç”¨QLoRAï¼‰ï¼Œå…¶åœ¨å®F1åˆ†æ•°ä¸Šä¼˜äºOpenAI Moderatorå’ŒLlama Guardã€‚ç»“è®ºæŒ‡å‡ºï¼Œç°æœ‰LLMå®¡æ ¸å™¨åœ¨éšå«æ€§ä»‡æ¨ã€æ€§åˆ«ä¸ç§æ—åè§æ£€æµ‹ä¸Šè¡¨ç°æœ‰é™ï¼Œå¼ºè°ƒéœ€å¼•å…¥å¤šæ ·åŒ–æ•°æ®åŠäººç±»å‚ä¸ï¼Œä»¥æå‡æ¨¡å‹å¯é æ€§å’Œå¯è§£é‡Šæ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="158-ReasonRank-Empowering-Passage-Ranking-with-Strong-Reasoning-Ability"><a href="#158-ReasonRank-Empowering-Passage-Ranking-with-Strong-Reasoning-Ability" class="headerlink" title="158. ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability"></a>158. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/ReasonRank__Empowering_Passage_Ranking_with_Strong_Reasoning_Ability.pdf">ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Renmin University of China</span></p>
<p>è¯¥è®ºæ–‡æå‡ºReasonRankï¼Œä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†å¼ºåŒ–å‹æ–‡æœ¬é‡æ’æ–¹æ³•ã€‚æ–¹æ³•åŒ…æ‹¬è‡ªåŠ¨åˆæˆå¤šé¢†åŸŸæ¨ç†å¯†é›†å‹è®­ç»ƒæ•°æ®ï¼Œé€šè¿‡DeepSeek-R1ç”Ÿæˆé«˜è´¨é‡æ ‡ç­¾ï¼Œå¹¶é‡‡ç”¨è‡ªä¸€è‡´æ€§æ•°æ®ç­›é€‰ï¼›å†é€šè¿‡ä¸¤é˜¶æ®µè®­ç»ƒæ¡†æ¶ï¼Œå…ˆç”¨ç›‘ç£å¾®è°ƒ(SFT)å­¦ä¹ æ¨ç†æ¨¡å¼ï¼Œå†ç”¨å¤šè§†è§’å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ (RL)æå‡æ’åºèƒ½åŠ›ã€‚ç»“è®ºæ˜¾ç¤ºReasonRankåœ¨BRIGHTå’ŒR2MEDæ¨ç†å¯†é›†å‹ä¿¡æ¯æ£€ç´¢åŸºå‡†ä¸Šå–å¾—SOTAæ€§èƒ½ï¼Œæ•ˆç‡ä¼˜äºç°æœ‰åŸºçº¿ï¼Œå¹¶å…·å¤‡è¾ƒå¼ºé€šç”¨æ€§å’Œæ¨ç†èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="159-K-Dense-Analyst-Towards-Fully-Automated-Scientific-Analysis"><a href="#159-K-Dense-Analyst-Towards-Fully-Automated-Scientific-Analysis" class="headerlink" title="159. K-Dense Analyst: Towards Fully Automated Scientific Analysis"></a>159. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/K-Dense_Analyst__Towards_Fully_Automated_Scientific_Analysis.pdf">K-Dense Analyst: Towards Fully Automated Scientific Analysis</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Biostate AI</span></p>
<p>K-Dense Analystæ˜¯ä¸€ç§åŸºäºå±‚çº§å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„ç§‘å­¦åˆ†æå¹³å°ï¼Œé€šè¿‡åŒç¯æ¶æ„å®ç°è‡ªä¸»ç”Ÿç‰©ä¿¡æ¯å­¦åˆ†æï¼ŒåŒ…æ‹¬è§„åˆ’ã€éªŒè¯å’Œæ‰§è¡Œã€‚è¯¥æ–¹æ³•åœ¨BixBenchå¼€æ”¾å¼ç”Ÿç‰©åˆ†æåŸºå‡†ä¸Šå–å¾—äº†29.2%çš„å‡†ç¡®ç‡ï¼Œæ˜¾è‘—è¶…è¿‡å½“å‰æœ€å¼ºçš„è¯­è¨€æ¨¡å‹ï¼ˆå¦‚GPT-5ï¼‰ï¼Œè¯æ˜æ¶æ„åˆ›æ–°æ¯”æ¨¡å‹è§„æ¨¡æ›´é‡è¦ï¼Œæ¨åŠ¨äº†ç§‘å­¦åˆ†æçš„è‡ªåŠ¨åŒ–è¿›ç¨‹ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="160-From-Nodes-to-Narratives-Explaining-Graph-Neural-Networks-with-LLMs-and-Graph-Context"><a href="#160-From-Nodes-to-Narratives-Explaining-Graph-Neural-Networks-with-LLMs-and-Graph-Context" class="headerlink" title="160. From Nodes to Narratives: Explaining Graph Neural Networks with LLMs and Graph Context"></a>160. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/From_Nodes_to_Narratives__Explaining_Graph_Neural_Networks_with_LLMs_and_Graph_Context.pdf">From Nodes to Narratives: Explaining Graph Neural Networks with LLMs and Graph Context</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Illinois Chicago</span></p>
<p>æœ¬æ–‡æå‡ºäº†LOGICï¼Œä¸€ç§åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯¹å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰è¿›è¡Œè§£é‡Šçš„è½»é‡çº§åéªŒæ¡†æ¶ã€‚æ–¹æ³•æ ¸å¿ƒä¸ºå°†GNNèŠ‚ç‚¹åµŒå…¥æŠ•å½±åˆ°LLMçš„åµŒå…¥ç©ºé—´ï¼Œæ„å»ºèåˆè½¯æç¤ºå’Œç»“æ„æ–‡æœ¬çš„æ··åˆæç¤ºï¼Œé©±åŠ¨LLMç”Ÿæˆä¸æ¨¡å‹å†…éƒ¨è¡¨ç¤ºç›¸å…³çš„è‡ªç„¶è¯­è¨€è§£é‡ŠåŠè§£é‡Šå­å›¾ã€‚LOGICæ— éœ€é¢å¤–è®­ç»ƒï¼Œå¯ç›´æ¥éƒ¨ç½²åœ¨é¢„è®­ç»ƒGNNå’ŒLLMä¸Šï¼Œå®éªŒè¯æ˜å…¶åœ¨ä¿æŒé«˜ä¿çœŸåº¦çš„åŒæ—¶ç”Ÿæˆæ›´ç´§å‡‘ä¸”å…·å¤‡å¯è§£é‡Šæ€§çš„å­å›¾è§£é‡Šï¼Œå¹¶åœ¨äººç±»è¯„æµ‹ä¸­æå‡äº†å¯ç†è§£æ€§å’Œè¯´æœåŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="161-Investigating-Intersectional-Bias-in-Large-Language-Models-using-Confidence-Disparities-in-Coreference-Resolution"><a href="#161-Investigating-Intersectional-Bias-in-Large-Language-Models-using-Confidence-Disparities-in-Coreference-Resolution" class="headerlink" title="161. Investigating Intersectional Bias in Large Language Models using Confidence Disparities in Coreference Resolution"></a>161. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Investigating_Intersectional_Bias_in_Large_Language_Models_using_Confidence_Disparities_in_Coreferen.pdf">Investigating Intersectional Bias in Large Language Models using Confidence Disparities in Coreference Resolution</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Apple</span></p>
<p>è¯¥è®ºæ–‡æå‡ºWinoIdentityæ•°æ®é›†ï¼Œé€šè¿‡æ‰©å±•WinoBiasä¸º10ç±»å±æ€§ã€25ä¸ªç¾¤ä½“æ ‡è®°ï¼Œè®¾è®¡245,700ä¸ªæ¢æµ‹å¥ï¼Œå¹¶ç”¨â€œCoreference Confidence Disparityâ€ä¸å…¬å¹³æ€§æŒ‡æ ‡ï¼Œç³»ç»Ÿè¯„ä¼°äº”ç§ä¸»æµLLMsåœ¨å¤šé‡äº¤å‰èº«ä»½ä¸‹çš„æ¨ç†ä¸å…¬å¹³æ€§ã€‚ç»“æœå‘ç°LLMsåœ¨äº¤å‰èº«ä»½çš„æŒ‡ä»£æ¶ˆè§£ä»»åŠ¡ä¸­è¡¨ç°è¾ƒå·®ï¼Œå­˜åœ¨é«˜è¾¾40%çš„ç½®ä¿¡åº¦å·®å¼‚ï¼Œå°¤å…¶å¯¹åŒé‡åŠ£åŠ¿ç¾¤ä½“åè§æ›´ä¸¥é‡ï¼Œä¸”æ¨¡å‹æ›´å¤šä¾èµ–è®°å¿†è€ŒéçœŸå®æ¨ç†ï¼Œå‡¸æ˜¾ç°å®åº”ç”¨ä¸­çš„ç¤¾ä¼šä¼¤å®³é£é™©ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="162-Hide-or-Highlight-Understanding-the-Impact-of-Factuality-Expression-on-User-Trust"><a href="#162-Hide-or-Highlight-Understanding-the-Impact-of-Factuality-Expression-on-User-Trust" class="headerlink" title="162. Hide or Highlight: Understanding the Impact of Factuality Expression on User Trust"></a>162. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Hide_or_Highlight__Understanding_the_Impact_of_Factuality_Expression_on_User_Trust.pdf">Hide or Highlight: Understanding the Impact of Factuality Expression on User Trust</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">IBM Research</span></p>
<p>æœ¬æ–‡æå‡ºå¹¶æ¯”è¾ƒäº†äº”ç§åœ¨AIç”Ÿæˆå†…å®¹ä¸­è¡¨è¾¾äº‹å®æ€§çš„æ–¹æ³•ï¼ˆé€æ˜ã€æ³¨æ„ã€é®è”½ã€æ¨¡ç³Šã€åŸºçº¿ï¼‰ï¼Œå…¶ä¸­é®è”½å’Œæ¨¡ç³Šç­–ç•¥é€šè¿‡éšè—æˆ–å¼±åŒ–ä½äº‹å®æ€§å†…å®¹ï¼Œæœ‰æ•ˆæå‡äº†ç”¨æˆ·å¯¹AIç³»ç»Ÿçš„ä¿¡ä»»ä¸”ä¸æŸå®³ç­”æ¡ˆè´¨é‡ã€‚å®éªŒè¯æ˜ï¼Œéšè—ä½äº‹å®æ€§å†…å®¹æˆ–å°†å…¶æ”¹ä¸ºæ¨¡ç³Šè¡¨è¾¾æ›´èƒ½å¢å¼ºç”¨æˆ·ä¿¡ä»»ï¼Œä¼˜äºé«˜äº®æ˜¾ç¤ºç­–ç•¥ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="163-SEADialogues-A-Multilingual-Culturally-Grounded-Multi-turn-Dialogue-Dataset-on-Southeast-Asian-Languages"><a href="#163-SEADialogues-A-Multilingual-Culturally-Grounded-Multi-turn-Dialogue-Dataset-on-Southeast-Asian-Languages" class="headerlink" title="163. SEADialogues: A Multilingual Culturally Grounded Multi-turn Dialogue Dataset on Southeast Asian Languages"></a>163. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/SEADialogues__A_Multilingual_Culturally_Grounded_Multi-turn_Dialogue_Dataset_on_Southeast_Asian_Lang.pdf">SEADialogues: A Multilingual Culturally Grounded Multi-turn Dialogue Dataset on Southeast Asian Languages</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">MBZUAI</span></p>
<p>æœ¬è®ºæ–‡æå‡ºäº†SEADialogUESï¼Œè¿™æ˜¯ä¸€ä¸ªé¢å‘ä¸œå—äºšå…«ç§è¯­è¨€ã€å…­å›½å¤šæ–‡åŒ–èƒŒæ™¯çš„å¤šè½®ã€å¤šè¯­ç§ã€å…·å¤‡ä¸ªæ€§åŒ–è®¾å®šçš„å¯¹è¯æ•°æ®é›†ã€‚å…¶æ–¹æ³•åŒ…æ‹¬æ¨¡æ¿ç”Ÿæˆã€æ–‡åŒ–å…ƒç´ è¯æ±‡åŒ–ã€åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆå¯¹è¯ï¼Œå¹¶ç»“åˆäººå·¥ä¸LLMè‡ªåŠ¨è¯„æµ‹ï¼ŒéªŒè¯æ•°æ®çš„æ–‡åŒ–ç›¸å…³æ€§ã€æµç•…æ€§å’Œè‡ªç„¶åº¦ã€‚ç»“è®ºæ˜¾ç¤ºï¼ŒSEADialogUESèƒ½æœ‰æ•ˆä¿ƒè¿›æ–‡åŒ–æ•æ„Ÿã€ä¸ªæ€§åŒ–å¯¹è¯ç³»ç»Ÿçš„å‘å±•ï¼Œä¸”é«˜è´¨é‡çš„æ–‡åŒ–æ•°æ®é›†æœ‰åŠ©äºæå‡å¼€æºå¤§æ¨¡å‹æ€§èƒ½ï¼Œå¼¥è¡¥ä¸ä¸“æœ‰æ¨¡å‹çš„å·®è·ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="164-Membership-and-Memorization-in-LLM-Knowledge-Distillation"><a href="#164-Membership-and-Memorization-in-LLM-Knowledge-Distillation" class="headerlink" title="164. Membership and Memorization in LLM Knowledge Distillation"></a>164. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Membership_and_Memorization_in_LLM_Knowledge_Distillation.pdf">Membership and Memorization in LLM Knowledge Distillation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Peking University</span></p>
<p>æœ¬æ–‡ç³»ç»Ÿåˆ†æäº†å…­ç§å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çŸ¥è¯†è’¸é¦ï¼ˆKDï¼‰æŠ€æœ¯åœ¨éšç§ä¿æŠ¤æ–¹é¢çš„é£é™©ï¼Œä¸»è¦å…³æ³¨æˆå‘˜æ¨æ–­æ”»å‡»å’Œæ•°æ®è®°å¿†æ³„æ¼ã€‚é€šè¿‡å¤šæ¨¡å‹ã€å¤šä»»åŠ¡å®éªŒï¼Œä½œè€…å‘ç°æ‰€æœ‰ç°æœ‰ KD æ–¹æ³•éƒ½ä¼šå°†æ•™å¸ˆæ¨¡å‹çš„éšç§é£é™©ä¼ é€’ç»™å­¦ç”Ÿæ¨¡å‹ï¼Œä½†ä¸åŒæŠ€æœ¯æ³„æ¼ç¨‹åº¦ä¸åŒï¼Œå¹¶æå‡ºäº†æŒ‰æ¨¡å‹å—è¿›è¡Œç²¾ç»†åŒ–éšç§é£é™©åˆ†ææ¡†æ¶ã€‚ç»“è®ºè¡¨æ˜ï¼Œæ— è®ºé‡‡ç”¨å“ªç§è’¸é¦æ–¹æ³•ï¼Œå­¦ç”Ÿæ¨¡å‹éƒ½æ— æ³•å½»åº•ä¿æŠ¤æ•™å¸ˆæ¨¡å‹çš„è®­ç»ƒæ•°æ®éšç§ï¼Œä¸”éšç§æ³„æ¼åœ¨ä¸åŒæŠ€æœ¯å’Œæ¨¡å‹å—ä¹‹é—´å·®å¼‚æ˜¾è‘—ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="165-Whisfusion-Parallel-ASR-Decoding-via-a-Diffusion-Transformer"><a href="#165-Whisfusion-Parallel-ASR-Decoding-via-a-Diffusion-Transformer" class="headerlink" title="165. Whisfusion: Parallel ASR Decoding via a Diffusion Transformer"></a>165. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Whisfusion__Parallel_ASR_Decoding_via_a_Diffusion_Transformer.pdf">Whisfusion: Parallel ASR Decoding via a Diffusion Transformer</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Seoul National University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºWhisfusionæ¡†æ¶ï¼Œå°†é¢„è®­ç»ƒWhisperè¯­éŸ³ç¼–ç å™¨ä¸æ–‡æœ¬æ‰©æ•£è§£ç å™¨é€šè¿‡è½»é‡çº§Cross-Attentioné€‚é…å™¨èåˆï¼Œå®ç°äº†éè‡ªå›å½’ã€å…¨å¹¶è¡Œçš„ASRè§£ç æµç¨‹ï¼Œå¹¶è®¾è®¡äº†æ‰¹é‡å¹¶è¡Œå¤šæ­¥è§£ç ç­–ç•¥ï¼ˆPDDï¼‰ã€‚å®éªŒè¡¨æ˜ï¼ŒWhisfusionåœ¨LibriSpeechä¸Šç›¸è¾ƒäºWhisper-tinyæå‡äº†è¯†åˆ«å‡†ç¡®ç‡ï¼ˆ8.3% vs 9.7% WERï¼‰ï¼Œä¸”åœ¨é•¿è¯­éŸ³æ®µè½ä¸Šè§£ç é€Ÿåº¦æå‡æœ€é«˜è¾¾2.6å€ï¼Œå±•ç¤ºäº†æ‰©æ•£å¼éè‡ªå›å½’è§£ç åœ¨é«˜ååä½å»¶è¿ŸASRç³»ç»Ÿä¸­çš„å¯è¡Œæ€§å’Œé«˜æ•ˆæ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="166-Trustworthy-Medical-Imaging-with-Large-Language-Models-A-Study-of-Hallucinations-Across-Modalities"><a href="#166-Trustworthy-Medical-Imaging-with-Large-Language-Models-A-Study-of-Hallucinations-Across-Modalities" class="headerlink" title="166. Trustworthy Medical Imaging with Large Language Models: A Study of Hallucinations Across Modalities"></a>166. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Trustworthy_Medical_Imaging_with_Large_Language_Models__A_Study_of_Hallucinations_Across_Modalities.pdf">Trustworthy Medical Imaging with Large Language Models: A Study of Hallucinations Across Modalities</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">The University of Akron</span></p>
<p>æœ¬è®ºæ–‡ç³»ç»Ÿè¯„ä¼°äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨åŒ»å­¦å½±åƒä¸­çš„å¹»è§‰ç°è±¡ï¼Œæ¶µç›–å½±åƒè§£é‡Šï¼ˆimage-to-textï¼‰å’Œå½±åƒç”Ÿæˆï¼ˆtext-to-imageï¼‰ä»»åŠ¡ï¼Œé€šè¿‡å®šé‡å®éªŒåˆ†æäº†æ¨¡å‹åœ¨Xå°„çº¿ã€CTå’ŒMRIç­‰å¤šæ¨¡æ€å½±åƒæŠ¥å‘Šç”ŸæˆåŠåˆæˆå›¾åƒæ—¶å­˜åœ¨çš„äº‹å®ä¸ä¸€è‡´å’Œè§£å‰–é”™è¯¯ã€‚ç»“è®ºè¡¨æ˜ï¼Œå½“å‰LLMåœ¨åŒ»å­¦å½±åƒä»»åŠ¡ä¸­å­˜åœ¨å…³é”®å¯é æ€§æ¼æ´ï¼Œéœ€åŠ å¼ºåŒ»å­¦çº¦æŸå’Œé²æ£’æ€§ä»¥æå‡ä¸´åºŠå®‰å…¨ä¸ä¿¡ä»»ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="167-MultiMedEdit-A-Scenario-Aware-Benchmark-for-Evaluating-Knowledge-Editing-in-Medical-VQA"><a href="#167-MultiMedEdit-A-Scenario-Aware-Benchmark-for-Evaluating-Knowledge-Editing-in-Medical-VQA" class="headerlink" title="167. MultiMedEdit: A Scenario-Aware Benchmark for Evaluating Knowledge Editing in Medical VQA"></a>167. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/MultiMedEdit__A_Scenario-Aware_Benchmark_for_Evaluating_Knowledge_Editing_in_Medical_VQA.pdf">MultiMedEdit: A Scenario-Aware Benchmark for Evaluating Knowledge Editing in Medical VQA</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Nanjing University of Aeronautics and Astronautics</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†MultiMedEditï¼Œè¿™æ˜¯é¦–ä¸ªä¸“ä¸ºä¸´åºŠå¤šæ¨¡æ€ä»»åŠ¡è®¾è®¡çš„åŒ»å­¦çŸ¥è¯†ç¼–è¾‘è¯„æµ‹åŸºå‡†ï¼Œæ¶µç›–ç†è§£ä¸æ¨ç†ä¸¤ç±»ä»»åŠ¡ï¼Œå¹¶å»ºç«‹äº†å¯é æ€§ã€æ³›åŒ–æ€§å’Œå±€éƒ¨æ€§ä¸‰ç»´åº¦çš„è¯„ä¼°æ¡†æ¶ï¼Œæ”¯æŒè·¨èŒƒå¼æ–¹æ³•æ¯”è¾ƒã€‚å®éªŒè¡¨æ˜ï¼Œç°æœ‰çŸ¥è¯†ç¼–è¾‘æ–¹æ³•åœ¨å¤æ‚åŒ»å­¦åœºæ™¯ä¸‹è¡¨ç°å‡ºæ³›åŒ–èƒ½åŠ›å¼±ã€é•¿æœŸç¼–è¾‘æ˜“é—å¿˜å’Œç¨³å®šæ€§ä¸è¶³ç­‰é—®é¢˜ã€‚ç»“è®ºï¼šMultiMedEditæ­ç¤ºäº†å½“å‰æ–¹æ³•çš„å±€é™æ€§ï¼Œä¸ºæœªæ¥å¼€å‘æ›´å¯é åŒ»å­¦çŸ¥è¯†ç¼–è¾‘æŠ€æœ¯å¥ å®šäº†åŸºç¡€ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="168-MASteer-Multi-Agent-Adaptive-Steer-Strategy-for-End-to-End-LLM-Trustworthiness-Repair"><a href="#168-MASteer-Multi-Agent-Adaptive-Steer-Strategy-for-End-to-End-LLM-Trustworthiness-Repair" class="headerlink" title="168. MASteer: Multi-Agent Adaptive Steer Strategy for End-to-End LLM Trustworthiness Repair"></a>168. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/MASteer__Multi-Agent_Adaptive_Steer_Strategy_for_End-to-End_LLM_Trustworthiness_Repair.pdf">MASteer: Multi-Agent Adaptive Steer Strategy for End-to-End LLM Trustworthiness Repair</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Shanghai Jiao Tong University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºMASteerï¼Œé¦–ä¸ªåŸºäºè¡¨å¾å·¥ç¨‹çš„ç«¯åˆ°ç«¯å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯ä¿¡åº¦ä¿®å¤æ¡†æ¶ï¼ŒåŒ…å«å¤šæ™ºèƒ½ä½“æ ·æœ¬ç”Ÿæˆï¼ˆAutoTesterï¼‰å’Œè‡ªé€‚åº”ä¿®å¤ç­–ç•¥æ„å»ºï¼ˆAutoRepairerï¼‰ï¼Œå®ç°è‡ªåŠ¨åŒ–é—®é¢˜åˆ†æã€æ ·æœ¬æ„å»ºã€ç­–ç•¥é€‰å–ä¸æ¨ç†æ—¶åŠ¨æ€ä¿®å¤ã€‚å®éªŒè¯æ˜MASteeråœ¨å¤šé¡¹ä¿¡ä»»ä»»åŠ¡ä¸Šæ˜¾è‘—æå‡LLMçš„çœŸå®æ€§ã€å…¬å¹³æ€§ä¸å®‰å…¨æ€§ï¼Œä¸”ä¸æŸå®³æ¨¡å‹é€šç”¨èƒ½åŠ›ï¼Œå…·å¤‡é«˜æ•ˆã€å¯æ‰©å±•å’Œå®šåˆ¶åŒ–çš„å®é™…ä»·å€¼ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="169-BoRA-Towards-More-Expressive-Low-Rank-Adaptation-with-Block-Diversity"><a href="#169-BoRA-Towards-More-Expressive-Low-Rank-Adaptation-with-Block-Diversity" class="headerlink" title="169. BoRA: Towards More Expressive Low-Rank Adaptation with Block Diversity"></a>169. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/BoRA__Towards_More_Expressive_Low-Rank_Adaptation_with_Block_Diversity.pdf">BoRA: Towards More Expressive Low-Rank Adaptation with Block Diversity</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Huazhong University of Science and Technology</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†Block-Diversified Low-Rank Adaptation (BoRA)æ–¹æ³•ï¼Œé€šè¿‡å°†ä½ç§©çŸ©é˜µåˆ†å—å¹¶å¼•å…¥å—å¯¹è§’çŸ©é˜µï¼Œæœ‰æ•ˆæå‡äº†LoRAæƒé‡çš„ç§©å’Œè¡¨è¾¾èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒBoRAåœ¨å‚æ•°æ•°é‡æ¥è¿‘çš„æƒ…å†µä¸‹ï¼Œèƒ½æ¯”LoRAåŠå…¶å¤šç§å˜ä½“åœ¨å¤šä»»åŠ¡å’Œå¤šæ¨¡å‹åŸºå‡†æµ‹è¯•ä¸Šæå‡2-4%çš„å‡†ç¡®ç‡ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="170-AMFT-Aligning-LLM-Reasoners-by-Meta-Learning-the-Optimal-Imitation-Exploration-Balance"><a href="#170-AMFT-Aligning-LLM-Reasoners-by-Meta-Learning-the-Optimal-Imitation-Exploration-Balance" class="headerlink" title="170. AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance"></a>170. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/AMFT__Aligning_LLM_Reasoners_by_Meta-Learning_the_Optimal_Imitation-Exploration_Balance.pdf">AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Tsinghua University</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§å•é˜¶æ®µå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯¹é½ç®—æ³•AMFTï¼Œåˆ©ç”¨å…ƒå­¦ä¹ æ§åˆ¶å™¨åŠ¨æ€ä¼˜åŒ–æ¨¡ä»¿ï¼ˆSFTï¼‰ä¸æ¢ç´¢ï¼ˆRLï¼‰ä¹‹é—´çš„æƒé‡ï¼Œé€šè¿‡å…ƒæ¢¯åº¦è”åˆç†µå¯å‘å¼ï¼Œå®ç°åŸºäºéšå¼å’Œæ˜¾å¼å¥–åŠ±ä¿¡å·çš„è‡ªé€‚åº”è®­ç»ƒæµç¨‹ã€‚å®éªŒåœ¨æ•°å­¦æ¨ç†ã€å¤šæ¨¡æ€è§†è§‰æ¨ç†å’Œè§†è§‰-è¯­è¨€å¯¼èˆªä»»åŠ¡ä¸Šå‡å–å¾—äº†SOTAè¡¨ç°ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œæ ·æœ¬æ•ˆç‡ï¼Œé¿å…ç¾éš¾æ€§é—å¿˜å’Œç­–ç•¥åå¡Œã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="171-CLAP-Coreference-Linked-Augmentation-for-Passage-Retrieval"><a href="#171-CLAP-Coreference-Linked-Augmentation-for-Passage-Retrieval" class="headerlink" title="171. CLAP: Coreference-Linked Augmentation for Passage Retrieval"></a>171. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/CLAP__Coreference-Linked_Augmentation_for_Passage_Retrieval.pdf">CLAP: Coreference-Linked Augmentation for Passage Retrieval</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">The University of Adelaide</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†CLAPï¼Œä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ£€ç´¢å¢å¼ºæ¡†æ¶ï¼Œé€šè¿‡è¯­ä¹‰åˆ†å—ã€æŒ‡ä»£æ¶ˆè§£å’Œå±€éƒ¨ä¼ªæŸ¥è¯¢ç”Ÿæˆä¸‰æ­¥æµç¨‹ï¼Œå°†é•¿æ–‡æœ¬ç»“æ„åŒ–ä¸ºå¤šè§’åº¦ã€æ— æ­§ä¹‰çš„æ£€ç´¢ä¿¡å·ï¼Œå¹¶èåˆå…¨å±€ä¸ç»†ç²’åº¦ç›¸å…³æ€§åˆ†æ•°ã€‚åœ¨å¤šç§ä¸»æµç¨ å¯†å’Œç¨€ç–æ£€ç´¢å™¨åŠå¤šé¢†åŸŸæ•°æ®é›†ä¸Šï¼ŒCLAPæ˜¾è‘—æå‡äº†æ£€ç´¢æ€§èƒ½ï¼Œå°¤å…¶åœ¨é¢†åŸŸå¤–æ³›åŒ–åœºæ™¯ä¸‹è¡¨ç°ä¼˜å¼‚ï¼Œéƒ¨åˆ†æƒ…å†µä¸‹è¶…è¿‡äº†äºŒé˜¶æ®µé‡æ’åºå™¨ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="172-CROP-Integrating-Topological-and-Spatial-Structures-via-Cross-View-Prefixes-for-Molecular-LLMs"><a href="#172-CROP-Integrating-Topological-and-Spatial-Structures-via-Cross-View-Prefixes-for-Molecular-LLMs" class="headerlink" title="172. CROP: Integrating Topological and Spatial Structures via Cross-View Prefixes for Molecular LLMs"></a>172. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/CROP__Integrating_Topological_and_Spatial_Structures_via_Cross-View_Prefixes_for_Molecular_LLMs.pdf">CROP: Integrating Topological and Spatial Structures via Cross-View Prefixes for Molecular LLMs</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Science and Technology of China</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ›æ–°çš„åˆ†å­å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æ¶æ„CROPï¼Œé€šè¿‡SMILESå¼•å¯¼çš„è”åˆé‡é‡‡æ ·ï¼Œå°†åˆ†å­å›¾ï¼ˆæ‹“æ‰‘ç»“æ„ï¼‰å’Œåˆ†å­å›¾åƒï¼ˆç©ºé—´ç»“æ„ï¼‰ä¿¡æ¯èåˆä¸ºå›ºå®šé•¿åº¦å‰ç¼€ï¼Œæœ‰æ•ˆå¢å¼ºLLMå¯¹åˆ†å­çš„ç†è§£èƒ½åŠ›ã€‚å®éªŒè¯æ˜ï¼ŒCROPåœ¨åˆ†å­æè¿°ç”Ÿæˆã€IUPACå‘½åé¢„æµ‹å’Œåˆ†å­æ€§è´¨é¢„æµ‹ç­‰ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒéªŒè¯äº†å¤šè§†å›¾é›†æˆå’Œé«˜æ•ˆç»“æ„ä¿¡æ¯åˆ©ç”¨çš„æœ‰æ•ˆæ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="173-DocRefine-An-Intelligent-Framework-for-Scientific-Document-Understanding-and-Content-Optimization-based-on-Multimodal-Large-Model-Agents"><a href="#173-DocRefine-An-Intelligent-Framework-for-Scientific-Document-Understanding-and-Content-Optimization-based-on-Multimodal-Large-Model-Agents" class="headerlink" title="173. DocRefine: An Intelligent Framework for Scientific Document Understanding and Content Optimization based on Multimodal Large Model Agents"></a>173. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/DocRefine__An_Intelligent_Framework_for_Scientific_Document_Understanding_and_Content_Optimization_b.pdf">DocRefine: An Intelligent Framework for Scientific Document Understanding and Content Optimization based on Multimodal Large Model Agents</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Shangqiu University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºDocRefineæ¡†æ¶ï¼Œåˆ©ç”¨GPT-4oç­‰å…ˆè¿›è§†è§‰è¯­è¨€å¤§æ¨¡å‹ï¼ˆLVLMsï¼‰ï¼Œé€šè¿‡å…­å¤§å¤šæ™ºèƒ½ä½“åä½œï¼Œå®ç°å¯¹ç§‘å­¦PDFæ–‡æ¡£çš„ç»“æ„åˆ†æã€å¤šæ¨¡æ€å†…å®¹ç†è§£ã€æŒ‡ä»¤åˆ†è§£ã€å†…å®¹ä¼˜åŒ–ã€è‡ªåŠ¨æ€»ç»“å’Œä¸€è‡´æ€§éªŒè¯ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDocRefineåœ¨DocEditBenchæ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œåœ¨è¯­ä¹‰ä¸€è‡´æ€§ã€å¸ƒå±€ä¿çœŸå’ŒæŒ‡ä»¤éµå¾ªæ–¹é¢å‡å–å¾—äº†é¢†å…ˆæˆç»©ï¼Œæœ‰æ•ˆæå‡äº†å¤æ‚ç§‘å­¦æ–‡æ¡£çš„è‡ªåŠ¨åŒ–å¤„ç†èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="174-DATASETRESEARCH-Benchmarking-Agent-Systems-for-Demand-Driven-Dataset-Discovery"><a href="#174-DATASETRESEARCH-Benchmarking-Agent-Systems-for-Demand-Driven-Dataset-Discovery" class="headerlink" title="174. DATASETRESEARCH: Benchmarking Agent Systems for Demand-Driven Dataset Discovery"></a>174. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/DatasetResearch__Benchmarking_Agent_Systems_for_Demand-Driven_Dataset_Discovery.pdf">DATASETRESEARCH: Benchmarking Agent Systems for Demand-Driven Dataset Discovery</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Shanghai Jiao Tong University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†DATASETRESEARCHï¼Œè¿™æ˜¯é¦–ä¸ªç³»ç»Ÿè¯„ä¼°AIæ™ºèƒ½ä½“åŸºäºç”¨æˆ·éœ€æ±‚å‘ç°å’Œåˆæˆæ•°æ®é›†èƒ½åŠ›çš„ç»¼åˆåŸºå‡†ï¼ŒåŒ…æ‹¬208ä¸ªçœŸå®ä¸–ç•Œä»»åŠ¡ï¼Œè¦†ç›–çŸ¥è¯†å‹ä¸æ¨ç†å‹ä»»åŠ¡ã€‚é€šè¿‡ä¸‰ç»´è¯„æµ‹æ¡†æ¶ï¼Œå¯¹æœç´¢ã€åˆæˆå’Œæ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“åœ¨å…ƒæ•°æ®å¯¹é½ã€Few-shotå’Œå¾®è°ƒç­‰ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„è¡¨ç°è¿›è¡Œé‡åŒ–ï¼Œå‘ç°å½“å‰æœ€å…ˆè¿›ç³»ç»Ÿåœ¨é«˜éš¾åº¦å­é›†ä¸Šæœ€é«˜ä»…è¾¾22%ï¼Œæ­ç¤ºäº†ç°æœ‰æ–¹æ³•åœ¨é€šç”¨æ•°æ®å‘ç°ä¸Šçš„å·¨å¤§å·®è·ã€‚ç»“è®ºï¼šç°æœ‰æ™ºèƒ½ä½“åœ¨çŸ¥è¯†ä»»åŠ¡ä¸­æœç´¢è¡¨ç°ä¼˜å¼‚ï¼Œåœ¨æ¨ç†ä»»åŠ¡ä¸­åˆæˆæ–¹æ³•æ›´å¼ºï¼Œä½†åœ¨æç«¯â€œè§’è½æ¡ˆä¾‹â€ä¸Šå‡è¡¨ç°ä¸ä½³ï¼Œå‡¸æ˜¾AIæ•°æ®å‘ç°ä»æœ‰å¹¿é˜”æå‡ç©ºé—´ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="175-Large-Language-Models-Do-Not-Simulate-Human-Psychology"><a href="#175-Large-Language-Models-Do-Not-Simulate-Human-Psychology" class="headerlink" title="175. Large Language Models Do Not Simulate Human Psychology"></a>175. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Large_Language_Models_Do_Not_Simulate_Human_Psychology.pdf">Large Language Models Do Not Simulate Human Psychology</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Bielefeld University</span></p>
<p>æœ¬æ–‡é€šè¿‡ç†è®ºåˆ†æå’Œå®è¯ç ”ç©¶ï¼Œè¯„ä¼°äº†å½“å‰å¤§æ¨¡å‹ï¼ˆå¦‚GPT-4ã€Llama-3.1 70båŠCENTAURï¼‰æ˜¯å¦èƒ½æ¨¡æ‹Ÿäººç±»å¿ƒç†å­¦ã€‚ä½œè€…å‘ç°ï¼Œå°½ç®¡åœ¨éƒ¨åˆ†å¸¸è§„ä»»åŠ¡ä¸­LLMä¸äººç±»å“åº”é«˜åº¦ä¸€è‡´ï¼Œä½†å¯¹è¯­ä¹‰å˜åŒ–æ•æ„Ÿæ€§ä¸è¶³ï¼Œéš¾ä»¥å‡†ç¡®æ¨¡æ‹Ÿäººç±»å¿ƒç†ååº”ï¼Œç»“è®ºæ˜¯LLMä¸èƒ½æ›¿ä»£çœŸå®äººç±»å‚ä¸è€…ï¼Œéœ€è°¨æ…ç”¨äºå¿ƒç†å­¦å®éªŒã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="176-When-Prompt-Engineering-Meets-Software-Engineering-CNL-P-as-Natural-and-Robust-APIs-for-Human-AI-Interaction"><a href="#176-When-Prompt-Engineering-Meets-Software-Engineering-CNL-P-as-Natural-and-Robust-APIs-for-Human-AI-Interaction" class="headerlink" title="176. When Prompt Engineering Meets Software Engineering: CNL-P as Natural and Robust &quot;APIs&quot; for Human-AI Interaction"></a>176. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/When_Prompt_Engineering_Meets_Software_Engineering__CNL-P_as_Natural_and_Robust__APIs''_for_Human-AI.pdf">When Prompt Engineering Meets Software Engineering: CNL-P as Natural and Robust &quot;APIs&quot; for Human-AI Interaction</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">CSIROâ€™s Data61</span></p>
<p>æœ¬æ–‡æå‡ºäº†CNL-Pï¼ˆControlled Natural Language for Promptï¼‰ï¼Œèåˆäº†æç¤ºå·¥ç¨‹ï¼ˆPEï¼‰å’Œè½¯ä»¶å·¥ç¨‹ï¼ˆSEï¼‰æœ€ä½³å®è·µï¼Œé€šè¿‡ç²¾ç¡®å®šä¹‰è¯­æ³•ç»“æ„å’Œä¸¥æ ¼çš„è¯­ä¹‰è§„èŒƒï¼Œæ¶ˆé™¤è‡ªç„¶è¯­è¨€æç¤ºä¸­çš„æ­§ä¹‰ï¼Œå®ç°ç”¨æˆ·æ„å›¾çš„å‡†ç¡®è¡¨è¾¾ã€‚ä½œè€…å¼€å‘äº†NLåˆ°CNL-Pè‡ªåŠ¨è½¬æ¢å·¥å…·å’ŒCNL-P lintingé™æ€åˆ†æå·¥å…·ï¼Œå¹¶é€šè¿‡å¤§é‡å®éªŒéªŒè¯ï¼ŒCNL-På¯æå‡LLMçš„è¾“å‡ºè´¨é‡ï¼Œå…¶è¯­æ³•å’Œè¯­ä¹‰æ— éœ€é¢å¤–è¯´æ˜å³å¯è¢«ä¸»æµå¤§æ¨¡å‹æœ‰æ•ˆç†è§£ï¼Œä¸”lintingå·¥å…·èƒ½å¤Ÿé«˜æ•ˆå‘ç°å’Œå®šä½ç»“æ„åŒ–æç¤ºä¸­çš„è¯­æ³•ä¸è¯­ä¹‰é”™è¯¯ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="177-Model-Agnostic-Sentiment-Distribution-Stability-Analysis-for-Robust-LLM-Generated-Texts-Detection"><a href="#177-Model-Agnostic-Sentiment-Distribution-Stability-Analysis-for-Robust-LLM-Generated-Texts-Detection" class="headerlink" title="177. Model-Agnostic Sentiment Distribution Stability Analysis for Robust LLM-Generated Texts Detection"></a>177. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Model-Agnostic_Sentiment_Distribution_Stability_Analysis_for_Robust_LLM-Generated_Texts_Detection.pdf">Model-Agnostic Sentiment Distribution Stability Analysis for Robust LLM-Generated Texts Detection</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">School of Computer Science, Shanghai Jiao Tong University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†SentiDetectï¼Œä¸€ç§åŸºäºæƒ…æ„Ÿåˆ†å¸ƒç¨³å®šæ€§åˆ†æçš„æ¨¡å‹æ— å…³LLMç”Ÿæˆæ–‡æœ¬æ£€æµ‹æ¡†æ¶ã€‚æ–¹æ³•åŒ…æ‹¬ä½æƒ…æ„Ÿé‡å†™ã€æƒ…æ„Ÿåˆ†å¸ƒç‰¹å¾æå–åŠç¨³å®šæ€§åˆ†æï¼Œé€šè¿‡å®šä¹‰æƒ…æ„Ÿåˆ†å¸ƒä¸€è‡´æ€§å’Œä¿æŒæ€§æŒ‡æ ‡ï¼Œæ— éœ€æ¨¡å‹å‚æ•°æˆ–ç›‘ç£è®­ç»ƒå³å¯åŒºåˆ†LLMç”Ÿæˆæ–‡æœ¬å’Œäººç±»å†™ä½œã€‚å®éªŒè¯æ˜SentiDetectåœ¨äº”ä¸ªæ•°æ®é›†å’Œå¤šç§LLMï¼ˆå¦‚Gemini-1.5-Proã€Claude-3ã€GPT-4-0613ã€LLaMa-3.3ï¼‰ä¸ŠF1åˆ†æ•°æœ€é«˜æå‡è¶…16%ï¼Œä¸”å¯¹åŒä¹‰æ”¹å†™å’Œå¯¹æŠ—æ”»å‡»ç­‰å…·æœ‰æ›´å¼ºé²æ£’æ€§ã€‚ç»“è®ºï¼šSentiDetectæ˜¾è‘—æå‡LLMç”Ÿæˆæ–‡æœ¬æ£€æµ‹çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ï¼Œé€‚ç”¨äºå¤šé¢†åŸŸã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="178-BASIC-Boosting-Visual-Alignment-with-Intrinsic-Refined-Embeddings-in-Multimodal-Large-Language-Models"><a href="#178-BASIC-Boosting-Visual-Alignment-with-Intrinsic-Refined-Embeddings-in-Multimodal-Large-Language-Models" class="headerlink" title="178. BASIC: Boosting Visual Alignment with Intrinsic Refined Embeddings in Multimodal Large Language Models"></a>178. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/BASIC__Boosting_Visual_Alignment_with_Intrinsic_Refined_Embeddings_in_Multimodal_Large_Language_Mode.pdf">BASIC: Boosting Visual Alignment with Intrinsic Refined Embeddings in Multimodal Large Language Models</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Science and Technology of China</span></p>
<p>æœ¬æ–‡æå‡ºBASICæ–¹æ³•ï¼Œé€šè¿‡åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æµ…å±‚ä¸­çš„ç»†åŒ–è§†è§‰åµŒå…¥ä½œä¸ºç›‘ç£ä¿¡å·ï¼Œç›´æ¥å¼•å¯¼è§†è§‰æŠ•å½±å™¨ç”Ÿæˆæ›´ä¼˜çš„åˆå§‹è§†è§‰åµŒå…¥ï¼Œå®ç°è§†è§‰ä¸æ–‡æœ¬æ¨¡æ€çš„æ›´ç»†è‡´å¯¹é½ã€‚è¯¥æ–¹æ³•é€šè¿‡æ–¹å‘å¯¹é½å’Œè¯­ä¹‰åˆ†å¸ƒåŒ¹é…ä¸¤å¤§ä¼˜åŒ–ç›®æ ‡ï¼Œæ— éœ€é¢å¤–ç›‘ç£æ¨¡å‹æˆ–äººå·¥æ ‡æ³¨ï¼Œæ˜¾è‘—æå‡äº†å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨å¤šé¡¹ä¸»æµè§†è§‰ç†è§£åŸºå‡†ä¸Šçš„è¡¨ç°ï¼ŒéªŒè¯äº†ç›´æ¥è§†è§‰ç›‘ç£çš„æœ‰æ•ˆæ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="179-MeteorPred-A-Meteorological-Multimodal-Large-Model-and-Dataset-for-Severe-Weather-Event-Prediction"><a href="#179-MeteorPred-A-Meteorological-Multimodal-Large-Model-and-Dataset-for-Severe-Weather-Event-Prediction" class="headerlink" title="179. MeteorPred: A Meteorological Multimodal Large Model and Dataset for Severe Weather Event Prediction"></a>179. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/MeteorPred__A_Meteorological_Multimodal_Large_Model_and_Dataset_for_Severe_Weather_Event_Prediction.pdf">MeteorPred: A Meteorological Multimodal Large Model and Dataset for Severe Weather Event Prediction</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Institute of Automation, Chinese Academy of Sciences</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†MP-Benchå¤§è§„æ¨¡æ°”è±¡å¤šæ¨¡æ€æ•°æ®é›†ï¼Œå¹¶åŸºäºæ­¤å¼€å‘äº†æ°”è±¡å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆMMLMï¼‰ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿç›´æ¥å¤„ç†4Dæ°”è±¡æ•°æ®è¾“å…¥ï¼Œå¹¶é›†æˆäº†ä¸‰ç§è‡ªé€‚åº”ç‰¹å¾èåˆæ¨¡å—ï¼ˆDTGFã€TGSã€TGCAï¼‰ï¼Œåˆ†åˆ«æå‡æ¨¡å‹åœ¨æ—¶é—´ã€ç©ºé—´å’Œå‚ç›´å‹åŠ›å±‚ç»´åº¦ä¸Šçš„ç‰¹å¾æŠ½å–ä¸èåˆèƒ½åŠ›ã€‚å®éªŒè¡¨æ˜MMLMåœ¨å¤šé¡¹ä¸¥é…·å¤©æ°”äº‹ä»¶é¢„æµ‹ä¸é—®ç­”ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰å¼€æºå’Œé—­æºæ–¹æ³•ï¼Œä¸ºè‡ªåŠ¨åŒ–AIé©±åŠ¨çš„å¤©æ°”é¢„æŠ¥ç³»ç»Ÿæä¾›äº†å…³é”®è¿›å±•ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="180-Highlight-All-the-Phrases-Enhancing-LLM-Transparency-through-Visual-Factuality-Indicators"><a href="#180-Highlight-All-the-Phrases-Enhancing-LLM-Transparency-through-Visual-Factuality-Indicators" class="headerlink" title="180. Highlight All the Phrases: Enhancing LLM Transparency through Visual Factuality Indicators"></a>180. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Highlight_All_the_Phrases__Enhancing_LLM_Transparency_through_Visual_Factuality_Indicators.pdf">Highlight All the Phrases: Enhancing LLM Transparency through Visual Factuality Indicators</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">IBM Research, Cambridge, MA, USA</span></p>
<p>æœ¬è®ºæ–‡æå‡ºå¹¶ç³»ç»Ÿè¯„ä¼°äº†å¤šç§ç”¨äºåœ¨LLMé—®ç­”åœºæ™¯ä¸­å¯è§†åŒ–å±•ç¤ºäº‹å®æ€§åˆ†æ•°çš„è®¾è®¡ç­–ç•¥ï¼ŒåŒ…æ‹¬å…¨çŸ­è¯­é«˜äº®ã€é˜ˆå€¼é«˜äº®å’Œæ•°å€¼æ ‡æ³¨ï¼Œç²’åº¦åˆ†ä¸ºè¯çº§å’ŒçŸ­è¯­çº§ã€‚é€šè¿‡ä¸¤è½®ç”¨æˆ·å®éªŒå‘ç°ï¼ŒåŸºäºäº‹å®æ€§åˆ†æ•°å¯¹æ‰€æœ‰çŸ­è¯­è¿›è¡Œé«˜äº®çš„å¯è§†åŒ–è®¾è®¡æœ€å—ç”¨æˆ·åå¥½ã€ä¿¡ä»»åº¦æœ€é«˜ä¸”èƒ½æ˜¾è‘—æå‡ç”¨æˆ·æ ¡éªŒLLMè¾“å‡ºå‡†ç¡®æ€§çš„ä¾¿åˆ©æ€§ï¼Œå»ºè®®å¼€å‘è€…ä¼˜å…ˆé‡‡ç”¨è¯¥è®¾è®¡ä»¥æå‡ç”¨æˆ·å¯¹LLMè¾“å‡ºçš„ä¿¡ä»»ä¸è¾¨åˆ«èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="181-BiXSE-Improving-Dense-Retrieval-via-Probabilistic-Graded-Relevance-Distillation"><a href="#181-BiXSE-Improving-Dense-Retrieval-via-Probabilistic-Graded-Relevance-Distillation" class="headerlink" title="181. BiXSE: Improving Dense Retrieval via Probabilistic Graded Relevance Distillation"></a>181. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/BiXSE__Improving_Dense_Retrieval_via_Probabilistic_Graded_Relevance_Distillation.pdf">BiXSE: Improving Dense Retrieval via Probabilistic Graded Relevance Distillation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Universite de MontrÃ©al</span></p>
<p>è¯¥è®ºæ–‡æå‡ºBiXSEæ–¹æ³•ï¼Œç”¨äºŒå…ƒäº¤å‰ç†µæŸå¤±ç›´æ¥å¯¹LLMç”Ÿæˆçš„è¿ç»­å‹åˆ†çº§ç›¸å…³æ€§æ ‡ç­¾è¿›è¡Œè®­ç»ƒï¼Œå®ç°äº†æ›´ç»†ç²’åº¦çš„ç›‘ç£ä¿¡æ¯æ³¨å…¥åˆ°å¯†é›†æ£€ç´¢æ¨¡å‹ã€‚å®éªŒè¡¨æ˜ï¼ŒBiXSEåœ¨å¤šç§æ£€ç´¢ä¸å¥å­åµŒå…¥åŸºå‡†ä¸Šå‡ä¼˜äºæ ‡å‡†InfoNCEå¯¹æ¯”å­¦ä¹ ç›®æ ‡ï¼Œå¹¶å¯¹æ ‡ç­¾å™ªå£°è¡¨ç°å‡ºæ›´å¼ºé²æ£’æ€§ï¼Œæ˜¯é«˜æ•ˆä¸”å¯æ‰©å±•çš„LLMçŸ¥è¯†è’¸é¦æ–¹æ¡ˆã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="182-Zero-Direction-Probing-A-Linear-Algebraic-Framework-for-Deep-Analysis-of-Large-Language-Model-Drift"><a href="#182-Zero-Direction-Probing-A-Linear-Algebraic-Framework-for-Deep-Analysis-of-Large-Language-Model-Drift" class="headerlink" title="182. Zero-Direction Probing: A Linear-Algebraic Framework for Deep Analysis of Large-Language-Model Drift"></a>182. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Zero-Direction_Probing__A_Linear-Algebraic_Framework_for_Deep_Analysis_of_Large-Language-Model_Drift.pdf">Zero-Direction Probing: A Linear-Algebraic Framework for Deep Analysis of Large-Language-Model Drift</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">AI Analytics</span></p>
<p>æœ¬æ–‡æå‡ºäº†Zero-Direction Probing (ZDP)ç†è®ºæ¡†æ¶ï¼Œåˆ©ç”¨å˜æ¢å™¨å±‚æ¿€æ´»çŸ©é˜µçš„å·¦å³é›¶ç©ºé—´ï¼ˆnull spaceï¼‰åŠå…¶Fisherä¿¡æ¯å‡ ä½•æ¥åˆ»ç”»å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¡¨ç¤ºæ¼‚ç§»ï¼Œæ— éœ€æ ‡ç­¾æˆ–è¾“å‡ºï¼Œä»…åŸºäºçº¿æ€§ä»£æ•°å’Œä¿¡æ¯å‡ ä½•å·¥å…·ã€‚æ ¸å¿ƒè´¡çŒ®åŒ…æ‹¬ï¼šè¯æ˜äº†æ¼‚ç§»ä¸é›¶ç©ºé—´èƒ½é‡ä¹‹é—´çš„Varianceâ€“Leakå®šç†ï¼Œæå‡ºFisher Null-Conservationå®šç†ã€ä½ç§©LoRAæ›´æ–°çš„Rankâ€“Leakç•Œã€åŸºäºéšæœºçŸ©é˜µç†è®ºçš„æ— å‚æ•°æ¼‚ç§»é˜ˆå€¼ï¼Œä»¥åŠåœ¨çº¿é›¶ç©ºé—´è·Ÿè¸ªä¸æ¼‚ç§»ä¿è¯ã€‚ç»“è®ºæŒ‡å‡ºï¼šåªè¦â€œç›‘å¬æ²‰é»˜â€ï¼ˆç›‘æ§é›¶ç©ºé—´ï¼‰ï¼Œå°±èƒ½å®ç°å¯éªŒè¯çš„æ¨¡å‹è¡¨ç¤ºå˜åŒ–æ£€æµ‹ï¼Œç†è®ºç»“æœç›´æ¥é¢å‘å®è·µï¼Œä¸”æ‰€æœ‰å®šç†ç»éªŒè¯å‡å¯è¿ç§»ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="183-Many-Turn-Jailbreaking"><a href="#183-Many-Turn-Jailbreaking" class="headerlink" title="183. Many-Turn Jailbreaking"></a>183. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Many-Turn_Jailbreaking.pdf">Many-Turn Jailbreaking</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of California, Santa Barbara</span></p>
<p>è¯¥è®ºæ–‡é¦–æ¬¡ç³»ç»Ÿæ€§ç ”ç©¶äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šè½®å¯¹è¯åœºæ™¯ä¸‹çš„è¶Šç‹±æ”»å‡»é—®é¢˜ï¼Œæå‡ºâ€œMany-Turn Jailbreakingâ€æ¦‚å¿µï¼Œå¹¶åˆ›å»ºäº†MTJ-Benchå¤šè½®è¶Šç‹±è¯„æµ‹åŸºå‡†ï¼Œå¯¹14ä¸ªå¼€æºå’Œ1ä¸ªé—­æºæ¨¡å‹è¿›è¡Œäº†å®è¯æµ‹è¯•ã€‚ç»“æœæ˜¾ç¤ºï¼Œä¸€æ—¦æ¨¡å‹åœ¨é¦–è½®è¢«è¶Šç‹±åï¼Œåç»­ç›¸å…³æˆ–æ— å…³é—®é¢˜å‡æ˜“è¢«æŒç»­æ”»ç ´ï¼Œå®‰å…¨éšæ‚£è¿œè¶…ä»¥å¾€å•è½®è¶Šç‹±ï¼ŒäºŸéœ€ç¤¾åŒºå…³æ³¨å’Œé˜²æŠ¤ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="184-MDK12-Bench-A-Comprehensive-Evaluation-of-Multimodal-Large-Language-Models-on-Multidisciplinary-Exams"><a href="#184-MDK12-Bench-A-Comprehensive-Evaluation-of-Multimodal-Large-Language-Models-on-Multidisciplinary-Exams" class="headerlink" title="184. MDK12-Bench: A Comprehensive Evaluation of Multimodal Large Language Models on Multidisciplinary Exams"></a>184. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/MDK12-Bench__A_Comprehensive_Evaluation_of_Multimodal_Large_Language_Models_on_Multidisciplinary_Exa.pdf">MDK12-Bench: A Comprehensive Evaluation of Multimodal Large Language Models on Multidisciplinary Exams</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Shanghai AI Laboratory</span></p>
<p>æœ¬æ–‡æå‡ºMDK12-Benchï¼Œä¸€ä¸ªå¤§è§„æ¨¡å¤šå­¦ç§‘ã€å¤šæ¨¡æ€åŸºå‡†ï¼Œæ¶µç›–6ä¸ªå­¦ç§‘ã€141K K-12çœŸå®è€ƒè¯•é¢˜ï¼Œå¹¶ä»¥å…­å±‚çŸ¥è¯†ç‚¹ä½“ç³»ç»„ç»‡ã€‚æ–¹æ³•åŒ…æ‹¬å¤šç»´åº¦åŠ¨æ€è¯„æµ‹æ¡†æ¶å’ŒçŸ¥è¯†ç‚¹å‚è€ƒå¢å¼ºç”Ÿæˆï¼ˆKP-RAGï¼‰ï¼Œç³»ç»Ÿè¯„ä¼°MLLMåœ¨éš¾åº¦ã€æ—¶é—´ã€ä¸Šä¸‹æ–‡å’ŒçŸ¥è¯†åˆ©ç”¨æ–¹é¢çš„æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒå‘ç°ï¼Œç°æœ‰MLLMå¯¹åŠ¨æ€æ‰°åŠ¨ä¸æ–°é¢–ä»»åŠ¡æ•æ„Ÿï¼Œåœ¨å¤æ‚æ¨ç†å’ŒçŸ¥è¯†æ•´åˆä¸Šå­˜åœ¨æ˜æ˜¾çŸ­æ¿ï¼ŒKP-RAGå¯¹å›°éš¾é¢˜æå‡æœ‰é™ã€‚ç»“è®ºè¡¨æ˜ï¼ŒMDK12-Benchæœ‰åŠ©äºç²¾å‡†è¯Šæ–­å¤šæ¨¡æ€å¤§æ¨¡å‹çš„ä¼˜åŠ¿ä¸ä¸è¶³ï¼Œä¸ºæœªæ¥æ›´å¼ºæ³›åŒ–å’Œæ¨ç†èƒ½åŠ›çš„AIå‘å±•æä¾›æ–¹å‘ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="185-Remote-Sensing-Image-Intelligent-Interpretation-with-the-Language-Centered-Perspective-Principles-Methods-and-Challenges"><a href="#185-Remote-Sensing-Image-Intelligent-Interpretation-with-the-Language-Centered-Perspective-Principles-Methods-and-Challenges" class="headerlink" title="185. Remote Sensing Image Intelligent Interpretation with the Language-Centered Perspective: Principles, Methods and Challenges"></a>185. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Remote_Sensing_Image_Intelligent_Interpretation_with_the_Language-Centered_Perspective__Principles,_.pdf">Remote Sensing Image Intelligent Interpretation with the Language-Centered Perspective: Principles, Methods and Challenges</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Central South University</span></p>
<p>æœ¬æ–‡æå‡ºå°†é¥æ„Ÿå›¾åƒæ™ºèƒ½è§£è¯»ä»è§†è§‰ä¸­å¿ƒèŒƒå¼è½¬å‘è¯­è¨€ä¸­å¿ƒèŒƒå¼ï¼Œå€Ÿé‰´å…¨çƒå·¥ä½œç©ºé—´ç†è®ºï¼ˆGWTï¼‰ï¼Œä»¥å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸ºè®¤çŸ¥æ ¸å¿ƒï¼Œå®ç°æ„ŸçŸ¥ã€ä»»åŠ¡ã€çŸ¥è¯†ã€åŠ¨ä½œç©ºé—´çš„ç»Ÿä¸€èåˆã€‚æå‡ºäº†åŸºäºè¯­è¨€çš„é¥æ„Ÿè§£é‡Šç³»ç»Ÿç†è®ºæ¡†æ¶ï¼Œç³»ç»Ÿæ¢³ç†å¤šæ¨¡æ€ç»Ÿä¸€è¡¨è¾¾ã€çŸ¥è¯†å…³è”ä¸æ¨ç†å†³ç­–ç­‰æŠ€æœ¯éš¾é¢˜ï¼Œå¹¶å±•æœ›è‡ªé€‚åº”å¤šæ¨¡æ€å¯¹é½ã€åŠ¨æ€çŸ¥è¯†çº¦æŸä¸‹çš„ä»»åŠ¡ç†è§£ã€å¯ä¿¡æ¨ç†å’Œè‡ªä¸»äº¤äº’ç­‰æœªæ¥æ–¹å‘ã€‚ç»“è®ºè®¤ä¸ºï¼Œè¯­è¨€ä¸­å¿ƒèŒƒå¼èƒ½çªç ´ä¼ ç»Ÿè§†è§‰æ¨¡å‹çš„è®¤çŸ¥ç“¶é¢ˆï¼Œæ¨åŠ¨é¥æ„Ÿè§£é‡Šå‘å…·å¤‡è®¤çŸ¥è¿›åŒ–èƒ½åŠ›çš„æ™ºèƒ½ä½“å‘å±•ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="186-Technical-Report-Full-Stack-Fine-Tuning-for-the-Q-Programming-Language"><a href="#186-Technical-Report-Full-Stack-Fine-Tuning-for-the-Q-Programming-Language" class="headerlink" title="186. Technical Report: Full-Stack Fine-Tuning for the Q Programming Language"></a>186. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Technical_Report__Full-Stack_Fine-Tuning_for_the_Q_Programming_Language.pdf">Technical Report: Full-Stack Fine-Tuning for the Q Programming Language</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Morgan Stanley</span></p>
<p>æœ¬è®ºæ–‡æå‡ºäº†ä¸€å¥—å®Œæ•´çš„å¼€æºæ–¹æ³•ï¼Œå®ç°äº†å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨Qç¼–ç¨‹è¯­è¨€ä¸Šçš„é€‚åº”ï¼ŒåŒ…æ‹¬æ•°æ®é›†æ„å»ºã€é¢„è®­ç»ƒã€ç›‘ç£å¾®è°ƒå’Œå¼ºåŒ–å­¦ä¹ ç­‰æµç¨‹ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨Q-LeetCodeåŸºå‡†ä¸Šçš„ä»£ç ç”Ÿæˆèƒ½åŠ›ã€‚æœ€ç»ˆï¼Œæ‰€è®­ç»ƒçš„Qwen-2.5ç³»åˆ—æ¨¡å‹åœ¨Qä»»åŠ¡ä¸Šå‡è¶…è¶Šäº†GPT-4.1ï¼Œæœ€å¤§æ¨¡å‹æ¯”Claude Opus-4æå‡29.5%ï¼Œä¸ºä½èµ„æºé¢†åŸŸLLMé€‚é…æä¾›äº†å¯å¤ç”¨è“å›¾ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="187-LSDTs-LLM-Augmented-Semantic-Digital-Twins-for-Adaptive-Knowledge-Intensive-Infrastructure-Planning"><a href="#187-LSDTs-LLM-Augmented-Semantic-Digital-Twins-for-Adaptive-Knowledge-Intensive-Infrastructure-Planning" class="headerlink" title="187. LSDTs: LLM-Augmented Semantic Digital Twins for Adaptive Knowledge-Intensive Infrastructure Planning"></a>187. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/LSDTs__LLM-Augmented_Semantic_Digital_Twins_for_Adaptive_Knowledge-Intensive_Infrastructure_Planning.pdf">LSDTs: LLM-Augmented Semantic Digital Twins for Adaptive Knowledge-Intensive Infrastructure Planning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Maryland, College Park</span></p>
<p>æœ¬è®ºæ–‡æå‡ºLSDTsæ¡†æ¶ï¼Œå°†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸æ•°å­—å­ªç”Ÿï¼ˆDTï¼‰ç»“åˆï¼Œå®ç°å¯¹åŸºç¡€è®¾æ–½è§„åˆ’ä¸­éç»“æ„åŒ–æ³•è§„ä¸æŠ€æœ¯æ–‡æ¡£çš„è‡ªåŠ¨çŸ¥è¯†æŠ½å–å’Œç»“æ„åŒ–å»ºæ¨¡ï¼Œå…³é”®æŠ€æœ¯åŒ…æ‹¬LLMé©±åŠ¨çš„æœ¬ä½“æå–ã€RDFè¯­ä¹‰å›¾ç”Ÿæˆã€æ¨ç†ä¸ä»¿çœŸé›†æˆï¼Œä»¥åŠåŠ¨æ€æƒ…å¢ƒä¸‹çš„è‡ªé€‚åº”ä¼˜åŒ–ã€‚å®éªŒä»¥é©¬é‡Œå…°å·ç¦»å²¸é£ç”µåœºä¸ºä¾‹ï¼Œå±•ç¤ºè¯¥æ–¹æ³•èƒ½è‡ªåŠ¨é›†æˆæ³•è§„çº¦æŸã€ç”Ÿæˆåˆè§„å¸ƒå±€ã€å¹¶åœ¨æç«¯å¤©æ°”æƒ…å¢ƒä¸‹æ”¯æŒä»¿çœŸå’Œè‡ªåŠ¨è°ƒä¼˜ã€‚ç»“è®ºè®¤ä¸ºï¼ŒLSDTså¯æå‡åŸºç¡€è®¾æ–½è§„åˆ’çš„æ•°æ®é©±åŠ¨ã€æ³•è§„åˆè§„ä¸é€‚åº”æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="188-PROPS-Progressively-Private-Self-alignment-of-Large-Language-Models"><a href="#188-PROPS-Progressively-Private-Self-alignment-of-Large-Language-Models" class="headerlink" title="188. PROPS: Progressively Private Self-alignment of Large Language Models"></a>188. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/PROPS__Progressively_Private_Self-alignment_of_Large_Language_Models.pdf">PROPS: Progressively Private Self-alignment of Large Language Models</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Arizona</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†PROPSï¼ˆProgressively Private Self-alignmentï¼‰ï¼Œä¸€ç§å¤šé˜¶æ®µçš„éšç§ä¿æŠ¤å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯¹é½ç®—æ³•ã€‚æ–¹æ³•æµç¨‹åŒ…æ‹¬ï¼šå°†æ•°æ®é›†åˆ†å‰²ä¸ºå¤šä¸ªé˜¶æ®µï¼Œé¦–é˜¶æ®µç”¨éšæœºå“åº”æœºåˆ¶æ‰°åŠ¨åå¥½æ ‡ç­¾å¹¶å¯¹æ¨¡å‹è¿›è¡Œåˆæ­¥å¯¹é½ï¼Œåç»­é˜¶æ®µåˆ©ç”¨å‰ä¸€é˜¶æ®µæ¨¡å‹å¯¹æ–°æ•°æ®è¿›è¡Œåå¥½é¢„æµ‹ï¼Œå¹¶ç»“åˆæœ€å¤§ä¼¼ç„¶ä¼°è®¡æ•´åˆæ¨¡å‹é¢„æµ‹å’Œæ‰°åŠ¨æ ‡ç­¾ï¼Œä»è€Œè¿›ä¸€æ­¥æå‡å¯¹é½æ€§èƒ½å’Œéšç§ä¿æŠ¤ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨åŒç­‰éšç§é¢„ç®—ä¸‹ï¼ŒPROPSåœ¨å¤šæ¨¡å‹å’Œæ•°æ®é›†ä¸Šå¯¹é½è´¨é‡æ˜¾è‘—ä¼˜äºDP-SGDå’Œéšæœºå“åº”æ–¹æ³•ï¼Œå°¤å…¶åœ¨é«˜éšç§éœ€æ±‚åœºæ™¯ä¸‹è¡¨ç°çªå‡ºã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="189-Story-Ribbons-Reimagining-Storyline-Visualizations-with-Large-Language-Models"><a href="#189-Story-Ribbons-Reimagining-Storyline-Visualizations-with-Large-Language-Models" class="headerlink" title="189. Story Ribbons: Reimagining Storyline Visualizations with Large Language Models"></a>189. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Story_Ribbons__Reimagining_Storyline_Visualizations_with_Large_Language_Models.pdf">Story Ribbons: Reimagining Storyline Visualizations with Large Language Models</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Harvard University</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è‡ªåŠ¨å°è¯´ç»“æ„åŒ–ä¿¡æ¯æŠ½å–ç®¡é“ï¼Œç»“åˆäº¤äº’å¼å¯è§†åŒ–ç³»ç»ŸSTORY RIBBONSï¼Œå®ç°å°è¯´&#x2F;å‰§æœ¬ä¸­è§’è‰²ã€åœ°ç‚¹ã€ä¸»é¢˜ç­‰å¤šç»´æ•…äº‹è¦ç´ çš„è‡ªåŠ¨æå–ä¸å¯è§†åŒ–åˆ†æã€‚å®éªŒå’Œç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿæ˜¾è‘—é™ä½äº†æ–‡å­¦æ–‡æœ¬åˆ†æçš„é—¨æ§›ï¼Œå¸®åŠ©ç”¨æˆ·å‘ç°æ–°é¢–æ•…äº‹æ´å¯Ÿï¼Œä½†å½“å‰LLMåœ¨æ–‡å­¦ç»†èŠ‚ç†è§£ä¸æ­§ä¹‰æ¶ˆè§£ä¸Šä»æœ‰é™ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="190-Fed-MobiLLM-Efficient-Federated-LLM-Fine-Tuning-over-Heterogeneous-Mobile-Devices-via-Server-Assisted-Side-Tuning"><a href="#190-Fed-MobiLLM-Efficient-Federated-LLM-Fine-Tuning-over-Heterogeneous-Mobile-Devices-via-Server-Assisted-Side-Tuning" class="headerlink" title="190. Fed MobiLLM: Efficient Federated LLM Fine-Tuning over Heterogeneous Mobile Devices via Server Assisted Side-Tuning"></a>190. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Fed_MobiLLM__Efficient_Federated_LLM_Fine-Tuning_over_Heterogeneous_Mobile_Devices_via_Server_Assist.pdf">Fed MobiLLM: Efficient Federated LLM Fine-Tuning over Heterogeneous Mobile Devices via Server Assisted Side-Tuning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Houston</span></p>
<p>Fed MobiLLMæå‡ºäº†ä¸€ç§å¼‚æ­¥ã€æœåŠ¡å™¨è¾…åŠ©çš„side-tuningèŒƒå¼ï¼Œå®ç°äº†åœ¨å¼‚æ„ç§»åŠ¨è®¾å¤‡ä¸Šçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é«˜æ•ˆè”é‚¦å¾®è°ƒã€‚æ–¹æ³•ä¸Šï¼Œç§»åŠ¨ç«¯ä»…ä¿ç•™å†»ç»“çš„backboneï¼Œæ‰§è¡Œå‰å‘ä¼ æ’­å¹¶ä¸Šä¼ ä¸­é—´æ¿€æ´»ï¼ŒæœåŠ¡å™¨å¼‚æ­¥è®­ç»ƒç»Ÿä¸€çš„side-networkï¼Œå¹¶é€šè¿‡åˆ†å±‚æ¿€æ´»é‡‡æ ·å’Œè·¨ç»“æ„ç‰¹å¾å¯¹é½æ”¯æŒä¸åŒè®¾å¤‡æ¨¡å‹çš„é«˜æ•ˆååŒã€‚ç»“è®ºè¯æ˜ï¼Œè¯¥æ–¹æ³•å¤§å¹…é™ä½äº†è®¾å¤‡ç«¯å†…å­˜å’Œè®¡ç®—ã€é€šä¿¡æ¶ˆè€—ï¼Œå¹¶å®ç°æ›´å¿«æ”¶æ•›ï¼Œåœ¨IIDå’Œnon-IIDæ•°æ®åˆ†å¸ƒä¸‹å‡èƒ½ä¿æŒå¼ºåŠ²æ€§èƒ½ï¼Œé€‚ç”¨äºå®é™…åˆ†å¸ƒå¼ç§»åŠ¨åœºæ™¯ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="191-Democratizing-Diplomacy-A-Harness-for-Evaluating-Any-Large-Language-Model-on-Full-Press-Diplomacy"><a href="#191-Democratizing-Diplomacy-A-Harness-for-Evaluating-Any-Large-Language-Model-on-Full-Press-Diplomacy" class="headerlink" title="191. Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy"></a>191. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Democratizing_Diplomacy__A_Harness_for_Evaluating_Any_Large_Language_Model_on_Full-Press_Diplomacy.pdf">Democratizing Diplomacy: A Harness for Evaluating Any Large Language Model on Full-Press Diplomacy</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Good Start Labs</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†é¦–ä¸ªæ— éœ€å¾®è°ƒå³å¯è®©ä»»æ„æœ¬åœ°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å®Œæ•´å‚ä¸Full-Press Diplomacyï¼ˆå…¨äº¤æµå¤–äº¤æ£‹å±€ï¼‰çš„è¯„æµ‹æ¡†æ¶ã€‚æ–¹æ³•åŒ…æ‹¬æ•°æ®é©±åŠ¨çš„æ–‡æœ¬åŒ–åšå¼ˆçŠ¶æ€è¡¨ç¤ºã€è‡ªåŠ¨åŒ–å¯¹å±€æµç¨‹ã€æ‰¹é‡æ¨¡å‹å¯¹æ¯”ã€Critical State Analysiså…³é”®å±€åŠ¿åˆ†æç­‰ï¼Œå¯é«˜æ•ˆåˆ†ææ¨¡å‹çš„ç­–ç•¥æ¨ç†ã€å¤–äº¤è¡¨ç°ã€æ‰¿è¯ºä¸èƒŒå›ç­‰è¡Œä¸ºç‰¹å¾ã€‚ç»“è®ºè¡¨æ˜ï¼šå³ä½¿æ˜¯24Bå‚æ•°çš„å°å‹é€šç”¨æ¨¡å‹åœ¨æœªä¸“é—¨è®­ç»ƒä¸‹ä¹Ÿèƒ½é¡ºåˆ©å®Œæˆåšå¼ˆä¸”å±•ç°å‡ºè‡ªç„¶æ¶Œç°çš„æˆ˜ç•¥èƒ½åŠ›ï¼Œæ¡†æ¶æå¤§é™ä½äº†æˆ˜ç•¥æ¨ç†ç±»LLMç ”ç©¶é—¨æ§›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="192-AURA-A-Fine-Grained-Benchmark-and-Decomposed-Metric-for-Audio-Visual-Reasoning"><a href="#192-AURA-A-Fine-Grained-Benchmark-and-Decomposed-Metric-for-Audio-Visual-Reasoning" class="headerlink" title="192. AURA: A Fine-Grained Benchmark and Decomposed Metric for Audio-Visual Reasoning"></a>192. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/AURA__A_Fine-Grained_Benchmark_and_Decomposed_Metric_for_Audio-Visual_Reasoning.pdf">AURA: A Fine-Grained Benchmark and Decomposed Metric for Audio-Visual Reasoning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Maryland, College Park</span></p>
<p>æœ¬æ–‡æå‡ºAURAåŸºå‡†ï¼Œä¸“ä¸ºè¯„ä¼°éŸ³è§†é¢‘å¤§æ¨¡å‹ï¼ˆAV-LLMsï¼‰å’Œå…¨æ¨¡æ€å¤§æ¨¡å‹ï¼ˆOLMsï¼‰åœ¨å…­ç±»ç»†ç²’åº¦è·¨æ¨¡æ€æ¨ç†ä»»åŠ¡ï¼ˆå¦‚å› æœæ¨ç†ã€éŸ³è‰²&#x2F;éŸ³é«˜æ¨ç†ã€åŒæ­¥æ€§åˆ†æç­‰ï¼‰ä¸Šçš„æ¨ç†èƒ½åŠ›ã€‚AURAç»“åˆè‡ªåŠ¨åŒ–QAç”Ÿæˆæµç¨‹ä¸æ–°é¢–åˆ†è§£è¯„æµ‹æŒ‡æ ‡AuraScoreï¼ˆåŒ…æ‹¬äº‹å®ä¸€è‡´æ€§å’Œæ ¸å¿ƒæ¨ç†ä¸¤é¡¹ï¼‰ï¼Œæ­ç¤ºä¸»æµå¤šæ¨¡æ€æ¨¡å‹åœ¨å‡†ç¡®ç‡ä¸æ¨ç†é€»è¾‘ä¹‹é—´å­˜åœ¨æ˜¾è‘—å·®è·ï¼Œæ¨åŠ¨æ›´æ·±å…¥çš„å¤šæ¨¡æ€æ¨¡å‹ç†è§£å’Œè¯„æµ‹ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="193-Freeze-and-Reveal-Exposing-Modality-Bias-in-Vision-Language-Models"><a href="#193-Freeze-and-Reveal-Exposing-Modality-Bias-in-Vision-Language-Models" class="headerlink" title="193. Freeze and Reveal: Exposing Modality Bias in Vision-Language Models"></a>193. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Freeze_and_Reveal__Exposing_Modality_Bias_in_Vision-Language_Models.pdf">Freeze and Reveal: Exposing Modality Bias in Vision-Language Models</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">IIIT Hyderabad</span></p>
<p>æœ¬æ–‡æå‡ºäº†é’ˆå¯¹è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ä¸­æ€§åˆ«åè§çš„æ¨¡æ€å®šå‘å»åæ¡†æ¶ï¼Œé€šè¿‡åˆ†åˆ«å¯¹è§†è§‰ç¼–ç å™¨å’Œæ–‡æœ¬ç¼–ç å™¨åº”ç”¨Counterfactual Data Augmentationï¼ˆCDAï¼‰ã€Task Vectoræ–¹æ³•ä»¥åŠæ–°é¢–çš„æ•°æ®é«˜æ•ˆå»åæŠ€æœ¯DAUDoSä»¥é‡åŒ–å’Œé™ä½æ€§åˆ«åè§ã€‚å®éªŒè¯æ˜ï¼ŒCLIPæ¨¡å‹çš„è§†è§‰ç¼–ç å™¨åè§æ›´å¤§ï¼ŒPaliGemma2åˆ™ä»¥æ–‡æœ¬ç¼–ç å™¨ä¸ºä¸»ï¼Œé€šè¿‡é’ˆå¯¹æ€§å»åå¯æœ‰æ•ˆç¼©å°æ€§åˆ«å·®è·ä¸”ä¿æŒæ¨¡å‹æ€§èƒ½ï¼Œä¸ºå¤šæ¨¡æ€ç³»ç»Ÿå…¬å¹³æ€§æ”¹è¿›æä¾›äº†æ–¹æ³•è®ºå’Œè¯„ä¼°å·¥å…·ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="194-Event-Aware-Sentiment-Factors-from-LLM-Augmented-Financial-Tweets-A-Transparent-Framework-for-Interpretable-Quant-Trading"><a href="#194-Event-Aware-Sentiment-Factors-from-LLM-Augmented-Financial-Tweets-A-Transparent-Framework-for-Interpretable-Quant-Trading" class="headerlink" title="194. Event-Aware Sentiment Factors from LLM-Augmented Financial Tweets: A Transparent Framework for Interpretable Quant Trading"></a>194. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Event-Aware_Sentiment_Factors_from_LLM-Augmented_Financial_Tweets__A_Transparent_Framework_for_Inter.pdf">Event-Aware Sentiment Factors from LLM-Augmented Financial Tweets: A Transparent Framework for Interpretable Quant Trading</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Cambridge</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯¹é‡‘èç›¸å…³æ¨æ–‡è¿›è¡Œå¤šæ ‡ç­¾äº‹ä»¶åˆ†ç±»ï¼Œå¹¶ç»“åˆæƒ…æ„Ÿå¼ºåº¦é‡åŒ–æ„å»ºå¯è§£é‡Šçš„é‡åŒ–äº¤æ˜“å› å­ã€‚å®è¯ç»“æœè¡¨æ˜ï¼ŒLLMæ ‡æ³¨çš„ç‰¹å®šäº‹ä»¶ï¼ˆå¦‚è°£è¨€&#x2F;ç‚’ä½œã€æ•£æˆ·çƒ­è®®ç­‰ï¼‰æƒ…æ„Ÿå› å­åœ¨å¤šä¸ªæŒä»“å‘¨æœŸå†…å…·æœ‰æ˜¾è‘—ä¸”ç¨³å®šçš„è´ŸAlphaå’Œé«˜ä¿¡æ¯ç³»æ•°ï¼ŒéªŒè¯äº†ç¤¾äº¤åª’ä½“è¯­ä¹‰ç»“æ„å¯¹é‡‘èé¢„æµ‹çš„æœ‰æ•ˆæ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="195-Generative-AI-for-Strategic-Plan-Development"><a href="#195-Generative-AI-for-Strategic-Plan-Development" class="headerlink" title="195. Generative AI for Strategic Plan Development"></a>195. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Generative_AI_for_Strategic_Plan_Development.pdf">Generative AI for Strategic Plan Development</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Johns Hopkins University</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ¨¡å—åŒ–è®¤çŸ¥æ¨¡å‹ï¼Œåˆ©ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼ˆGAIï¼‰å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¾…åŠ©æ”¿åºœæœºæ„æˆ˜ç•¥è§„åˆ’å¼€å‘ã€‚é€šè¿‡å¯¹BERTopicå’Œéè´ŸçŸ©é˜µåˆ†è§£ï¼ˆNMFï¼‰ä¸¤ç§ä¸»é¢˜å»ºæ¨¡æŠ€æœ¯åœ¨æˆ˜ç•¥è®¡åˆ’æ„¿æ™¯è¦ç´ æå–ä»»åŠ¡ä¸­çš„è¡¨ç°è¿›è¡Œæ¯”è¾ƒï¼Œç»“æœè¡¨æ˜ä¸¤è€…å‡èƒ½è¦†ç›–å…¨éƒ¨æ„¿æ™¯è¦ç´ ï¼Œä½†BERTopicçš„ç›¸å…³æ€§æ›´å¼ºï¼Œè¡¨ç°æœ€ä½³ã€‚ç»“è®ºæŒ‡å‡ºä¸»é¢˜å»ºæ¨¡å¯æœ‰æ•ˆè¾…åŠ©æˆ˜ç•¥æ„¿æ™¯è¦ç´ çš„ç”Ÿæˆï¼ŒBERTopicä¼˜äºNMFï¼Œæœªæ¥éœ€æ‰©å±•è‡³æ›´å¤šæ¨¡å—å¹¶ä¼˜åŒ–æ¨¡å‹ä»¥å®ç°å®é™…åº”ç”¨ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="196-LET-US-Long-Event-Text-Understanding-of-Scenes"><a href="#196-LET-US-Long-Event-Text-Understanding-of-Scenes" class="headerlink" title="196. LET-US: Long Event-Text Understanding of Scenes"></a>196. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/LET-US__Long_Event-Text_Understanding_of_Scenes.pdf">LET-US: Long Event-Text Understanding of Scenes</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Peking University</span></p>
<p>æœ¬æ–‡æå‡ºLET-USæ¡†æ¶ï¼Œé’ˆå¯¹äº‹ä»¶ç›¸æœºäº§ç”Ÿçš„ç¨€ç–é•¿åºåˆ—æ•°æ®ï¼Œé€šè¿‡è·¨æ¨¡æ€è¯­ä¹‰å¼•å¯¼å‹ç¼©å’Œå±‚æ¬¡èšç±»ï¼ŒåŠ¨æ€é€‰å–å…³é”®ä¿¡æ¯æ®µï¼Œå®ç°äº‹ä»¶æµä¸æ–‡æœ¬çš„å¯¹é½å’Œç†è§£ã€‚é€šè¿‡ä¸¤é˜¶æ®µä¼˜åŒ–ï¼ˆå…ˆRGBè§†è§‰-æ–‡æœ¬é¢„è®­ç»ƒï¼Œå†äº‹ä»¶æµ-æ–‡æœ¬å¾®è°ƒï¼‰ä»¥åŠè‡ªå»ºç™¾ä¸‡çº§äº‹ä»¶-æ–‡æœ¬å¯¹é½æ•°æ®é›†ï¼ŒLET-USæ˜¾è‘—æå‡äº†é•¿æ—¶äº‹ä»¶æµçš„æ¨ç†ã€åˆ†ç±»ã€å®šä½å’Œæè¿°ä»»åŠ¡æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLET-USåœ¨å¤šé¡¹äº‹ä»¶æµç†è§£ä»»åŠ¡ä¸Šå‡ä¼˜äºç°æœ‰ä¸»æµMLLMæ–¹æ³•ï¼Œèƒ½å¤Ÿé«˜æ•ˆå¤„ç†ç™¾ä¸‡çº§æ—¶é—´æˆ³çš„é•¿äº‹ä»¶æµã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="197-ALOPE-Adaptive-Layer-Optimization-for-Translation-Quality-Estimation-using-Large-Language-Models"><a href="#197-ALOPE-Adaptive-Layer-Optimization-for-Translation-Quality-Estimation-using-Large-Language-Models" class="headerlink" title="197. ALOPE: Adaptive Layer Optimization for Translation Quality Estimation using Large Language Models"></a>197. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/ALOPE__Adaptive_Layer_Optimization_for_Translation_Quality_Estimation_using_Large_Language_Models.pdf">ALOPE: Adaptive Layer Optimization for Translation Quality Estimation using Large Language Models</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Surrey</span></p>
<p>æœ¬è®ºæ–‡æå‡ºALOPEæ¡†æ¶ï¼Œé€šè¿‡åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„Transformerä¸åŒå±‚æ’å…¥ä½ç§©é€‚é…å™¨ï¼ˆLoRAï¼‰å’Œå›å½’å¤´ï¼Œå®ç°å¯¹æœºå™¨ç¿»è¯‘è´¨é‡çš„æ— å‚è€ƒè¯„ä¼°ã€‚è¯¥æ–¹æ³•ç³»ç»Ÿæ¢ç´¢ä¸­é—´å±‚è¡¨ç¤ºå¹¶å¼•å…¥åŠ¨æ€åŠ æƒä¸å¤šå¤´å›å½’ç­–ç•¥ï¼Œæ˜¾è‘—æå‡äº†ä½èµ„æºè¯­è¨€å¯¹ç¿»è¯‘è´¨é‡ä¼°ç®—çš„ç›¸å…³æ€§åˆ†æ•°ï¼Œä¼˜äºæ ‡å‡†å¾®è°ƒå’Œç°æœ‰ä¸»æµæ¨¡å‹ã€‚ç»“è®ºæŒ‡å‡ºï¼ŒTransformerä¸­é—´å±‚ï¼ˆå°¤å…¶æ˜¯TL-7ï¼‰å…·å¤‡æ›´ä¼˜çš„è·¨è¯­è¨€è¡¨å¾èƒ½åŠ›ï¼ŒALOPEåœ¨GPUèµ„æºå’Œæ•ˆæœä¸Šè¡¨ç°ä¼˜ç§€ï¼Œé€‚åˆå®é™…éƒ¨ç½²ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="198-Grounding-Natural-Language-for-Multi-agent-Decision-Making-with-Multi-agentic-LLMs"><a href="#198-Grounding-Natural-Language-for-Multi-agent-Decision-Making-with-Multi-agentic-LLMs" class="headerlink" title="198. Grounding Natural Language for Multi-agent Decision-Making with Multi-agentic LLMs"></a>198. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Grounding_Natural_Language_for_Multi-agent_Decision-Making_with_Multi-agentic_LLMs.pdf">Grounding Natural Language for Multi-agent Decision-Making with Multi-agentic LLMs</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">UC Davis</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªå¤šæ™ºèƒ½ä½“å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç³»ç»Ÿæ¡†æ¶ï¼Œå°†å…ˆè¿›çš„æç¤ºå·¥ç¨‹ã€å¤šæ¨¡æ€ä¿¡æ¯å¤„ç†ã€æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ã€è®°å¿†ç»“æ„å’Œæœºåˆ¶è®¾è®¡ä¸å¤šæ™ºèƒ½ä½“å†³ç­–ç®—æ³•ç»“åˆã€‚é€šè¿‡åœ¨ç»å…¸åšå¼ˆï¼ˆå¦‚å›šå¾’å›°å¢ƒã€é¸¡æ¸¸æˆç­‰ï¼‰ä¸Šçš„å®éªŒï¼Œä½œè€…å‘ç°ç»å¾®è°ƒçš„å¤šæ™ºèƒ½ä½“LLMèƒ½å¤Ÿä¿ƒè¿›ä¸ªä½“å’Œæ•´ä½“çš„é«˜æ•ˆã€å¯è§£é‡Šã€é²æ£’çš„åä½œå†³ç­–ï¼Œå¹¶æœ‰æ•ˆåº”å¯¹ç¤¾ä¼šå›°å¢ƒã€ä¿¡æ¯ä¸å®Œå…¨ã€ç›®æ ‡ä¸ä¸€è‡´ç­‰å¤æ‚æƒ…å†µã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="199-Grounding-Multilingual-Multimodal-LLMs-With-Cultural-Knowledge"><a href="#199-Grounding-Multilingual-Multimodal-LLMs-With-Cultural-Knowledge" class="headerlink" title="199. Grounding Multilingual Multimodal LLMs With Cultural Knowledge"></a>199. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Grounding_Multilingual_Multimodal_LLMs_With_Cultural_Knowledge.pdf">Grounding Multilingual Multimodal LLMs With Cultural Knowledge</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Carnegie Mellon University</span></p>
<p>æœ¬æ–‡æå‡ºCulturalGroundæ•°æ®é›†å’ŒCulturalPangeaæ¨¡å‹ï¼Œé€šè¿‡åˆ©ç”¨Wikidataæ„å»ºè¦†ç›–39ç§è¯­è¨€ã€42ä¸ªå›½å®¶ã€2200ä¸‡æ¡æ–‡åŒ–è§†è§‰é—®ç­”çš„æ•°æ®é›†ï¼Œé‡‡ç”¨å¤šé˜¶æ®µæ•°æ®ç”Ÿæˆã€LLMæ¶¦è‰²ã€VLMç­›é€‰ï¼Œæå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„æ–‡åŒ–çŸ¥è¯†å’Œå¤šè¯­è¨€èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼ŒCulturalPangeaåœ¨å¤šé¡¹æ–‡åŒ–ç›¸å…³å¤šè¯­è¨€å¤šæ¨¡æ€åŸºå‡†æµ‹è¯•ä¸Šè¶…è¶Šç°æœ‰å¼€æºæ¨¡å‹çº¦5%ï¼Œä¸”ä¸»æµè§†è§‰-è¯­è¨€ä»»åŠ¡æ€§èƒ½ä¸é™ï¼Œæ˜¾è‘—ç¼©å°LLMæ–‡åŒ–åå·®ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="200-A-Comprehensive-Survey-of-Self-Evolving-AI-Agents-A-New-Paradigm-Bridging-Foundation-Models-and-Lifelong-Agentic-Systems"><a href="#200-A-Comprehensive-Survey-of-Self-Evolving-AI-Agents-A-New-Paradigm-Bridging-Foundation-Models-and-Lifelong-Agentic-Systems" class="headerlink" title="200. A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems"></a>200. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/A_Comprehensive_Survey_of_Self-Evolving_AI_Agents__A_New_Paradigm_Bridging_Foundation_Models_and_Lif.pdf">A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Glasgow</span></p>
<p>æœ¬è®ºæ–‡ç³»ç»Ÿç»¼è¿°äº†è‡ªè¿›åŒ–AIä»£ç†çš„æ–°èŒƒå¼ï¼Œæå‡ºäº†ç»Ÿä¸€æ¦‚å¿µæ¡†æ¶ï¼Œæ¶µç›–æ¨¡å‹ç¦»çº¿è®­ç»ƒã€åœ¨çº¿é€‚åº”ã€å¤šæ™ºèƒ½ä½“ååŒåˆ°å¤šæ™ºèƒ½ä½“è‡ªè¿›åŒ–ï¼ˆMASEï¼‰ã€‚æ–¹æ³•åŒ…æ‹¬å¯¹LLMã€æç¤ºã€è®°å¿†ã€å·¥å…·ã€å·¥ä½œæµåŠå¤šæ™ºèƒ½ä½“é€šä¿¡ä¼˜åŒ–æŠ€æœ¯çš„æ¢³ç†ï¼Œå¹¶è®¨è®ºè¯„ä¼°ã€å®‰å…¨ä¸ä¼¦ç†é—®é¢˜ã€‚ç»“è®ºè®¤ä¸ºè‡ªè¿›åŒ–AIä»£ç†èƒ½å®ç°æŒç»­é€‚åº”ã€å¢å¼ºè‡ªä¸»æ€§å’Œé•¿æœŸå­¦ä¹ ï¼Œä¸ºåŠ¨æ€ç¯å¢ƒä¸‹çš„AIç³»ç»Ÿå‘å±•æä¾›ç†è®ºä¸æŠ€æœ¯åŸºç¡€ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="201-Urbanite-A-Dataflow-Based-Framework-for-Human-AI-Interactive-Alignment-in-Urban-Visual-Analytics"><a href="#201-Urbanite-A-Dataflow-Based-Framework-for-Human-AI-Interactive-Alignment-in-Urban-Visual-Analytics" class="headerlink" title="201. Urbanite: A Dataflow-Based Framework for Human-AI Interactive Alignment in Urban Visual Analytics"></a>201. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Urbanite__A_Dataflow-Based_Framework_for_Human-AI_Interactive_Alignment_in_Urban_Visual_Analytics.pdf">Urbanite: A Dataflow-Based Framework for Human-AI Interactive Alignment in Urban Visual Analytics</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Illinois Chicago</span></p>
<p>Urbaniteæå‡ºäº†ä¸€ç§åŸºäºæ•°æ®æµçš„æ•°æ®åˆ†ææ¡†æ¶ï¼Œé€šè¿‡é›†æˆå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œæ”¯æŒç”¨æˆ·ä»¥è‡ªç„¶è¯­è¨€æŒ‡å®šåˆ†ææ„å›¾ï¼Œè¿›è€Œè‡ªåŠ¨ç”Ÿæˆã€è§£é‡Šå’Œè¿­ä»£åŸå¸‚è§†è§‰åˆ†æçš„æ•°æ®æµæµç¨‹ã€‚è¯¥æ–¹æ³•æ˜¾è‘—é™ä½äº†åŸå¸‚æ•°æ®å¯è§†åŒ–åˆ†æçš„æŠ€æœ¯é—¨æ§›ï¼Œå®ç°äº†äººæœºåä½œã€ä»»åŠ¡å¯è¿½æº¯ä¸å¤šå±‚çº§å¯¹é½ï¼Œç»ä¸“å®¶å®è¯å’Œæ¡ˆä¾‹åˆ†æéªŒè¯æœ‰æ•ˆï¼Œèƒ½å‡†ç¡®å°†é«˜å±‚æ¬¡æ„å›¾è½¬åŒ–ä¸ºå¯æ‰§è¡Œåˆ†ææµç¨‹ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="202-Rethinking-Domain-Specific-LLM-Benchmark-Construction-A-Comprehensiveness-Compactness-Approach"><a href="#202-Rethinking-Domain-Specific-LLM-Benchmark-Construction-A-Comprehensiveness-Compactness-Approach" class="headerlink" title="202. Rethinking Domain-Specific LLM Benchmark Construction: A Comprehensiveness-Compactness Approach"></a>202. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Rethinking_Domain-Specific_LLM_Benchmark_Construction__A_Comprehensiveness-Compactness_Approach.pdf">Rethinking Domain-Specific LLM Benchmark Construction: A Comprehensiveness-Compactness Approach</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">The Hong Kong Polytechnic University</span></p>
<p>æœ¬æ–‡æå‡ºäº†COMP-COMPæ¡†æ¶ï¼Œç”¨äºé¢†åŸŸç‰¹å®šå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åŸºå‡†æµ‹è¯•é›†çš„è‡ªåŠ¨æ„å»ºï¼Œå¼ºè°ƒè¯­ä¹‰ç©ºé—´å†…çš„å…¨é¢æ€§ï¼ˆcomprehensivenessï¼‰å’Œç´§å‡‘æ€§ï¼ˆcompactnessï¼‰åŸåˆ™ï¼Œé€šè¿‡é«˜æ–¯æ ¸å¯†åº¦ä¼°è®¡å’Œç›¸å…³æ€§åˆ†æè¿­ä»£æ”¶é›†ä¸ç­›é€‰çŸ¥è¯†è¯­æ–™å’Œé—®ç­”æ•°æ®ï¼Œå®ç°é«˜æ•ˆè¦†ç›–ä¸ä½å†—ä½™çš„åŸºå‡†é›†è®¾è®¡ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•å¯æ˜¾è‘—å‡å°‘åŸºå‡†é—®é¢˜å’Œè¯­æ–™æ•°é‡ï¼ˆé—®é¢˜å‡å°‘98.3%ï¼Œè¯­æ–™å‡å°‘53.6%ï¼‰ï¼ŒåŒæ—¶æå‡LLMé¢†åŸŸä»»åŠ¡çš„è¯„æµ‹æ•ˆæœï¼Œå¹¶åœ¨å­¦æœ¯é¢†åŸŸæ„å»ºäº†å¤§è§„æ¨¡åŸºå‡†XUBenchï¼Œå…·å¤‡è·¨é¢†åŸŸæ‰©å±•æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="203-ObfusQAte-A-Proposed-Framework-to-Evaluate-LLM-Robustness-on-Obfuscated-Factual-Question-Answering"><a href="#203-ObfusQAte-A-Proposed-Framework-to-Evaluate-LLM-Robustness-on-Obfuscated-Factual-Question-Answering" class="headerlink" title="203. ObfusQAte: A Proposed Framework to Evaluate LLM Robustness on Obfuscated Factual Question Answering"></a>203. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/ObfusQAte__A_Proposed_Framework_to_Evaluate_LLM_Robustness_on_Obfuscated_Factual_Question_Answering.pdf">ObfusQAte: A Proposed Framework to Evaluate LLM Robustness on Obfuscated Factual Question Answering</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Indian Institute of Technology Patna</span></p>
<p>æœ¬æ–‡æå‡ºObfusQAteæŠ€æœ¯å’ŒObfusQAæ¡†æ¶ï¼Œé€šè¿‡å¤šå±‚æ¬¡çš„è¯­ä¹‰æ··æ·†ï¼ˆå‘½åå®ä½“é—´æ¥ã€å¹²æ‰°é¡¹é—´æ¥ã€ä¸Šä¸‹æ–‡è¿‡è½½ï¼‰ç³»ç»Ÿæ€§æ„é€ é—®é¢˜ï¼Œå…¨é¢è¯„ä¼°ä¸»æµå¤§è¯­è¨€æ¨¡å‹åœ¨åº”å¯¹è¢«æ··æ·†äº‹å®é—®ç­”ä»»åŠ¡æ—¶çš„é²æ£’æ€§ã€‚å®éªŒå‘ç°ï¼Œç°æœ‰LLMåœ¨å¤æ‚æ··æ·†ä¸‹å‡†ç¡®ç‡æ˜¾è‘—ä¸‹é™ï¼Œæš´éœ²å‡ºå¯¹é—´æ¥è¡¨è¾¾å’ŒèƒŒæ™¯å™ªå£°é€‚åº”èƒ½åŠ›ä¸è¶³ï¼Œæå‡ºæ··æ·†å‹é—®é¢˜æ˜¯æµ‹è¯•ä¸æå‡LLMçœŸå®æ¨ç†èƒ½åŠ›çš„é‡è¦æ–¹å‘ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="204-HealthBranches-Synthesizing-Clinically-Grounded-Question-Answering-Datasets-via-Decision-Pathways"><a href="#204-HealthBranches-Synthesizing-Clinically-Grounded-Question-Answering-Datasets-via-Decision-Pathways" class="headerlink" title="204. HealthBranches: Synthesizing Clinically-Grounded Question Answering Datasets via Decision Pathways"></a>204. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/HealthBranches__Synthesizing_Clinically-Grounded_Question_Answering_Datasets_via_Decision_Pathways.pdf">HealthBranches: Synthesizing Clinically-Grounded Question Answering Datasets via Decision Pathways</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Calabria</span></p>
<p>è¯¥è®ºæ–‡æå‡ºHealthBranchesæ•°æ®é›†ï¼Œé€šè¿‡åŠè‡ªåŠ¨æµç¨‹ä»åŒ»å­¦å†³ç­–è·¯å¾„ç”Ÿæˆä¸´åºŠçœŸå®åœºæ™¯çš„åŒ»å­¦é—®ç­”æ•°æ®ï¼Œæ¶µç›–17ç±»ä¸´åºŠé¢†åŸŸå…±4063ä¸ªæ¡ˆä¾‹ã€‚æ–¹æ³•ç»“åˆç»“æ„åŒ–çŸ¥è¯†æŠ½å–ã€LLMè¾…åŠ©ç”Ÿæˆå’Œäººå·¥å®¡æ ¸ï¼Œæ”¯æŒå¤šæ­¥æ¨ç†è¯„ä¼°ä¸RAGæ£€ç´¢å¢å¼ºã€‚ç»“æœæ˜¾ç¤ºç»“æ„åŒ–æ¨ç†è·¯å¾„æ˜¾è‘—æå‡LLMåœ¨åŒ»å­¦é—®ç­”ä»»åŠ¡ä¸­çš„å‡†ç¡®æ€§å’Œè§£é‡Šæ€§ï¼Œä¸ºåŒ»å­¦é¢†åŸŸå¯ä¿¡LLMå¼€å‘ä¸è¯„ä¼°å¥ å®šåŸºç¡€ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="205-Fine-Tuning-Large-Language-Models-Using-EEG-Microstate-Features-for-Mental-Workload-Assessment"><a href="#205-Fine-Tuning-Large-Language-Models-Using-EEG-Microstate-Features-for-Mental-Workload-Assessment" class="headerlink" title="205. Fine-Tuning Large Language Models Using EEG Microstate Features for Mental Workload Assessment"></a>205. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Fine-Tuning_Large_Language_Models_Using_EEG_Microstate_Features_for_Mental_Workload_Assessment.pdf">Fine-Tuning Large Language Models Using EEG Microstate Features for Mental Workload Assessment</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">School of Computer Science, Technological University Dublin</span></p>
<p>æœ¬è®ºæ–‡æå‡ºäº†åˆ©ç”¨EEGå¾®çŠ¶æ€ç‰¹å¾å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œå¾®è°ƒçš„æ–¹æ³•ï¼Œä»¥æå‡å¯¹è®¤çŸ¥è´Ÿè·çŠ¶æ€ï¼ˆä¼‘æ¯ä¸è´Ÿè·ï¼‰çš„åˆ¤åˆ«èƒ½åŠ›ã€‚ç ”ç©¶æµç¨‹æ¶µç›–æ•°æ®é‡‡é›†ä¸é¢„å¤„ç†ã€å¾®çŠ¶æ€åˆ†å‰²ä¸å›æ‹Ÿåˆã€ç‰¹å¾æå–ä¸æç¤ºå·¥ç¨‹ã€æ¨¡å‹é€‰æ‹©ä¸å¾®è°ƒï¼Œæœ€ç»ˆé€šè¿‡ç›‘ç£å­¦ä¹ è®­ç»ƒLLMåŸºäºEEGå¾®çŠ¶æ€ç‰¹å¾åŒºåˆ†ç”¨æˆ·çš„è®¤çŸ¥è´Ÿè·çŠ¶æ€ã€‚ç»“æœæ˜¾ç¤ºï¼Œç»è¿‡EEGå¾®çŠ¶æ€ç‰¹å¾å¾®è°ƒåçš„LLMæ¨¡å‹ï¼Œå…¶è®¤çŸ¥è´Ÿè·åˆ¤åˆ«å‡†ç¡®ç‡ç”±4.5%å¤§å¹…æå‡è‡³97%ï¼Œæ˜¾è‘—ä¼˜äºæœªå¾®è°ƒæ¨¡å‹ï¼Œè¯æ˜EEGå¾®çŠ¶æ€ç‰¹å¾å¯æœ‰æ•ˆå¢å¼ºLLMå¯¹å¤§è„‘è®¤çŸ¥æ´»åŠ¨çš„æ„ŸçŸ¥ä¸æ¨æ–­èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="206-MAQUA-Adaptive-Question-Asking-for-Multidimensional-Mental-Health-Screening-using-Item-Response-Theory"><a href="#206-MAQUA-Adaptive-Question-Asking-for-Multidimensional-Mental-Health-Screening-using-Item-Response-Theory" class="headerlink" title="206. MAQUA: Adaptive Question-Asking for Multidimensional Mental Health Screening using Item Response Theory"></a>206. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/MAQuA__Adaptive_Question-Asking_for_Multidimensional_Mental_Health_Screening_using_Item_Response_The.pdf">MAQUA: Adaptive Question-Asking for Multidimensional Mental Health Screening using Item Response Theory</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Stony Brook University</span></p>
<p>æœ¬è®ºæ–‡æå‡ºäº†MAQUAæ¡†æ¶ï¼Œå°†å¤šè¾“å‡ºè¯­è¨€å»ºæ¨¡ã€å› å­åˆ†æä¸å¤šç»´é¡¹ç›®ååº”ç†è®ºï¼ˆMIRTï¼‰ç»“åˆï¼Œå®ç°å¤šç»´å¿ƒç†å¥åº·è‡ªé€‚åº”é—®è¯Šã€‚è¯¥æ–¹æ³•é€šè¿‡å¤šä»»åŠ¡å»ºæ¨¡ä¸ä¿¡æ¯å¢ç›Šé©±åŠ¨çš„é—®é¢˜é€‰æ‹©ï¼Œæ˜¾è‘—å‡å°‘æ‰€éœ€é—®é¢˜æ•°ï¼ˆæœ€å¤šå‡å°‘85%ï¼‰ï¼Œæå‡å¤šç»´å¿ƒç†å¥åº·ç­›æŸ¥æ•ˆç‡ã€‚ç»“è®ºè¡¨æ˜ï¼ŒMAQUAåœ¨ä¿è¯å‡†ç¡®æ€§çš„åŒæ—¶å¤§å¹…é™ä½ç”¨æˆ·è´Ÿæ‹…ï¼Œé€‚åˆå¤§æ¨¡å‹é©±åŠ¨çš„ä¸´åºŠåº”ç”¨ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="207-LLM-based-Agents-for-Automated-Confounder-Discovery-and-Subgroup-Analysis-in-Causal-Inference"><a href="#207-LLM-based-Agents-for-Automated-Confounder-Discovery-and-Subgroup-Analysis-in-Causal-Inference" class="headerlink" title="207. LLM-based Agents for Automated Confounder Discovery and Subgroup Analysis in Causal Inference"></a>207. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/LLM-based_Agents_for_Automated_Confounder_Discovery_and_Subgroup_Analysis_in_Causal_Inference.pdf">LLM-based Agents for Automated Confounder Discovery and Subgroup Analysis in Causal Inference</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">National Sun Yat-Sen University</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ™ºèƒ½ä½“æ¡†æ¶ï¼Œé€šè¿‡å°†LLM Agentä¸å› æœæœºå™¨å­¦ä¹ æµç¨‹ç»“åˆï¼Œå®ç°è‡ªåŠ¨åŒ–æ··æ‚å› å­å‘ç°ä¸äºšç»„åˆ†æã€‚æ–¹æ³•é‡‡ç”¨Mixture of Expertsç»“æ„å’Œè¿­ä»£ä¸ç¡®å®šæ€§è¯„ä¼°ï¼Œåˆ©ç”¨RAGå’ŒçŸ¥è¯†åº“åŠ å¼ºLLMæ¨ç†èƒ½åŠ›ï¼Œæ˜¾è‘—æå‡äº†æ²»ç–—æ•ˆåº”ä¼°è®¡çš„é²æ£’æ€§å¹¶é™ä½ä¸“å®¶å·¥ä½œé‡ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶èƒ½æœ‰æ•ˆç¼©å°ç½®ä¿¡åŒºé—´å®½åº¦ï¼Œå‘ç°éšåŒ¿æ··æ‚å› ç´ ï¼Œæé«˜å› æœæ¨æ–­çš„å¯ä¿¡åº¦å’Œå¯æ‰©å±•æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="208-Can-Smaller-Large-Language-Models-Evaluate-Research-Quality"><a href="#208-Can-Smaller-Large-Language-Models-Evaluate-Research-Quality" class="headerlink" title="208. Can Smaller Large Language Models Evaluate Research Quality?"></a>208. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Can_Smaller_Large_Language_Models_Evaluate_Research_Quality_.pdf">Can Smaller Large Language Models Evaluate Research Quality?</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Wolverhampton</span></p>
<p>æœ¬è®ºæ–‡ç³»ç»Ÿè¯„ä¼°äº†å¯ä¸‹è½½çš„ä¸­å‹å¼€æºå¤§è¯­è¨€æ¨¡å‹Gemma-3-27b-itåœ¨å­¦æœ¯è®ºæ–‡ç ”ç©¶è´¨é‡è¯„åˆ†ä»»åŠ¡ä¸Šçš„èƒ½åŠ›ï¼Œä¸ä¸“å®¶è¯„åˆ†åŠä¸»æµäº‘ç«¯LLMï¼ˆå¦‚ChatGPT 4o&#x2F;4o-miniï¼‰è¿›è¡Œäº†å¹¿æ³›å¯¹æ¯”ã€‚ç»“æœè¡¨æ˜ï¼ŒGemma-3-27b-itçš„è¯„åˆ†ä¸ä¸“å®¶è¯„åˆ†åœ¨å…¨éƒ¨å­¦ç§‘æ–¹å‘å‡å‘ˆæ˜¾è‘—æ­£ç›¸å…³ï¼Œä¸”ç›¸å…³å¼ºåº¦è¾¾åˆ°ChatGPT 4oçš„83.8%ã€4o-miniçš„94.7%ï¼›ä½†æ¨¡å‹æŠ¥å‘Šç»“æ„è¾ƒä¸ºç»Ÿä¸€ï¼Œé‡å¤è¯„åˆ†æå‡æœ‰é™ã€‚ç»“è®ºï¼šGemmaç­‰ä¸­å‹ç¦»çº¿LLMå¯ç”¨äºç ”ç©¶è´¨é‡è‡ªåŠ¨è¯„ä¼°ï¼Œæ”¯æŒé«˜å®‰å…¨æˆ–ä½æˆæœ¬åœºæ™¯ï¼Œä¸”è¿™ç§èƒ½åŠ›ä¸æ˜¯è¶…å¤§æ¨¡å‹çš„ç‰¹æœ‰æ¶Œç°æ€§è´¨ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="209-AutoAssert-1-A-LoRA-Fine-Tuned-LLM-Model-for-Efficient-Automated-Assertion-Generation"><a href="#209-AutoAssert-1-A-LoRA-Fine-Tuned-LLM-Model-for-Efficient-Automated-Assertion-Generation" class="headerlink" title="209. AutoAssert 1: A LoRA Fine-Tuned LLM Model for Efficient Automated Assertion Generation"></a>209. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/AutoAssert_1__A_LoRA_Fine-Tuned_LLM_Model_for_Efficient_Automated_Assertion_Generation.pdf">AutoAssert 1: A LoRA Fine-Tuned LLM Model for Efficient Automated Assertion Generation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Institute of Computing Technology, Chinese Academy of Sciences</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºLoRAé«˜æ•ˆå¾®è°ƒæŠ€æœ¯å’ŒUnslothå¹³å°çš„è½»é‡çº§å¤§è¯­è¨€æ¨¡å‹ï¼Œç”¨äºè‡ªåŠ¨ä»Verilogç¡¬ä»¶æè¿°è¯­è¨€ä»£ç ä¸­ç”ŸæˆéªŒè¯æ–­è¨€ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤§å¹…é™ä½å¾®è°ƒè®¡ç®—èµ„æºæ¶ˆè€—çš„åŒæ—¶ï¼Œèƒ½å¤Ÿç”Ÿæˆè¯­æ³•å’Œè¯­ä¹‰å‡å‡†ç¡®çš„æ–­è¨€ï¼Œæ€§èƒ½ä¼˜äºä¼ ç»Ÿè§„åˆ™æ–¹æ³•ï¼Œé€‚ç”¨äºèµ„æºå—é™ç¯å¢ƒä¸‹çš„è‡ªåŠ¨åŒ–æµ‹è¯•ä¸ç»´æŠ¤ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="210-Hallucination-as-a-Computational-Boundary-A-Hierarchy-of-Inevitability-and-the-Oracle-Escape"><a href="#210-Hallucination-as-a-Computational-Boundary-A-Hierarchy-of-Inevitability-and-the-Oracle-Escape" class="headerlink" title="210. Hallucination as a Computational Boundary: A Hierarchy of Inevitability and the Oracle Escape"></a>210. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Hallucination_as_a_Computational_Boundary__A_Hierarchy_of_Inevitability_and_the_Oracle_Escape.pdf">Hallucination as a Computational Boundary: A Hierarchy of Inevitability and the Oracle Escape</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Changzhou University</span></p>
<p>æœ¬æ–‡å°†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å½¢å¼åŒ–ä¸ºæ¦‚ç‡å›¾çµæœºï¼Œæå‡ºäº†å¹»è§‰ä¸å¯é¿å…çš„è®¡ç®—å±‚çº§ï¼ˆå¯¹è§’åŒ–ã€ä¸å¯è®¡ç®—æ€§ã€ä¿¡æ¯è®ºè¾¹ç•Œï¼‰ï¼Œå¹¶é€šè¿‡â€œå­¦ä¹ è€…æ³µå¼•ç†â€ç»™å‡ºç†è®ºè¯æ˜ã€‚è®ºæ–‡é¦–æ¬¡ä»ç†è®ºä¸Šè¯æ˜äº†æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ä½œä¸ºå¤–éƒ¨â€œoracleâ€å¯å®ç°ç»å¯¹é€ƒé€¸ï¼Œå¹¶æå‡ºåŸºäºç¥ç»åšå¼ˆç†è®ºçš„æŒç»­å­¦ä¹ ä½œä¸ºå†…éƒ¨é€‚åº”è·¯å¾„ï¼Œå®éªŒè¯æ˜RAG-CLæ··åˆç­–ç•¥åœ¨å‡†ç¡®æ€§å’Œå¥å£®æ€§ä¸Šä¼˜äºå•ç‹¬ç­–ç•¥ã€‚ç»“è®ºè®¤ä¸ºï¼šå¹»è§‰æ˜¯LLMçš„æ ¹æœ¬é™åˆ¶ï¼Œä½†é€šè¿‡å¤–éƒ¨æ£€ç´¢æˆ–å†…éƒ¨æŒç»­å­¦ä¹ å¯ç³»ç»Ÿæ€§è§„é¿ï¼Œæå‡ºâ€œè®¡ç®—ç±»åˆ«å¯¹é½â€ä½œä¸ºAIå®‰å…¨çš„æ–°åŸåˆ™ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="211-Efficient-Edge-LLMs-Deployment-via-Hessian-Aware-Quantization-and-CPUâ€“GPU-Collaborative"><a href="#211-Efficient-Edge-LLMs-Deployment-via-Hessian-Aware-Quantization-and-CPUâ€“GPU-Collaborative" class="headerlink" title="211. Efficient Edge LLMs Deployment via Hessian-Aware Quantization and CPUâ€“GPU Collaborative"></a>211. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Efficient_Edge_LLMs_Deployment_via_HessianAware_Quantization_and_CPU_GPU_Collaborative.pdf">Efficient Edge LLMs Deployment via Hessian-Aware Quantization and CPUâ€“GPU Collaborative</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">The Hong Kong Polytechnic University</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºHessianæ„ŸçŸ¥é‡åŒ–ï¼ˆHAQï¼‰ä¸CPU-GPUååŒæ¨ç†çš„é«˜æ•ˆè¾¹ç¼˜ç«¯Mixture-of-Expertsï¼ˆMoEï¼‰å¤§è¯­è¨€æ¨¡å‹éƒ¨ç½²æ–¹æ¡ˆã€‚æ–¹æ³•é¦–å…ˆé€šè¿‡è‡ªé€‚åº”æ¿€æ´»å¹³æ»‘åŠHessiançŸ©é˜µæƒé‡é‡åŒ–ï¼Œå®ç°æ¿€æ´»ä¸æƒé‡çš„è”åˆ8æ¯”ç‰¹é‡åŒ–ï¼Œæ˜¾è‘—ç¼“è§£ç¦»ç¾¤å€¼å¯¼è‡´çš„ç²¾åº¦æŸå¤±ï¼Œå¹¶ç»“åˆä¸“å®¶æ¿€æ´»è·¯å¾„ç»Ÿè®¡ï¼Œè®¾è®¡ä¸“å®¶çº§ååŒå¸è½½ä¸ç¼“å­˜æœºåˆ¶ï¼Œæœ‰æ•ˆåˆ†é…GPUä¸CPUèµ„æºï¼Œé™ä½æ˜¾å­˜å‹åŠ›ä¸æ¨ç†å»¶è¿Ÿã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨OPTç³»åˆ—å’ŒMixtral-8Ã—7Bæ¨¡å‹ä¸Šï¼Œé‡åŒ–æ¨¡å‹æ¨ç†ç²¾åº¦æ¥è¿‘å…¨ç²¾åº¦ï¼Œæ˜¾å­˜å ç”¨é™ä½çº¦60%ï¼Œæ¨ç†å»¶è¿Ÿå’Œç³»ç»Ÿç¨³å®šæ€§å¤§å¹…æå‡ï¼Œä¸ºMoE LLMåœ¨å®é™…è¾¹ç¼˜ç¯å¢ƒä¸‹é«˜æ•ˆç¨³å®šéƒ¨ç½²æä¾›äº†å®ç”¨æŠ€æœ¯è·¯å¾„ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="212-DocR1-Evidence-Page-Guided-GRPO-for-Multi-Page-Document-Understanding"><a href="#212-DocR1-Evidence-Page-Guided-GRPO-for-Multi-Page-Document-Understanding" class="headerlink" title="212. DocR1: Evidence Page-Guided GRPO for Multi-Page Document Understanding"></a>212. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/DocR1__Evidence_Page-Guided_GRPO_for_Multi-Page_Document_Understanding.pdf">DocR1: Evidence Page-Guided GRPO for Multi-Page Document Understanding</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Science and Technology of China</span></p>
<p>DocR1æ˜¯ä¸€ç§ä¸“ä¸ºå¤šé¡µæ–‡æ¡£ç†è§£è®¾è®¡çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ï¼Œé€šè¿‡æå‡ºEvidence Page-Guided GRPOï¼ˆEviGRPOï¼‰å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œå¼•å…¥è¯æ®æ„ŸçŸ¥å¥–åŠ±æœºåˆ¶ï¼Œå®ç°ä»ç²—åˆ°ç»†çš„äººç±»å¼æ¨ç†ï¼šå…ˆæ£€ç´¢ç›¸å…³é¡µé¢ï¼Œå†ç”Ÿæˆç­”æ¡ˆã€‚ç»“åˆä¸¤é˜¶æ®µæ ‡æ³¨æµç¨‹å’Œè¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼ŒDocR1åœ¨å¤šä¸ªå¤šé¡µæ–‡æ¡£ç†è§£åŸºå‡†ä¸Šå–å¾—äº†æœ€å…ˆè¿›æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒäº†å•é¡µä»»åŠ¡ä¸Šçš„å¼ºè¡¨ç°ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="213-MCITlib-Multimodal-Continual-Instruction-Tuning-Library-and-Benchmark"><a href="#213-MCITlib-Multimodal-Continual-Instruction-Tuning-Library-and-Benchmark" class="headerlink" title="213. MCITlib: Multimodal Continual Instruction Tuning Library and Benchmark"></a>213. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/MCITlib__Multimodal_Continual_Instruction_Tuning_Library_and_Benchmark.pdf">MCITlib: Multimodal Continual Instruction Tuning Library and Benchmark</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">School of Advanced Interdisciplinary Sciences, UCAS</span></p>
<p>MCITlibæå‡ºäº†ä¸€ä¸ªé¢å‘å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„æŒç»­æŒ‡ä»¤å¾®è°ƒå¼€æºåº“ï¼Œæ¶µç›–8ç§ä»£è¡¨æ€§ç®—æ³•ï¼Œå¹¶åœ¨ä¸¥æ ¼ç­›é€‰çš„ä¸¤ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šç³»ç»Ÿè¯„æµ‹å„ç§æ–¹æ³•ï¼Œæœ‰æ•ˆè§£å†³ä¿¡æ¯æ³„éœ²å’Œå…¬å¹³æ¯”è¾ƒéš¾é¢˜ã€‚ç»“è®ºæ˜¾ç¤ºï¼Œä¸åŒæ–¹æ³•åœ¨ç¼“è§£é—å¿˜å’Œæå‡å¤šä»»åŠ¡æ€§èƒ½ä¸Šè¡¨ç°æœ‰å·®å¼‚ï¼ŒDISCOæ–¹æ³•è¡¨ç°æœ€ä½³ï¼Œä½†å­˜åœ¨å‚æ•°è†¨èƒ€é—®é¢˜ï¼Œåº“å°†æŒç»­æ‰©å±•ä»¥ä¿ƒè¿›å¤šæ¨¡æ€æŒç»­å­¦ä¹ é¢†åŸŸç ”ç©¶ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="214-â€œPull-or-Not-to-Pull-â€-Investigating-Moral-Biases-in-Leading-Large-Language-Models-Across-Ethical-Dilemmas"><a href="#214-â€œPull-or-Not-to-Pull-â€-Investigating-Moral-Biases-in-Leading-Large-Language-Models-Across-Ethical-Dilemmas" class="headerlink" title="214. â€œPull or Not to Pull?â€: Investigating Moral Biases in Leading Large Language Models Across Ethical Dilemmas"></a>214. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/_Pull_or_Not_to_Pull_''__Investigating_Moral_Biases_in_Leading_Large_Language_Models_Across_Ethical_.pdf">â€œPull or Not to Pull?â€: Investigating Moral Biases in Leading Large Language Models Across Ethical Dilemmas</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of New South Wales</span></p>
<p>æœ¬æ–‡ç³»ç»Ÿè¯„ä¼°äº†14ç§ä¸»æµå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨27ç±»â€œç”µè½¦éš¾é¢˜â€ä¸‹çš„é“å¾·å†³ç­–ä¸è§£é‡Šï¼Œæ¶µç›–åç§ä¼¦ç†å“²å­¦è§†è§’ï¼Œé‡‡ç”¨äºŒé˜¶æ®µåˆ†æ­¥æç¤ºå’Œå¤šæŒ‡æ ‡ï¼ˆå†³ç­–æœæ–­æ€§ã€è§£é‡Šä¸€è‡´æ€§ã€ä¸äººç±»é“å¾·ä¸€è‡´æ€§ã€æƒ…å¢ƒåå·®æ•æ„Ÿæ€§ï¼‰åˆ†æã€‚ç»“æœæ˜¾ç¤ºï¼Œæ¨ç†å¢å¼ºå‹æ¨¡å‹æ›´å…·å†³ç­–æœæ–­æ€§å’Œç»“æ„åŒ–è§£é‡Šï¼Œä½†ä¸äººç±»å…±è¯†çš„å¯¹é½åº¦å¹¶ä¸æ€»æ˜¯æ›´é«˜ï¼Œä¸”åœ¨æŸäº›ä¼¦ç†æ¡†æ¶ä¸‹ï¼ˆå¦‚äº²æƒ…ã€è‡ªåˆ©ã€æ³•å¾‹ï¼‰åå·®æ˜æ˜¾ã€‚ç ”ç©¶å‘ç°â€œå…¬å¹³â€â€œåˆ©ä»–â€â€œç¾å¾·ä¼¦ç†â€æç¤ºåœ¨å†³ç­–æœæ–­ã€è§£é‡Šä¸€è‡´å’Œäººç±»ä¸€è‡´æ€§é—´è¾¾æˆè¾ƒå¥½å¹³è¡¡ï¼Œå»ºè®®å°†é“å¾·æ¨ç†çº³å…¥LLMå¯¹é½è¯„ä¼°ä¸»è½´ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="215-Selection-and-Exploitation-of-High-Quality-Knowledge-from-Large-Language-Models-for-Recommendation"><a href="#215-Selection-and-Exploitation-of-High-Quality-Knowledge-from-Large-Language-Models-for-Recommendation" class="headerlink" title="215. Selection and Exploitation of High-Quality Knowledge from Large Language Models for Recommendation"></a>215. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Selection_and_Exploitation_of_High-Quality_Knowledge_from_Large_Language_Models_for_Recommendation.pdf">Selection and Exploitation of High-Quality Knowledge from Large Language Models for Recommendation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Kuaishou Technology</span></p>
<p>è®ºæ–‡æå‡ºäº†KSERæ¡†æ¶ï¼Œé€šè¿‡çŸ¥è¯†è¿‡æ»¤æ¨¡å—ï¼ˆESFNetï¼‰å’ŒåµŒå…¥ç©ºé—´å¯¹é½æ¨¡å—ï¼Œæœ‰æ•ˆåœ°ä»å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­ç­›é€‰å’Œåˆ©ç”¨é«˜è´¨é‡çŸ¥è¯†ç”¨äºæ¨èç³»ç»Ÿã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒKSERä¸ä»…èƒ½æå‡æ¨èæ¨¡å‹æ€§èƒ½ï¼Œè¿˜èƒ½é€šè¿‡extractor-onlyè®­ç»ƒç­–ç•¥é™ä½è®¡ç®—æˆæœ¬ï¼ŒéªŒè¯äº†çŸ¥è¯†è¿‡æ»¤ä¸å¯¹é½æ¨¡å—çš„æœ‰æ•ˆæ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="216-What-One-Cannot-Two-Can-Two-Layer-Transformers-Provably-Represent-Induction-Heads-on-Any-Order-Markov-Chains"><a href="#216-What-One-Cannot-Two-Can-Two-Layer-Transformers-Provably-Represent-Induction-Heads-on-Any-Order-Markov-Chains" class="headerlink" title="216. What One Cannot, Two Can: Two-Layer Transformers Provably Represent Induction Heads on Any-Order Markov Chains"></a>216. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/What_One_Cannot,_Two_Can__Two-Layer_Transformers_Provably_Represent_Induction_Heads_on_Any-Order_Mar.pdf">What One Cannot, Two Can: Two-Layer Transformers Provably Represent Induction Heads on Any-Order Markov Chains</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Massachusetts Institute of Technology</span></p>
<p>è¯¥è®ºæ–‡æå‡ºå¹¶ä¸¥æ ¼è¯æ˜äº†ï¼šä»…ç”¨ä¸¤å±‚ã€æ¯å±‚ä¸€ä¸ªæ³¨æ„åŠ›å¤´çš„Transformerå³å¯è¡¨å¾ä»»æ„é˜¶çš„Markové“¾çš„æ¡ä»¶k-gramæ¨¡å‹ï¼ˆå³å½’çº³å¤´ä»»åŠ¡ï¼‰ï¼Œçªç ´äº†æ­¤å‰éœ€ä¸‰å±‚ç»“æ„çš„ç†è®ºä¸‹ç•Œã€‚ä½œè€…è¿˜å¯¹ä¸€é˜¶Markové“¾ä¸Šè¯¥ç»“æ„çš„æ¢¯åº¦ä¸‹é™å­¦ä¹ åŠ¨æ€è¿›è¡Œäº†åˆ†æï¼Œè¯´æ˜æµ…å±‚Transformeræ¨¡å‹åœ¨ç»“æ„åŒ–åºåˆ—å»ºæ¨¡ä»»åŠ¡ä¸Šä¹Ÿå…·å¤‡å¼ºå¤§çš„in-context learningèƒ½åŠ›ã€‚ç»“è®ºè¡¨æ˜Transformerçš„å±‚æ•°ä¸å¯è¡¨è¾¾çš„Markové˜¶æ•°å…³ç³»è¾¾åˆ°äº†æœ€ç´§è‡´çš„å·²çŸ¥è¡¨å¾ï¼Œæ·±åŒ–äº†å¯¹å…¶in-context learningæœ¬è´¨çš„ç†è§£ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="217-Adapting-LLMs-to-Time-Series-Forecasting-via-Temporal-Heterogeneity-Modeling-and-Semantic-Alignment"><a href="#217-Adapting-LLMs-to-Time-Series-Forecasting-via-Temporal-Heterogeneity-Modeling-and-Semantic-Alignment" class="headerlink" title="217. Adapting LLMs to Time Series Forecasting via Temporal Heterogeneity Modeling and Semantic Alignment"></a>217. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Adapting_LLMs_to_Time_Series_Forecasting_via_Temporal_Heterogeneity_Modeling_and_Semantic_Alignment.pdf">Adapting LLMs to Time Series Forecasting via Temporal Heterogeneity Modeling and Semantic Alignment</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Tianjin University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†TALONæ¡†æ¶ï¼Œé€šè¿‡å¼‚è´¨æ—¶åºç¼–ç å™¨å’Œè¯­ä¹‰å¯¹é½æ¨¡å—ï¼Œå°†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é€‚é…äºæ—¶é—´åºåˆ—é¢„æµ‹ã€‚æ–¹æ³•åŒ…æ‹¬å¯¹å¤šå˜é‡æ—¶é—´åºåˆ—è¿›è¡Œç»“æ„åˆ†æ®µã€ä¸“å®¶æ¨¡å‹åŠ¨æ€è·¯ç”±ï¼Œä»¥åŠç”¨è‡ªç„¶è¯­è¨€ç»Ÿè®¡ç‰¹å¾å¼•å¯¼LLMåµŒå…¥ï¼Œå¹¶é€šè¿‡å¯¹æ¯”å­¦ä¹ å®ç°æ—¶åºä¸è¯­è¨€è¡¨ç¤ºçš„ç»†ç²’åº¦å¯¹é½ã€‚å®éªŒæ˜¾ç¤ºTALONåœ¨ä¸ƒä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰LLMåŠæ·±åº¦å­¦ä¹ æ–¹æ³•ï¼ŒMSEæå‡æœ€é«˜è¾¾11%ï¼Œå…·å¤‡é«˜æ•ˆç‡å’Œå¼ºæ³›åŒ–èƒ½åŠ›ï¼Œå°¤å…¶åœ¨é›¶æ ·æœ¬å’Œè·¨åŸŸè¿ç§»ç¯å¢ƒä¸‹è¡¨ç°çªå‡ºã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="218-Multi-Dimensional-Summarization-Agents-with-Context-Aware-Reasoning-over-Enterprise-Tables"><a href="#218-Multi-Dimensional-Summarization-Agents-with-Context-Aware-Reasoning-over-Enterprise-Tables" class="headerlink" title="218. Multi-Dimensional Summarization Agents with Context-Aware Reasoning over Enterprise Tables"></a>218. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Multi-Dimensional_Summarization_Agents_with_Context-Aware_Reasoning_over_Enterprise_Tables.pdf">Multi-Dimensional Summarization Agents with Context-Aware Reasoning over Enterprise Tables</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Amazon</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤šæ™ºèƒ½ä½“çš„æ¡†æ¶ï¼Œç»“åˆå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œå®ç°å¯¹ä¼ä¸šè¡¨æ ¼å¤šç»´ç»“æ„åŒ–æ•°æ®çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥è‡ªåŠ¨æ‘˜è¦ã€‚æ–¹æ³•æµç¨‹åŒ…æ‹¬åˆ‡ç‰‡ã€åº¦é‡å˜å¼‚æ£€æµ‹ã€ä¸Šä¸‹æ–‡å¢å¼ºå’ŒLLMé©±åŠ¨ç”Ÿæˆï¼Œå„æ™ºèƒ½ä½“åˆ†å·¥åä½œï¼Œæå‡äº†ç”Ÿæˆæ‘˜è¦çš„äº‹å®ä¸€è‡´æ€§ã€è¦†ç›–ç‡å’Œä¸šåŠ¡ç›¸å…³æ€§ã€‚ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨Kaggleä¼ä¸šæ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿå¹³é“ºå¼LLMå’Œæ¨¡æ¿åŒ–NLGæ–¹æ³•ï¼Œåœ¨æ•°æ®å¯¹é½ã€å…³é”®ä¿¡æ¯å±•ç°å’Œå†³ç­–æ´å¯Ÿæ–¹é¢è¡¨ç°æ›´ä½³ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="219-Dynamic-Benchmark-Construction-for-Evaluating-Large-Language-Models-on-Real-World-Codes"><a href="#219-Dynamic-Benchmark-Construction-for-Evaluating-Large-Language-Models-on-Real-World-Codes" class="headerlink" title="219. Dynamic Benchmark Construction for Evaluating Large Language Models on Real-World Codes"></a>219. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Dynamic_Benchmark_Construction_for_Evaluating_Large_Language_Models_on_Real-World_Codes.pdf">Dynamic Benchmark Construction for Evaluating Large Language Models on Real-World Codes</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Beihang University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†CODE2BENCHï¼Œä¸€ä¸ªç”¨äºåŠ¨æ€æ„å»ºçœŸå®ä¸–ç•Œä»£ç åŸºå‡†çš„è‡ªåŠ¨åŒ–ç®¡é“ï¼Œç»“åˆäº†è‡ªåŠ¨ä»£ç æŠ“å–ã€Scope Graphä¾èµ–åˆ†æå’ŒåŸºäºæ€§è´¨çš„è‡ªåŠ¨åŒ–æµ‹è¯•ï¼Œæœ‰æ•ˆè§£å†³äº†æ•°æ®æ±¡æŸ“å’Œæµ‹è¯•è¦†ç›–ç‡ä½çš„é—®é¢˜ã€‚å®éªŒè¡¨æ˜ç°æœ‰ä¸»æµå¤§è¯­è¨€æ¨¡å‹åœ¨è‡ªåŒ…å«å¤æ‚é€»è¾‘ä»»åŠ¡å’Œè·¨è¯­è¨€æ³›åŒ–ä¸Šè¡¨ç°è¾ƒå¼±ï¼Œä½†åœ¨å¸¸ç”¨åº“äº¤äº’ä»»åŠ¡è¡¨ç°è¾ƒå¥½ï¼ŒCODE2BENCHèƒ½æ›´çœŸå®æ­ç¤ºæ¨¡å‹åœ¨å¤æ‚ä»£ç ç”Ÿæˆä¸­çš„ä¸è¶³ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="220-Improved-Personalized-Headline-Generation-via-Denoising-Fake-Interests-from-Implicit-Feedback"><a href="#220-Improved-Personalized-Headline-Generation-via-Denoising-Fake-Interests-from-Implicit-Feedback" class="headerlink" title="220. Improved Personalized Headline Generation via Denoising Fake Interests from Implicit Feedback"></a>220. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Improved_Personalized_Headline_Generation_via_Denoising_Fake_Interests_from_Implicit_Feedback.pdf">Improved Personalized Headline Generation via Denoising Fake Interests from Implicit Feedback</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Henan Institute of Advanced Technology, Zhengzhou University</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ä¸ªæ€§åŒ–æ–°é—»æ ‡é¢˜ç”Ÿæˆæ¡†æ¶PHG-DIFï¼Œé€šè¿‡åŒé˜¶æ®µè¿‡æ»¤ï¼ˆåŸºäºæ–°é—»å’Œæ—¶é—´ï¼‰å»é™¤ç”¨æˆ·å†å²ç‚¹å‡»æµä¸­çš„å™ªå£°ç‚¹å‡»ï¼Œå¹¶èåˆå³æ—¶ã€æ¼”åŒ–å’Œç¨³å®šå…´è¶£å»ºæ¨¡æ¨¡å—ï¼ŒåŠ¨æ€åˆ»ç”»ç”¨æˆ·å¤šç»´å…´è¶£ï¼Œç»“åˆBreaking-Newsæ„ŸçŸ¥ç”Ÿæˆå™¨æå‡äº‹å®å‡†ç¡®æ€§ä¸ä¸ªæ€§åŒ–çš„å¹³è¡¡ã€‚åŒæ—¶ï¼Œä½œè€…æ„å»ºäº†åŒ…å«ç”¨æˆ·åœç•™æ—¶é•¿æ ‡æ³¨çš„å¤§è§„æ¨¡åŸºå‡†æ•°æ®é›†DT-PENSã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—å‡å°‘äº†ç‚¹å‡»å™ªå£°å¯¹ä¸ªæ€§åŒ–ç”Ÿæˆçš„è´Ÿé¢å½±å“ï¼Œæå‡äº†æ ‡é¢˜è´¨é‡ï¼Œåœ¨DT-PENSä¸Šå–å¾—äº†SOTAè¡¨ç°ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="221-A-Stable-and-Principled-Loss-Function-for-Direct-Language-Model-Alignment"><a href="#221-A-Stable-and-Principled-Loss-Function-for-Direct-Language-Model-Alignment" class="headerlink" title="221. A Stable and Principled Loss Function for Direct Language Model Alignment"></a>221. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/A_Stable_and_Principled_Loss_Function_for_Direct_Language_Model_Alignment.pdf">A Stable and Principled Loss Function for Direct Language Model Alignment</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Peking University</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ç¨³å®šåå¥½ä¼˜åŒ–ï¼ˆSPOï¼‰æŸå¤±å‡½æ•°ï¼Œç”¨äºç›´æ¥å¯¹é½å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸äººç±»åå¥½ã€‚è¯¥æ–¹æ³•é€šè¿‡ç†è®ºåˆ†æå’Œæ¢¯åº¦å¯¹æ¯”ï¼Œä¼˜åŒ–æ¨¡å‹çš„logitså·®å€¼è‡³æœ‰é™ç›®æ ‡ï¼Œé¿å…äº†DPOæ–¹æ³•ä¸‹çš„ä¸ç¨³å®šå’Œâ€œå¥–åŠ±é»‘å®¢â€é—®é¢˜ã€‚å®éªŒè¡¨æ˜SPOåœ¨Qwen2.5-7Bå’ŒLlama-3-8Bæ¨¡å‹ä¸Šå‡ä¼˜äºDPOï¼Œæ˜¾è‘—æå‡æ¨¡å‹å¯¹é½è´¨é‡ï¼Œå…·æœ‰æ›´å¥½çš„ç¨³å®šæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="222-DySK-Attn-A-Framework-for-Efficient-Real-Time-Knowledge-Updating-in-Large-Language-Models-via-Dynamic-Sparse-Knowledge-Attention"><a href="#222-DySK-Attn-A-Framework-for-Efficient-Real-Time-Knowledge-Updating-in-Large-Language-Models-via-Dynamic-Sparse-Knowledge-Attention" class="headerlink" title="222. DySK-Attn: A Framework for Efficient, Real-Time Knowledge Updating in Large Language Models via Dynamic Sparse Knowledge Attention"></a>222. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/DySK-Attn__A_Framework_for_Efficient,_Real-Time_Knowledge_Updating_in_Large_Language_Models_via_Dyna.pdf">DySK-Attn: A Framework for Efficient, Real-Time Knowledge Updating in Large Language Models via Dynamic Sparse Knowledge Attention</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Department of Computer Science, San Francisco State University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºDySK-Attnæ¡†æ¶ï¼Œé€šè¿‡åŠ¨æ€çŸ¥è¯†å›¾è°±ä¸ç¨€ç–çŸ¥è¯†æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ç°å¤§è¯­è¨€æ¨¡å‹å®æ—¶é«˜æ•ˆåœ°èåˆå¤–éƒ¨æœ€æ–°çŸ¥è¯†ã€‚æ–¹æ³•åŒ…æ‹¬ä¸¤é˜¶æ®µæ£€ç´¢ï¼ˆç²—æ£€ç´¢+ç¨€ç–æ³¨æ„åŠ›é€‰å–top-kçŸ¥è¯†ç‚¹ï¼‰ã€çŸ¥è¯†å‘é‡èåˆè¿›LLMç”Ÿæˆè¿‡ç¨‹ï¼Œå¹¶æ”¯æŒçŸ¥è¯†å›¾è°±æ¯«ç§’çº§å®æ—¶æ›´æ–°ã€‚å®éªŒè¡¨æ˜ï¼ŒDySK-Attnåœ¨æ—¶æ•ˆæ€§é—®ç­”ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºRAGå’Œæ¨¡å‹ç¼–è¾‘ç­‰ä¸»æµæ–¹æ³•ï¼Œå…¼å…·è®¡ç®—æ•ˆç‡å’Œäº‹å®å‡†ç¡®æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="223-Schema-Lineage-Extraction-at-Scale-Multilingual-Pipelines-Composite-Evaluation-and-Language-Model-Benchmarks"><a href="#223-Schema-Lineage-Extraction-at-Scale-Multilingual-Pipelines-Composite-Evaluation-and-Language-Model-Benchmarks" class="headerlink" title="223. Schema Lineage Extraction at Scale: Multilingual Pipelines, Composite Evaluation, and Language-Model Benchmarks"></a>223. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Schema_Lineage_Extraction_at_Scale__Multilingual_Pipelines,_Composite_Evaluation,_and_Language-Model.pdf">Schema Lineage Extraction at Scale: Multilingual Pipelines, Composite Evaluation, and Language-Model Benchmarks</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Microsoft</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°æ¡†æ¶ï¼Œå®ç°å¯¹å¤šè¯­è¨€ä¼ä¸šæ•°æ®ç®¡é“è„šæœ¬ä¸­ç»†ç²’åº¦schema lineageçš„è‡ªåŠ¨æŠ½å–ï¼Œæ¶µç›–æºschemaã€æºè¡¨ã€è½¬æ¢é€»è¾‘å’Œèšåˆæ“ä½œï¼Œå¹¶æå‡ºäº†SLiCEè¯„æµ‹æŒ‡æ ‡å¯¹ç»“æ„å’Œè¯­ä¹‰æ­£ç¡®æ€§è¿›è¡Œå¤åˆè¯„ä»·ã€‚å®éªŒè¯æ˜ï¼Œéšç€æ¨¡å‹è§„æ¨¡å’Œæç¤ºç­–ç•¥çš„æå‡ï¼ˆå¦‚é“¾å¼æ€ç»´ï¼‰ï¼Œå¼€æº32Bæ¨¡å‹çš„æ€§èƒ½å¯åª²ç¾GPT-4oç­‰ä¸“æœ‰å¤§æ¨¡å‹ï¼Œä¸ºä¼ä¸šçº§schemaæ„ŸçŸ¥æ™ºèƒ½ä½“çš„ç»æµéƒ¨ç½²æä¾›å¯è¡Œè·¯å¾„ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="224-LL3M-Large-Language-3D-Modelers"><a href="#224-LL3M-Large-Language-3D-Modelers" class="headerlink" title="224. LL3M: Large Language 3D Modelers"></a>224. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/LL3M__Large_Language_3D_Modelers.pdf">LL3M: Large Language 3D Modelers</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Chicago</span></p>
<p>è¯¥è®ºæ–‡æå‡ºLL3Mï¼Œä¸€ç§å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œåˆ©ç”¨å¤šç§é¢„è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åä½œç”Ÿæˆå¯ç¼–è¾‘çš„3Dèµ„äº§ï¼Œé€šè¿‡è‡ªåŠ¨ç¼–å†™è§£é‡Šæ€§å¼ºçš„Blender Pythonä»£ç å®ç°3Då»ºæ¨¡å’Œç¼–è¾‘ã€‚LL3Måˆ›æ–°æ€§åœ°å°†å½¢çŠ¶ç”Ÿæˆä»»åŠ¡è½¬åŒ–ä¸ºä»£ç ç¼–å†™æµç¨‹ï¼ŒåŒ…å«è§„åˆ’ã€æ£€ç´¢ã€ç¼–å†™ã€æ‰¹è¯„ã€éªŒè¯å’Œç”¨æˆ·åé¦ˆå…­ç±»æ™ºèƒ½ä½“ï¼Œå¹¶å¼•å…¥BlenderRAGæ•°æ®åº“æå‡é«˜çº§å»ºæ¨¡èƒ½åŠ›ï¼Œå®ç°é«˜è´¨é‡ã€å¯è¿­ä»£ã€æ˜“äºäººæœºåä½œçš„3Dèµ„äº§ç”Ÿæˆå’Œç»†åŒ–ã€‚ç»“è®ºè¡¨æ˜ï¼ŒLL3Mæ— éœ€3Dæ•°æ®é›†è®­ç»ƒå³å¯å®ç°é«˜ä¿çœŸã€å¯è§£é‡Šçš„3Dèµ„äº§ç”Ÿæˆï¼Œå¹¶æ”¯æŒç”¨æˆ·å¤šè½®è‡ªç„¶è¯­è¨€ç¼–è¾‘ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="225-Multi-head-Transformers-Provably-Learn-Symbolic-Multi-step-Reasoning-via-Gradient-Descent"><a href="#225-Multi-head-Transformers-Provably-Learn-Symbolic-Multi-step-Reasoning-via-Gradient-Descent" class="headerlink" title="225. Multi-head Transformers Provably Learn Symbolic Multi-step Reasoning via Gradient Descent"></a>225. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Multi-head_Transformers_Provably_Learn_Symbolic_Multi-step_Reasoning_via_Gradient_Descent.pdf">Multi-head Transformers Provably Learn Symbolic Multi-step Reasoning via Gradient Descent</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Carnegie Mellon University</span></p>
<p>æœ¬æ–‡æå‡ºå¹¶ç†è®ºè¯æ˜äº†å•å±‚å¤šå¤´Transformerå¯é€šè¿‡æ¢¯åº¦ä¸‹é™æœºåˆ¶å­¦ä¹ å¹¶æ³›åŒ–ç¬¦å·åŒ–å¤šæ­¥é“¾å¼æ¨ç†ä»»åŠ¡ï¼Œå°¤å…¶åœ¨æ ‘ç»“æ„ä¸Šçš„è·¯å¾„æŸ¥æ‰¾ï¼ŒåŒ…æ‹¬å•æ­¥å’Œå¤æ‚ä¸¤é˜¶æ®µï¼ˆå…ˆåå‘å†æ­£å‘ï¼‰æ¨ç†ã€‚æ„å»ºæ€§å’Œä¼˜åŒ–åˆ†ææ­ç¤ºå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶å¯è‡ªä¸»åˆ†å·¥å¹¶åè°ƒå®Œæˆé€’å½’è·¯å¾„éå†å’Œé˜¶æ®µæ§åˆ¶ï¼Œä¸”è¯¥èƒ½åŠ›èƒ½æ³›åŒ–åˆ°æœªè§ç»“æ„ï¼Œè¡¨æ˜Transformerå­¦åˆ°ç®—æ³•è§„åˆ™è€Œéä»…è®°å¿†è®­ç»ƒæ ·æœ¬ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="226-Human-Alignment-and-Calibration-of-Inference-Time-Uncertainty-in-Large-Language-Models"><a href="#226-Human-Alignment-and-Calibration-of-Inference-Time-Uncertainty-in-Large-Language-Models" class="headerlink" title="226. Human-Alignment and Calibration of Inference-Time Uncertainty in Large Language Models"></a>226. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Human-Alignment_and_Calibration_of_Inference-Time_Uncertainty_in_Large_Language_Models.pdf">Human-Alignment and Calibration of Inference-Time Uncertainty in Large Language Models</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Vanderbilt University</span></p>
<p>æœ¬æ–‡ç³»ç»Ÿè¯„ä¼°äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†æ—¶çš„ä¸ç¡®å®šæ€§åº¦é‡æ–¹æ³•ï¼Œé‡ç‚¹åˆ†æå…¶ä¸äººç±»ç¾¤ä½“ä¸ç¡®å®šæ€§å’Œæ¨¡å‹ä¼ ç»Ÿæ ¡å‡†ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚é€šè¿‡å¤šç§ç†µç±»ä¸ç¡®å®šæ€§æŒ‡æ ‡ï¼ˆå¦‚choice entropyã€top-k entropyã€top-p entropyç­‰ï¼‰åœ¨å¤§è§„æ¨¡äººç±»è°ƒæŸ¥æ•°æ®é›†å’Œæ ‡å‡†MMLUåŸºå‡†ä¸Šè¿›è¡Œå¯¹æ¯”ï¼Œå‘ç°è¿™äº›åº¦é‡ä¸äººç±»ä¸ç¡®å®šæ€§é«˜åº¦ç›¸å…³ï¼Œå¹¶ä¸”åœ¨æ¨¡å‹æ ¡å‡†æ–¹é¢å…·æœ‰ç»Ÿè®¡æ˜¾è‘—æ€§ã€‚ç»“è®ºæŒ‡å‡ºï¼Œç†µç±»æ¨ç†æ—¶ä¸ç¡®å®šæ€§åº¦é‡èƒ½è¾ƒå¥½åæ˜ äººç±»ä¸ç¡®å®šæ€§å¹¶å…·å¤‡ä¸€å®šæ¨¡å‹æ ¡å‡†èƒ½åŠ›ï¼Œæœªæ¥å¯æ‹“å±•è‡³å¼€æ”¾å¼é—®é¢˜å’Œå¢å¼ºäººæœºäº¤äº’ä¿¡ä»»ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="227-Capabilities-of-GPT-5-on-Multimodal-Medical-Reasoning"><a href="#227-Capabilities-of-GPT-5-on-Multimodal-Medical-Reasoning" class="headerlink" title="227. Capabilities of GPT-5 on Multimodal Medical Reasoning"></a>227. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Capabilities_of_GPT-5_on_Multimodal_Medical_Reasoning.pdf">Capabilities of GPT-5 on Multimodal Medical Reasoning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Emory University</span></p>
<p>æœ¬è®ºæ–‡ç³»ç»Ÿè¯„ä¼°äº†GPT-5åœ¨åŒ»å­¦é¢†åŸŸå¤šæ¨¡æ€æ¨ç†ä»»åŠ¡ä¸Šçš„èƒ½åŠ›ï¼Œé‡‡ç”¨ç»Ÿä¸€çš„é›¶æ ·æœ¬é“¾å¼æ€ç»´(CoT)åè®®ï¼Œæ¶µç›–æ–‡æœ¬é—®ç­”å’Œè§†è§‰é—®ç­”ï¼Œå¯¹æ¯”GPT-5åŠå¤šä¸ªå˜ä½“ä¸GPT-4oä»¥åŠäººç±»ä¸“å®¶åœ¨MedQAã€MedXpertQAï¼ˆæ–‡æœ¬å’Œå¤šæ¨¡æ€ï¼‰ã€MMLUåŒ»å­¦å­é›†ã€USMLEè‡ªæµ‹å’ŒVQA-RADç­‰åŸºå‡†ä¸Šçš„è¡¨ç°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼šGPT-5åœ¨æ‰€æœ‰é—®ç­”åŸºå‡†ä¸Šå‡å®ç°äº†æœ€å…ˆè¿›çš„å‡†ç¡®ç‡ï¼Œå°¤å…¶åœ¨å¤šæ¨¡æ€æ¨ç†ä»»åŠ¡ä¸Šæ˜¾è‘—è¶…è¶ŠGPT-4oå’Œäººç±»ä¸“å®¶ï¼Œæå‡å¹…åº¦è¾¾20%ä»¥ä¸Šï¼Œå±•ç¤ºäº†å…¶ä½œä¸ºä¸´åºŠå†³ç­–æ”¯æŒæ ¸å¿ƒç»„ä»¶çš„æ½œåŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="228-PYVERITAS-On-Verifying-Python-via-LLM-Based-Transpilation-and-Bounded-Model-Checking-for-C"><a href="#228-PYVERITAS-On-Verifying-Python-via-LLM-Based-Transpilation-and-Bounded-Model-Checking-for-C" class="headerlink" title="228. PYVERITAS: On Verifying Python via LLM-Based Transpilation and Bounded Model Checking for C"></a>228. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/PyVeritas__On_Verifying_Python_via_LLM-Based_Transpilation_and_Bounded_Model_Checking_for_C.pdf">PYVERITAS: On Verifying Python via LLM-Based Transpilation and Bounded Model Checking for C</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Oxford</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†PYVERITASæ¡†æ¶ï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å°†Pythonä»£ç é«˜å±‚æ¬¡è½¬è¯‘ä¸ºCä»£ç ï¼Œå¹¶ç»“åˆCBMCæœ‰ç•Œæ¨¡å‹æ£€æµ‹ä¸MaxSATæ•…éšœå®šä½å·¥å…·å®ç°å¯¹Pythonç¨‹åºçš„å½¢å¼åŒ–éªŒè¯ä¸é”™è¯¯å®šä½ã€‚å®éªŒè¡¨æ˜ï¼Œéƒ¨åˆ†ä¸“ç”¨ä»£ç å¤§æ¨¡å‹ï¼ˆå¦‚QWEN2.5-CODERï¼‰èƒ½åœ¨80-90%çš„æ¡ˆä¾‹ä¸­ç”Ÿæˆè¯­ä¹‰ç­‰ä»·ä¸”å¯éªŒè¯çš„Cä»£ç ï¼Œå®ç°å¯¹å°å‹ä½†éå¹³å‡¡Pythonç¨‹åºçš„æœ‰æ•ˆéªŒè¯å’Œå¯è§£é‡Šçš„é”™è¯¯è¯Šæ–­ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="229-Can-LLMs-Detect-Their-Confabulations-Estimating-Reliability-in-Uncertainty-Aware-Language-Models"><a href="#229-Can-LLMs-Detect-Their-Confabulations-Estimating-Reliability-in-Uncertainty-Aware-Language-Models" class="headerlink" title="229. Can LLMs Detect Their Confabulations? Estimating Reliability in Uncertainty-Aware Language Models"></a>229. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Can_LLMs_Detect_Their_Confabulations__Estimating_Reliability_in_Uncertainty-Aware_Language_Models.pdf">Can LLMs Detect Their Confabulations? Estimating Reliability in Uncertainty-Aware Language Models</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">KTH Royal Institute of Technology</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºä¸ç¡®å®šæ€§å¼•å¯¼çš„æ¢æµ‹æ–¹æ³•ï¼Œé€šè¿‡è®¡ç®—LLMè¾“å‡ºçš„tokençº§åˆ«çš„aleatoricå’Œepistemicä¸ç¡®å®šæ€§ï¼Œèšåˆé«˜ä¸ç¡®å®šæ€§çš„éšè—çŠ¶æ€ï¼Œæå‡å¯¹å“åº”å¯é æ€§çš„é¢„æµ‹èƒ½åŠ›ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é¢å¯¹æ­£ç¡®å’Œè¯¯å¯¼æ€§ä¸Šä¸‹æ–‡æ—¶ï¼Œèƒ½æ›´æœ‰æ•ˆæ£€æµ‹LLMè¾“å‡ºçš„ä¸å¯é å†…å®¹ï¼Œä¼˜äºç›´æ¥ä¸ç¡®å®šæ€§ä¿¡å·ï¼Œæ­ç¤ºäº†ä¸Šä¸‹æ–‡å¯¹æ¨¡å‹è¿‡åº¦è‡ªä¿¡é”™è¯¯çš„å½±å“ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="230-Optimal-Transport-Regularization-for-Speech-Text-Alignment-in-Spoken-Language-Models"><a href="#230-Optimal-Transport-Regularization-for-Speech-Text-Alignment-in-Spoken-Language-Models" class="headerlink" title="230. Optimal Transport Regularization for Speech Text Alignment in Spoken Language Models"></a>230. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Optimal_Transport_Regularization_for_Speech_Text_Alignment_in_Spoken_Language_Models.pdf">Optimal Transport Regularization for Speech Text Alignment in Spoken Language Models</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Mashang Consumer Finance Co., Ltd.</span></p>
<p>æœ¬æ–‡æå‡ºäº†Optimal Transport Regularization (OTReg)æ–¹æ³•ï¼Œå°†è¯­éŸ³-æ–‡æœ¬å¯¹é½å»ºæ¨¡ä¸ºæœ€ä¼˜ä¼ è¾“é—®é¢˜ï¼Œé€šè¿‡æ— å‚æ•°æ­£åˆ™åŒ–æŸå¤±æå‡Spoken Language Modelsï¼ˆSLMsï¼‰çš„è®­ç»ƒæ•ˆæœå’Œæ³›åŒ–èƒ½åŠ›ã€‚OTRegæ— éœ€é¢å¤–æ ‡ç­¾æˆ–å‚æ•°ï¼Œç›´æ¥å¯¹é½è¯­éŸ³ä¸æ–‡æœ¬åµŒå…¥ï¼Œå®éªŒæ˜¾ç¤ºè¯¥æ–¹æ³•æœ‰æ•ˆç¼“è§£æ¨¡æ€é—´å·®è·ï¼Œæå‡å¤šè¯­è¨€è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰ä»»åŠ¡çš„è·¨åŸŸæ³›åŒ–æ€§èƒ½ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="231-TBAC-UniImage-Unified-Understanding-and-Generation-by-Ladder-Side-Diffusion-Tuning"><a href="#231-TBAC-UniImage-Unified-Understanding-and-Generation-by-Ladder-Side-Diffusion-Tuning" class="headerlink" title="231. TBAC-UniImage: Unified Understanding and Generation by Ladder-Side Diffusion Tuning"></a>231. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/TBAC-UniImage__Unified_Understanding_and_Generation_by_Ladder-Side_Diffusion_Tuning.pdf">TBAC-UniImage: Unified Understanding and Generation by Ladder-Side Diffusion Tuning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Basic Algorithm Center, PCG, Tencent</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†TBAC-UniImageï¼Œä¸€ç§é€šè¿‡Ladder-Side Diffusion Tuningæœºåˆ¶æ·±åº¦èåˆå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ä¸Diffusion Transformerï¼ˆDiTï¼‰çš„ç»Ÿä¸€å¤šæ¨¡æ€ç†è§£ä¸ç”Ÿæˆæ¨¡å‹ã€‚æ–¹æ³•é‡‡ç”¨åˆ†å±‚æ¡ä»¶æœºåˆ¶ï¼Œå°†MLLMä¸åŒå±‚çš„éšè—çŠ¶æ€ä½œä¸ºæ¡ä»¶è¾“å…¥åˆ°DiTå„å±‚ï¼Œæå‡ç†è§£ä¸ç”Ÿæˆçš„ååŒèƒ½åŠ›ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ¨¡å‹åœ¨GenEvalã€DPG-Benchå’ŒTIIF-Benchç­‰å¤šä¸ªåŸºå‡†ä¸Šå…·æœ‰é¢†å…ˆçš„ç»Ÿä¸€ç†è§£ä¸ç”Ÿæˆæ€§èƒ½ï¼Œå°¤å…¶åœ¨å¤æ‚æŒ‡ä»¤è·Ÿéšå’Œå¤šæ¨¡æ€ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="232-Dual-Information-Speech-Language-Models-for-Emotional-Conversations"><a href="#232-Dual-Information-Speech-Language-Models-for-Emotional-Conversations" class="headerlink" title="232. Dual Information Speech Language Models for Emotional Conversations"></a>232. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Dual_Information_Speech_Language_Models_for_Emotional_Conversations.pdf">Dual Information Speech Language Models for Emotional Conversations</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Mashang Consumer Finance Co., Ltd.</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§é«˜æ•ˆæ‰©å±•ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸ºè¯­éŸ³è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰çš„æ–¹æ³•ï¼Œé€šè¿‡è®¾è®¡å¼‚æ„åŒé€‚é…å™¨ç»“æ„å¹¶é‡‡ç”¨å¼±ç›‘ç£è®­ç»ƒç­–ç•¥ï¼Œå®ç°äº†å¯¹è¯­éŸ³ä¸­çš„å‰¯è¯­è¨€å’Œè¯­è¨€ä¿¡æ¯çš„ç»“æ„åŒ–è§£è€¦è¡¨ç¤ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä»…éœ€è®­ç»ƒé€‚é…å™¨å³å¯åœ¨æƒ…æ„Ÿå¯¹è¯åœºæ™¯ä¸­é«˜æ•ˆèåˆå‰¯è¯­è¨€ä¸è¯­è¨€ä¿¡æ¯ï¼Œæ€§èƒ½ä¼˜è¶Šä¸”ç†è§£ä¸Šä¸‹æ–‡èƒ½åŠ›å¼ºã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="233-HierSearch-A-Hierarchical-Enterprise-Deep-Search-Framework-Integrating-Local-and-Web-Searches"><a href="#233-HierSearch-A-Hierarchical-Enterprise-Deep-Search-Framework-Integrating-Local-and-Web-Searches" class="headerlink" title="233. HierSearch: A Hierarchical Enterprise Deep Search Framework Integrating Local and Web Searches"></a>233. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/HierSearch__A_Hierarchical_Enterprise_Deep_Search_Framework_Integrating_Local_and_Web_Searches.pdf">HierSearch: A Hierarchical Enterprise Deep Search Framework Integrating Local and Web Searches</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Gaoling School of Artificial Intelligence, Renmin University of China</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†HierSearchï¼Œä¸€ç§å±‚æ¬¡åŒ–å¤šæ™ºèƒ½ä½“æ·±åº¦æœç´¢æ¡†æ¶ï¼Œé›†æˆäº†æœ¬åœ°ä¸WebçŸ¥è¯†æ£€ç´¢ï¼Œå¹¶é‡‡ç”¨å±‚æ¬¡åŒ–å¼ºåŒ–å­¦ä¹ ï¼ˆHRLï¼‰è®­ç»ƒæœ¬åœ°ä¸Webæ·±åº¦æœç´¢ä»£ç†ï¼Œå†ç”±é«˜å±‚è§„åˆ’ä»£ç†æ•´åˆè¯æ®å¹¶ç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€‚é€šè¿‡è®¾è®¡çŸ¥è¯†ç²¾ç‚¼æ¨¡å—ï¼Œè¿‡æ»¤ä½å±‚ä»£ç†è¿”å›çš„æ— å…³ä¸å¹»è§‰è¯æ®ï¼Œæ–¹æ³•åœ¨å…­å¤§é¢†åŸŸåŸºå‡†ä¸Šä¼˜äºå¹³å¦RLå’Œå¤šç§æ·±åº¦æœç´¢åŠå¤šæºRAGåŸºçº¿ï¼Œæå‡äº†å¤šæºæ£€ç´¢ä¸æ¨ç†èƒ½åŠ›ï¼Œæ³›åŒ–æ€§å¼ºã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="234-Robust-Anomaly-Detection-in-O-RAN-Leveraging-LLMs-against-Data-Manipulation-Attacks"><a href="#234-Robust-Anomaly-Detection-in-O-RAN-Leveraging-LLMs-against-Data-Manipulation-Attacks" class="headerlink" title="234. Robust Anomaly Detection in O-RAN: Leveraging LLMs against Data Manipulation Attacks"></a>234. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Robust_Anomaly_Detection_in_O-RAN__Leveraging_LLMs_against_Data_Manipulation_Attacks.pdf">Robust Anomaly Detection in O-RAN: Leveraging LLMs against Data Manipulation Attacks</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Monash University</span></p>
<p>æœ¬æ–‡æå‡ºåœ¨5G O-RANæ¶æ„ä¸‹ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œå¼‚å¸¸æ£€æµ‹ï¼Œå¯¹æŠ—é€šè¿‡Unicodeå­—ç¬¦ï¼ˆhypoglyphsï¼‰å®æ–½çš„æ•°æ®æ“çºµæ”»å‡»ã€‚æ–¹æ³•åŒ…æ‹¬å°†LLMé›†æˆè‡³O-RANçš„Near-RT RIC xAppï¼Œé‡‡ç”¨çª—å£åŒ–æ¶ˆæ¯å¤„ç†æµç¨‹ï¼Œå¯¹ä¼ ç»ŸMLæ¨¡å‹æ˜“å´©æºƒçš„æƒ…å†µè¿›è¡Œå¯¹æ¯”ï¼Œç»“æœæ˜¾ç¤ºLLMä¸ä»…èƒ½ç¨³å®šå¤„ç†è¢«ç¯¡æ”¹çš„æ¶ˆæ¯ä¸”æ£€æµ‹å»¶è¿Ÿä½äº0.07ç§’ï¼Œé€‚ç”¨äºå®æ—¶åœºæ™¯ï¼Œä½†æ£€æµ‹å‡†ç¡®ç‡ä»éœ€ä¼˜åŒ–ã€‚ç»“è®ºï¼šLLMå¯¹æ•°æ®æ“çºµæ”»å‡»å±•ç°å‡ºæ›´é«˜é²æ£’æ€§ï¼Œä¸ºO-RANå®‰å…¨éƒ¨ç½²æä¾›äº†å¯è¡Œæ–¹æ¡ˆã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="235-From-Natural-Language-to-Solver-Ready-Power-System-Optimization-An-LLM-Assisted-Validation-in-the-Loop-Framework"><a href="#235-From-Natural-Language-to-Solver-Ready-Power-System-Optimization-An-LLM-Assisted-Validation-in-the-Loop-Framework" class="headerlink" title="235. From Natural Language to Solver-Ready Power System Optimization: An LLM-Assisted, Validation-in-the-Loop Framework"></a>235. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/From_Natural_Language_to_Solver-Ready_Power_System_Optimization__An_LLM-Assisted,_Validation-in-the-.pdf">From Natural Language to Solver-Ready Power System Optimization: An LLM-Assisted, Validation-in-the-Loop Framework</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Southern California</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§ä»¥å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸ºæ ¸å¿ƒçš„æ™ºèƒ½ä»£ç†ç³»ç»Ÿï¼Œèƒ½å°†ç”µåŠ›ç³»ç»Ÿä¼˜åŒ–çš„è‡ªç„¶è¯­è¨€æè¿°è‡ªåŠ¨è½¬æ¢ä¸ºç´§å‡‘ã€æ±‚è§£å™¨å¯ç”¨çš„æ•°å­¦æ¨¡å‹ï¼Œå¹¶åœ¨å›è·¯ä¸­è¿›è¡ŒéªŒè¯å’Œä¿®å¤ã€‚æ–¹æ³•æµç¨‹åŒ…æ‹¬é¢†åŸŸæ„ŸçŸ¥çš„å‚æ•°æå–ã€ç»“æ„åŒ–æ¨¡æ¿ç”Ÿæˆã€è¿­ä»£æ ¡éªŒä¸ä¿®å¤ï¼Œä»¥åŠGNNè¾…åŠ©çš„åˆ†æ”¯ç­–ç•¥æå‡MILPæ±‚è§£æ•ˆç‡ã€‚å®éªŒæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å•å…ƒç»„åˆé—®é¢˜ä¸Šå®ç°äº†100%æœ‰æ•ˆå»ºæ¨¡ï¼Œæå‡äº†è¿è¡Œæ—¶æ•ˆç‡å¹¶ä¿è¯äº†è§£çš„å¯è¡Œæ€§ä¸æœ€ä¼˜æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="236-MuaLLM-A-Multimodal-Large-Language-Model-Agent-for-Circuit-Design-Assistance-with-Hybrid-Contextual-Retrieval-Augmented-Generation"><a href="#236-MuaLLM-A-Multimodal-Large-Language-Model-Agent-for-Circuit-Design-Assistance-with-Hybrid-Contextual-Retrieval-Augmented-Generation" class="headerlink" title="236. MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation"></a>236. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/MuaLLM__A_Multimodal_Large_Language_Model_Agent_for_Circuit_Design_Assistance_with_Hybrid_Contextual.pdf">MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Utah</span></p>
<p>æœ¬è®ºæ–‡æå‡ºäº†MuaLLMï¼Œä¸€ç§å¼€æºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†ï¼Œé›†æˆäº†åŸºäºReActï¼ˆReason + Actï¼‰è¿­ä»£æ¨ç†æµç¨‹å’Œæ··åˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ¡†æ¶ï¼Œä¸“ä¸ºç”µè·¯è®¾è®¡æ–‡çŒ®æ£€ç´¢ä¸å¤šæ­¥æ¨ç†ä»»åŠ¡è®¾è®¡ã€‚MuaLLMé€šè¿‡ç»“åˆç¨€ç–&#x2F;å¯†é›†æ£€ç´¢ã€å‘é‡æ•°æ®åº“ã€æ™ºèƒ½å·¥å…·é“¾ï¼ˆå¦‚è‡ªåŠ¨æ–‡çŒ®æŠ“å–ã€æ•°æ®åº“åŠ¨æ€æ›´æ–°ã€åŸç†å›¾åˆ°ç½‘è¡¨è½¬æ¢ï¼‰ä»¥åŠå¤šæ¨¡æ€èƒ½åŠ›ï¼ˆæ–‡æœ¬+å›¾åƒï¼‰ï¼Œå®ç°äº†é«˜æ•ˆã€å¯æ‰©å±•ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„ç”µè·¯è®¾è®¡é—®ç­”å’Œåˆ†æã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMuaLLMåœ¨è‡ªå»ºRAG-250å’ŒReas-100æ•°æ®é›†ä¸Šåˆ†åˆ«è¾¾åˆ°90.1%å¬å›ç‡å’Œ86.8%æ¨ç†å‡†ç¡®ç‡ï¼ŒåŒæ—¶åœ¨å¤§è¯­å¢ƒä¸‹æ¨ç†é€Ÿåº¦æå‡1.6å€ã€æˆæœ¬é™ä½10å€ï¼Œå…·å¤‡é«˜æ•ˆã€å¯æ‰©å±•çš„ç”µè·¯è®¾è®¡è¾…åŠ©èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="237-BlindGuard-Safeguarding-LLM-based-Multi-Agent-Systems-under-Unknown-Attacks"><a href="#237-BlindGuard-Safeguarding-LLM-based-Multi-Agent-Systems-under-Unknown-Attacks" class="headerlink" title="237. BlindGuard: Safeguarding LLM-based Multi-Agent Systems under Unknown Attacks"></a>237. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/BlindGuard__Safeguarding_LLM-based_Multi-Agent_Systems_under_Unknown_Attacks.pdf">BlindGuard: Safeguarding LLM-based Multi-Agent Systems under Unknown Attacks</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Jilin University</span></p>
<p>æœ¬æ–‡æå‡ºBlindGuardï¼Œä¸€ç§é’ˆå¯¹LLMé©±åŠ¨çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMASï¼‰åœ¨æœªçŸ¥æ”»å‡»ä¸‹çš„æ— ç›‘ç£é˜²å¾¡æ–¹æ³•ã€‚é€šè¿‡è®¾è®¡å±‚æ¬¡åŒ–ä»£ç†ç¼–ç å™¨èåˆä¸ªä½“ã€é‚»åŸŸå’Œå…¨å±€ä¿¡æ¯ï¼Œå¹¶å¼•å…¥è¯­ä¹‰è…åŒ–å¼•å¯¼çš„æ”»å‡»æ£€æµ‹å™¨ï¼ŒBlindGuardæ— éœ€æ”»å‡»æ ‡ç­¾å³å¯æ£€æµ‹å’Œéš”ç¦»æ¶æ„ä»£ç†ï¼Œæœ‰æ•ˆåº”å¯¹æç¤ºæ³¨å…¥ã€å†…å­˜æ±¡æŸ“å’Œå·¥å…·æ”»å‡»ç­‰å¤šç§åœºæ™¯ã€‚å®éªŒè¡¨æ˜ï¼ŒBlindGuardåœ¨å¤šç§MASæ‹“æ‰‘å’Œæ”»å‡»ç±»å‹ä¸‹å‡å…·æœ‰å¼ºæ³›åŒ–æ€§å’Œä¼˜è¶Šé˜²å¾¡æ€§èƒ½ï¼Œæ¨åŠ¨äº†LLMå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å®‰å…¨é˜²æŠ¤å‘å±•ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="238-TeamMedAgents-Enhancing-Medical-Decision-Making-of-LLMs-Through-Structured-Teamwork"><a href="#238-TeamMedAgents-Enhancing-Medical-Decision-Making-of-LLMs-Through-Structured-Teamwork" class="headerlink" title="238. TeamMedAgents: Enhancing Medical Decision-Making of LLMs Through Structured Teamwork"></a>238. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/TeamMedAgents__Enhancing_Medical_Decision-Making_of_LLMs_Through_Structured_Teamwork.pdf">TeamMedAgents: Enhancing Medical Decision-Making of LLMs Through Structured Teamwork</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Illinois, Chicago</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†TeamMedAgentsï¼Œä¸€ä¸ªå°†äººç±»ç»„ç»‡å¿ƒç†å­¦ä¸­çš„å›¢é˜Ÿåä½œç†è®ºç³»ç»ŸåŒ–å¼•å…¥å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„å¤šæ™ºèƒ½ä½“åŒ»å­¦å†³ç­–ç³»ç»Ÿã€‚æ–¹æ³•é€šè¿‡æ¨¡å—åŒ–å®ç°å›¢é˜Ÿé¢†å¯¼ã€äº’ç›¸ç›‘æ§ã€å›¢é˜Ÿå¯¼å‘ã€å…±äº«å¿ƒç†æ¨¡å‹ã€é—­ç¯æ²Ÿé€šå’Œäº’ä¿¡å…­å¤§å›¢é˜Ÿæœºåˆ¶ï¼Œå¹¶åœ¨å…«ä¸ªåŒ»å­¦åŸºå‡†ä¸Šé€šè¿‡ç³»ç»Ÿæ¶ˆèå®éªŒéªŒè¯å…¶æå‡æ•ˆæœã€‚ç»“è®ºæŒ‡å‡ºï¼Œé’ˆå¯¹ä»»åŠ¡ç±»å‹é€‰æ‹©ä¸åŒåä½œæœºåˆ¶æ¯”å…¨é¢é›†æˆæ›´ä¼˜ï¼Œå®éªŒè¯æ˜è¯¥æ–¹æ³•åœ¨ä¸ƒä¸ªåŒ»å­¦ä»»åŠ¡ä¸Šè¶…è¶Šç°æœ‰å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæœ€å¤§æé«˜è¾¾17.6%ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="239-Assessing-LLM-Text-Detection-in-Educational-Contexts-Does-Human-Contribution-Affect-Detection"><a href="#239-Assessing-LLM-Text-Detection-in-Educational-Contexts-Does-Human-Contribution-Affect-Detection" class="headerlink" title="239. Assessing LLM Text Detection in Educational Contexts: Does Human Contribution Affect Detection?"></a>239. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Assessing_LLM_Text_Detection_in_Educational_Contexts__Does_Human_Contribution_Affect_Detection_.pdf">Assessing LLM Text Detection in Educational Contexts: Does Human Contribution Affect Detection?</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Bielefeld University</span></p>
<p>æœ¬æ–‡æå‡ºäº†GEDEæ•°æ®é›†ï¼Œæ¶µç›–900ä½™ç¯‡å­¦ç”ŸåŸåˆ›ä¸12500ä½™ç¯‡ä¸åŒè´¡çŒ®åº¦ä¸‹çš„å¤§æ¨¡å‹ç”Ÿæˆä½œæ–‡ï¼Œç³»ç»Ÿè¯„æµ‹DetectGPTã€Fast-DetectGPTã€Ghostbusterã€RoBERTaç­‰æ£€æµ‹å™¨åœ¨æ•™è‚²åœºæ™¯å¯¹ä¸åŒäººç±»-LLMåä½œæ–‡æœ¬çš„è¯†åˆ«èƒ½åŠ›ã€‚ç ”ç©¶å‘ç°ï¼Œç°æœ‰æ£€æµ‹å™¨åœ¨åŒºåˆ†å®Œå…¨äººç±»æˆ–å®Œå…¨LLMç”Ÿæˆæ–‡æœ¬æ—¶è¡¨ç°è‰¯å¥½ï¼Œä½†å¯¹ä¸­é—´è´¡çŒ®å±‚æ¬¡è¡¨ç°ä¸ä½³ï¼Œå°¤å…¶å®¹æ˜“å‡ºç°é«˜å‡é˜³æ€§ï¼Œå½±å“æ•™è‚²å…¬å¹³æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="240-Investigating-the-Design-Space-of-Visual-Grounding-in-Multimodal-Large-Language-Model"><a href="#240-Investigating-the-Design-Space-of-Visual-Grounding-in-Multimodal-Large-Language-Model" class="headerlink" title="240. Investigating the Design Space of Visual Grounding in Multimodal Large Language Model"></a>240. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Investigating_the_Design_Space_of_Visual_Grounding_in_Multimodal_Large_Language_Model.pdf">Investigating the Design Space of Visual Grounding in Multimodal Large Language Model</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Illinois Chicago</span></p>
<p>æœ¬æ–‡ç³»ç»Ÿæ€§ç ”ç©¶äº†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰åœ¨è§†è§‰æŒ‡ä»£ï¼ˆVisual Grounding, VGï¼‰ä»»åŠ¡ä¸Šçš„è®¾è®¡ç©ºé—´ï¼Œå›´ç»•è§†è§‰å®šä½èŒƒå¼ä¸æ•°æ®è®¾è®¡è¿›è¡Œå…¨é¢çš„æ¶ˆèå®éªŒï¼Œæå‡ºæœ€ä¼˜æ–¹æ¡ˆä¸ºå½’ä¸€åŒ–æ•´æ•°æ ¼å¼ç»“åˆå·¦ä¸Šå³ä¸‹åæ ‡ä¸one-hotç›‘ç£ã€‚ç»“è®ºæ˜¾ç¤ºï¼Œé‡‡çº³è¿™äº›è®¾è®¡èƒ½ä½¿MLLMåœ¨RefCOCO&#x2F;+&#x2F;gç­‰åŸºå‡†ä¸Šè¾ƒLLaVA-1.5æ˜¾è‘—æå‡ï¼ˆ+5.6%&#x2F;+6.9%&#x2F;+7.0%ï¼‰ï¼Œä¸ºæœªæ¥MLLMåœ¨è§†è§‰æŒ‡ä»£ä»»åŠ¡çš„å‘å±•æä¾›äº†æ˜ç¡®æŒ‡å¯¼ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="241-AdaptFlow-Adaptive-Workflow-Optimization-via-Meta-Learning"><a href="#241-AdaptFlow-Adaptive-Workflow-Optimization-via-Meta-Learning" class="headerlink" title="241. AdaptFlow: Adaptive Workflow Optimization via Meta-Learning"></a>241. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/AdaptFlow__Adaptive_Workflow_Optimization_via_Meta-Learning.pdf">AdaptFlow: Adaptive Workflow Optimization via Meta-Learning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Peking University</span></p>
<p>æœ¬è®ºæ–‡æå‡ºäº†AdaptFlowï¼Œä¸€ç§åŸºäºæ¨¡å‹æ— å…³å…ƒå­¦ä¹ ï¼ˆMAMLï¼‰çš„è‡ªç„¶è¯­è¨€é©±åŠ¨å…ƒå­¦ä¹ æ¡†æ¶ï¼Œç”¨äºè‡ªé€‚åº”ä¼˜åŒ–LLMçš„agenticå·¥ä½œæµã€‚æ–¹æ³•åŒ…æ‹¬é€šè¿‡K-meansä»»åŠ¡èšç±»ã€åŒå±‚ä¼˜åŒ–ï¼ˆå†…å¾ªç¯ç”¨LLMæ–‡æœ¬åé¦ˆç»†åŒ–å·¥ä½œæµã€å¤–å¾ªç¯èšåˆå¹¶åæ€ï¼‰ã€ä»¥åŠæµ‹è¯•æ—¶åŸºäºè¯­ä¹‰æè¿°çš„å¿«é€Ÿé€‚åº”ã€‚å®éªŒè¡¨æ˜ï¼ŒAdaptFlowåœ¨é—®ç­”ã€ä»£ç ç”Ÿæˆå’Œæ•°å­¦æ¨ç†ç­‰å…«ä¸ªåŸºå‡†ä¸Šæ˜¾è‘—ä¼˜äºæ‰‹å·¥å’Œè‡ªåŠ¨å·¥ä½œæµä¼˜åŒ–åŸºçº¿ï¼Œå®ç°äº†è·¨ä»»åŠ¡å’Œæ¨¡å‹çš„å¼ºæ³›åŒ–èƒ½åŠ›ã€‚ç»“è®ºï¼šAdaptFlowå¯è‡ªåŠ¨æ„å»ºé€šç”¨ä¸”å¯è‡ªé€‚åº”çš„LLMå·¥ä½œæµï¼Œæå‡å¤æ‚ä»»åŠ¡è¡¨ç°ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="242-FEAT-A-Multi-Agent-Forensic-AI-System-with-Domain-Adapted-Large-Language-Model-for-Automated-Cause-of-Death-Analysis"><a href="#242-FEAT-A-Multi-Agent-Forensic-AI-System-with-Domain-Adapted-Large-Language-Model-for-Automated-Cause-of-Death-Analysis" class="headerlink" title="242. FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis"></a>242. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/FEAT__A_Multi-Agent_Forensic_AI_System_with_Domain-Adapted_Large_Language_Model_for_Automated_Cause-.pdf">FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Xiâ€™an Jiaotong University</span></p>
<p>æœ¬æ–‡æå‡ºFEATç³»ç»Ÿï¼Œä¸€ç§åŸºäºå¤šæ™ºèƒ½ä½“å’Œé¢†åŸŸè‡ªé€‚åº”å¤§è¯­è¨€æ¨¡å‹ï¼ˆForensic-LLMï¼‰çš„æ³•åŒ»è‡ªåŠ¨æ­»å› åˆ†æAIæ¡†æ¶ã€‚ç³»ç»Ÿé‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼ŒåŒ…æ‹¬ä»»åŠ¡åˆ†è§£çš„Plannerã€è¯æ®åˆ†æçš„Local Solversã€åæ€ä¸è®°å¿†æ¨¡å—ä»¥åŠç»“è®ºæ•´åˆçš„Global Solverï¼Œå¹¶é›†æˆå¤–éƒ¨å·¥å…·æ¨ç†ã€å±‚æ¬¡åŒ–RAGã€é¢†åŸŸå¾®è°ƒLLMåŠäººç±»åé¦ˆã€‚å®éªŒè¯æ˜FEATåœ¨ä¸­å›½å…­çœå¸‚å¤šæœºæ„7,748ä¾‹æ³•åŒ»æ¡ˆä»¶ä¸­ï¼Œæ˜¾è‘—ä¼˜äºåŒç±»AIç³»ç»Ÿï¼Œæå‡é•¿æ–‡åˆ†æå’ŒçŸ­ç»“è®ºçš„å‡†ç¡®æ€§ï¼Œå¹¶è·å¾—é«˜çº§æ³•åŒ»ä¸“å®¶çš„é«˜ä¸€è‡´æ€§è®¤å¯ã€‚ç»“è®ºï¼šFEATå®ç°äº†æ³•åŒ»æ­»å› åˆ†æé¢†åŸŸçš„ä¸“å®¶çº§å†³ç­–æ”¯æŒç³»ç»Ÿï¼Œå¯å¤§å¹…æå‡å¸æ³•æµç¨‹è‡ªåŠ¨åŒ–ä¸æ ‡å‡†åŒ–æ°´å¹³ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="243-Not-Yet-AlphaFold-for-the-Mind-Evaluating-Centaur-as-a-Synthetic-Participant"><a href="#243-Not-Yet-AlphaFold-for-the-Mind-Evaluating-Centaur-as-a-Synthetic-Participant" class="headerlink" title="243. Not Yet AlphaFold for the Mind: Evaluating Centaur as a Synthetic Participant"></a>243. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Not_Yet_AlphaFold_for_the_Mind__Evaluating_Centaur_as_a_Synthetic_Participant.pdf">Not Yet AlphaFold for the Mind: Evaluating Centaur as a Synthetic Participant</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">OsnabrÃ¼ck University</span></p>
<p>æœ¬æ–‡è¯„ä¼°äº†ç»è¿‡è®¤çŸ¥å®éªŒæ•°æ®å¾®è°ƒçš„å¤§è¯­è¨€æ¨¡å‹Centauråœ¨è®¤çŸ¥è¡Œä¸ºæ¨¡æ‹Ÿä¸­çš„èƒ½åŠ›ï¼Œé‡ç‚¹æ¯”è¾ƒå…¶é¢„æµ‹æ€§èƒ½å’Œç”Ÿæˆæ€§èƒ½ã€‚å®éªŒè¡¨æ˜ï¼Œå°½ç®¡Centauråœ¨å·²çŸ¥ä»»åŠ¡ä¸­é¢„æµ‹å‡†ç¡®æ€§é«˜ï¼Œä½†å…¶è‡ªä¸»ç”Ÿæˆè¡Œä¸ºä¸äººç±»è¡Œä¸ºå­˜åœ¨ç³»ç»Ÿæ€§åå·®ï¼Œå°šä¸å…·å¤‡ä½œä¸ºå¯é â€œåˆæˆå‚ä¸è€…â€æˆ–è®¤çŸ¥æ¨¡å‹çš„èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="244-CATP-Contextually-Adaptive-Token-Pruning-for-Efficient-and-Enhanced-Multimodal-In-Context-Learning"><a href="#244-CATP-Contextually-Adaptive-Token-Pruning-for-Efficient-and-Enhanced-Multimodal-In-Context-Learning" class="headerlink" title="244. CATP: Contextually Adaptive Token Pruning for Efficient and Enhanced Multimodal In-Context Learning"></a>244. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/CATP__Contextually_Adaptive_Token_Pruning_for_Efficient_and_Enhanced_Multimodal_In-Context_Learning.pdf">CATP: Contextually Adaptive Token Pruning for Efficient and Enhanced Multimodal In-Context Learning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Brown University</span></p>
<p>CATPæ˜¯ä¸€ç§é’ˆå¯¹å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆLVLMsï¼‰å¤šæ¨¡æ€in-context learningåœºæ™¯è®¾è®¡çš„æ— è®­ç»ƒå›¾åƒtokenå‰ªææ–¹æ³•ï¼Œé€šè¿‡ä¸¤é˜¶æ®µå‰ªæç­–ç•¥ï¼Œåˆ†åˆ«åœ¨æŠ•å½±å™¨å’Œè§£ç å™¨æ—©æœŸå±‚æ ¹æ®è¯­ä¹‰å¯¹é½å’Œç‰¹å¾å¤šæ ·æ€§ï¼Œä»¥åŠè·¨å±‚æ³¨æ„åŠ›åŠ¨æ€å’Œè¯­ä¹‰ç›¸å…³æ€§ç­›é€‰æœ€å…³é”®çš„å›¾åƒtokenã€‚å®éªŒè¯æ˜CATPåœ¨å››ç§ä¸»æµLVLMå’Œå…«ä¸ªåŸºå‡†ä¸Šæå‡æ•ˆç‡ï¼ˆæ¨ç†å»¶è¿Ÿå¹³å‡é™ä½10.78%ï¼‰åŒæ—¶ç•¥å¾®æå‡æ€§èƒ½ï¼ˆå¹³å‡æå‡0.6%ï¼‰ï¼Œä¼˜äºç°æœ‰æ‰€æœ‰å‰ªææ–¹æ³•ï¼Œæœ‰æ•ˆç¼“è§£å¤šæ¨¡æ€å†—ä½™å¹¶å¢å¼ºæ¨¡å‹æ³›åŒ–èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="245-Pareto-Multi-Objective-Alignment-for-Language-Models"><a href="#245-Pareto-Multi-Objective-Alignment-for-Language-Models" class="headerlink" title="245. Pareto Multi-Objective Alignment for Language Models"></a>245. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Pareto_Multi-Objective_Alignment_for_Language_Models.pdf">Pareto Multi-Objective Alignment for Language Models</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Ruhr University Bochum</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†PAreto Multi-Objective Alignment (PAMA)ç®—æ³•ï¼Œä¸“ä¸ºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šç›®æ ‡ï¼ˆå¯èƒ½ç›¸äº’å†²çªï¼‰å¯¹é½åœºæ™¯ä¸‹é«˜æ•ˆä¼˜åŒ–è€Œè®¾è®¡ã€‚PAMAå°†å¤šç›®æ ‡å¼ºåŒ–å­¦ä¹ äººç±»åé¦ˆï¼ˆRLHFï¼‰é—®é¢˜è½¬åŒ–ä¸ºå…·æœ‰é—­å¼è§£çš„å‡¸ä¼˜åŒ–é—®é¢˜ï¼Œå°†å¤æ‚åº¦ä»O(nÂ²d)é™è‡³O(n)ï¼Œå¹¶ç†è®ºè¯æ˜æ”¶æ•›åˆ°Paretoå¹³è¡¡ç‚¹ã€‚å®éªŒè¡¨æ˜ï¼ŒPAMAåœ¨GPT-2ã€LLaMA-2ç­‰æ¨¡å‹ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•ï¼Œå®ç°äº†é«˜æ•ˆã€ç¨³å®šçš„å¤šç›®æ ‡å¯¹é½ï¼Œæœ‰åŠ©äºæå‡LLMåœ¨å¤šæ ·åŒ–å®é™…éœ€æ±‚ä¸‹çš„çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="246-Interpreting-Fedspeak-with-Confidence-A-LLM-Based-Uncertainty-Aware-Framework-Guided-by-Monetary-Policy-Transmission-Paths"><a href="#246-Interpreting-Fedspeak-with-Confidence-A-LLM-Based-Uncertainty-Aware-Framework-Guided-by-Monetary-Policy-Transmission-Paths" class="headerlink" title="246. Interpreting Fedspeak with Confidence: A LLM-Based Uncertainty-Aware Framework Guided by Monetary Policy Transmission Paths"></a>246. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Interpreting_Fedspeak_with_Confidence__A_LLM-Based_Uncertainty-Aware_Framework_Guided_by_Monetary_Po.pdf">Interpreting Fedspeak with Confidence: A LLM-Based Uncertainty-Aware Framework Guided by Monetary Policy Transmission Paths</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">The Hong Kong University of Science and Technology (Guangzhou)</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»“åˆè´§å¸æ”¿ç­–ä¼ å¯¼æœºåˆ¶çš„é¢†åŸŸæ¨ç†ä¸åŠ¨æ€ä¸ç¡®å®šæ€§è§£ç æ¨¡å—çš„LLMæ¡†æ¶ï¼Œç”¨äºè§£æç¾è”å‚¨â€œFedspeakâ€å¹¶åˆ†ç±»å…¶è´§å¸æ”¿ç­–ç«‹åœºã€‚æ–¹æ³•é€šè¿‡é‡‘èå®ä½“å…³ç³»æŠ½å–ã€æ”¿ç­–ä¼ å¯¼è·¯å¾„æ¨ç†å’Œæ„ŸçŸ¥ä¸ç¡®å®šæ€§é‡åŒ–æå‡æ¨¡å‹å¯è§£é‡Šæ€§ä¸é¢„æµ‹å¯é æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨FOMCæ”¿ç­–ç«‹åœºåˆ†æä»»åŠ¡ä¸Šè¾¾åˆ°å½“å‰æœ€ä¼˜è¡¨ç°ï¼Œå¹¶èƒ½æœ‰æ•ˆè¯†åˆ«é«˜ä¸ç¡®å®šæ€§é¢„æµ‹ï¼Œå¢å¼ºå®é™…é‡‘èå†³ç­–ä¸­çš„æ¨¡å‹å¯é æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="247-The-Escalator-Problem-Identifying-Implicit-Motion-Blindness-in-AI-for-Accessibility"><a href="#247-The-Escalator-Problem-Identifying-Implicit-Motion-Blindness-in-AI-for-Accessibility" class="headerlink" title="247. The Escalator Problem: Identifying Implicit Motion Blindness in AI for Accessibility"></a>247. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/The_Escalator_Problem__Identifying_Implicit_Motion_Blindness_in_AI_for_Accessibility.pdf">The Escalator Problem: Identifying Implicit Motion Blindness in AI for Accessibility</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Beihang University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†â€œç”µæ¢¯é—®é¢˜â€ï¼Œæ­ç¤ºäº†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨è¾…åŠ©è§†è§‰éšœç¢è€…æ—¶æ— æ³•æ„ŸçŸ¥è¿ç»­ã€ä½ä¿¡å·è¿åŠ¨ï¼ˆå¦‚åˆ¤æ–­è‡ªåŠ¨æ‰¶æ¢¯æ–¹å‘ï¼‰çš„å…³é”®ç¼ºé™·ï¼Œå³â€œéšæ€§è¿åŠ¨ç›²ç‚¹â€ã€‚ä½œè€…åˆ†æäº†è¿™ä¸€é—®é¢˜å¯¹ç”¨æˆ·ä¿¡ä»»å’Œå®‰å…¨çš„å½±å“ï¼Œå¹¶å‘¼åä»é™æ€è¯­ä¹‰è¯†åˆ«è½¬å‘æ›´å¼ºçš„ç‰©ç†æ„ŸçŸ¥ï¼Œå»ºè®®å¼€å‘ä»¥ç”¨æˆ·å®‰å…¨å’Œå¯é æ€§ä¸ºæ ¸å¿ƒçš„æ–°è¯„æµ‹æ–¹æ³•ã€‚ç»“è®ºè®¤ä¸ºï¼Œç°æœ‰MLLMsåœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„è¾…åŠ©èƒ½åŠ›å­˜åœ¨æ ¹æœ¬æ€§ä¸è¶³ï¼ŒäºŸéœ€èŒƒå¼è½¬å˜ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="248-WeChat-YATT-A-Simple-Scalable-and-Balanced-RLHF-Trainer"><a href="#248-WeChat-YATT-A-Simple-Scalable-and-Balanced-RLHF-Trainer" class="headerlink" title="248. WeChat-YATT: A Simple, Scalable and Balanced RLHF Trainer"></a>248. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/WeChat-YATT__A_Simple,_Scalable_and_Balanced_RLHF_Trainer.pdf">WeChat-YATT: A Simple, Scalable and Balanced RLHF Trainer</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Tencent</span></p>
<p>è¯¥è®ºæ–‡æå‡ºWeChat-YATTï¼Œä¸€ç§ç®€æ´ä¸”å¯æ‰©å±•çš„RLHFè®­ç»ƒæ¡†æ¶ï¼Œé€šè¿‡å¹¶è¡Œæ§åˆ¶å™¨ç¼–ç¨‹æ¨¡å‹å’ŒåŠ¨æ€èµ„æºåˆ†é…ç­–ç•¥ï¼Œå®ç°é«˜æ•ˆçš„äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ æµç¨‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒWeChat-YATTæ˜¾è‘—æå‡äº†ç¡¬ä»¶åˆ©ç”¨ç‡å’Œè®­ç»ƒååé‡ï¼Œå·²æˆåŠŸå¤§è§„æ¨¡åº”ç”¨äºå¾®ä¿¡äº§å“æ¨¡å‹è®­ç»ƒã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="249-X-evolve-Solution-space-evolution-powered-by-large-language-models"><a href="#249-X-evolve-Solution-space-evolution-powered-by-large-language-models" class="headerlink" title="249. X-evolve: Solution space evolution powered by large language models"></a>249. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/_(X_)-evolve__Solution_space_evolution_powered_by_large_language_models.pdf">X-evolve: Solution space evolution powered by large language models</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Science and Technology of China</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åˆ›æ–°çš„LLM+EAæ··åˆä¼˜åŒ–æ–¹æ³•X-evolveï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆå¯è°ƒå‚æ•°çš„ç¨‹åºï¼Œé€šè¿‡æ ‡æ³¨tunableå‚æ•°å®šä¹‰è§£ç©ºé—´ï¼Œå¹¶ç»“åˆåŸºäºå¾—åˆ†çš„æœç´¢ç®—æ³•ï¼ˆX-searchï¼‰é«˜æ•ˆæ¢ç´¢è¯¥ç©ºé—´ã€‚æ–¹æ³•æ˜¾è‘—é™ä½äº†LLMè°ƒç”¨æˆæœ¬ï¼ˆå‡å°‘ä¸¤æ•°é‡çº§ï¼‰ï¼Œåœ¨cap seté—®é¢˜ã€Shannonå®¹é‡é—®é¢˜å’ŒNPéš¾åœ¨çº¿è£…ç®±ç­‰å¤šä¸ªéš¾é¢˜ä¸­æ˜¾è‘—æå‡äº†æœç´¢æ•ˆç‡å’Œç»“æœè´¨é‡ï¼Œéƒ¨åˆ†ç»“æœåˆ·æ–°äº†ä¸–ç•Œè®°å½•ã€‚ç»“è®ºæ˜¯X-evolveèƒ½å¤Ÿæ›´é«˜æ•ˆåœ°è§£å†³é«˜ç»´ä¼˜åŒ–é—®é¢˜ï¼Œæå¤§æ‹“å±•äº†LLMåœ¨ç§‘å­¦å‘ç°ä¸­çš„åº”ç”¨è¾¹ç•Œã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="250-MIMIC-Multimodal-Inversion-for-Model-Interpretation-and-Conceptualization"><a href="#250-MIMIC-Multimodal-Inversion-for-Model-Interpretation-and-Conceptualization" class="headerlink" title="250. MIMIC: Multimodal Inversion for Model Interpretation and Conceptualization"></a>250. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/MIMIC__Multimodal_Inversion_for_Model_Interpretation_and_Conceptualization.pdf">MIMIC: Multimodal Inversion for Model Interpretation and Conceptualization</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Twente</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºMIMICçš„å¤šæ¨¡æ€åæ¼”æ¡†æ¶ï¼Œèƒ½é€šè¿‡è”åˆè§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰åæ¼”ä¸ç‰¹å¾å¯¹é½ç›®æ ‡ï¼Œåœ¨ä¸ä¿®æ”¹æ¨¡å‹æƒé‡çš„å‰æä¸‹ï¼Œå°†VLMå†…éƒ¨ç¼–ç çš„è¯­ä¹‰æ¦‚å¿µå¯è§†åŒ–ä¸ºå›¾åƒã€‚æ–¹æ³•ç»“åˆäº†è‡ªé€‚åº”äº¤å‰ç†µæŸå¤±ã€åŸºäºViTæ¿€æ´»çš„ç‰¹å¾æŸå¤±ã€ç©ºé—´åŠå…ˆéªŒæ­£åˆ™åŒ–å™¨ï¼Œå®ç°äº†é«˜è¯­ä¹‰ä¸€è‡´æ€§å’Œç»“æ„è¿è´¯çš„æ¦‚å¿µå›¾åƒç”Ÿæˆï¼Œæå‡äº†VLMæ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMIMICèƒ½å¤Ÿä»ä¸åŒé•¿åº¦æ–‡æœ¬è¾“å‡ºä¸­åæ¼”VLMçš„è§†è§‰æ¦‚å¿µï¼Œç”Ÿæˆé«˜ä¿çœŸã€è¯­ä¹‰å¯¹é½çš„å›¾åƒï¼Œå±•ç¤ºäº†å¯¹VLMå†…éƒ¨è¡¨å¾ç©ºé—´çš„æœ‰æ•ˆè§£é‡Šèƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="251-EvoCoT-Overcoming-the-Exploration-Bottleneck-in-Reinforcement-Learning"><a href="#251-EvoCoT-Overcoming-the-Exploration-Bottleneck-in-Reinforcement-Learning" class="headerlink" title="251. EvoCoT: Overcoming the Exploration Bottleneck in Reinforcement Learning"></a>251. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/EvoCoT__Overcoming_the_Exploration_Bottleneck_in_Reinforcement_Learning.pdf">EvoCoT: Overcoming the Exploration Bottleneck in Reinforcement Learning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Peking University</span></p>
<p>æœ¬æ–‡æå‡ºEvoCoTï¼Œä¸€ç§é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è‡ªè¿›åŒ–çš„è¯¾ç¨‹å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡ä¸¤é˜¶æ®µé“¾å¼æ€ç»´ï¼ˆCoTï¼‰ä¼˜åŒ–å®ç°è‡ªç”Ÿæˆå¹¶éªŒè¯æ¨ç†è·¯å¾„ï¼Œéšåé€æ­¥ç¼©çŸ­æ¨ç†æ­¥éª¤ä»¥å—æ§æ‰©å±•æ¢ç´¢ç©ºé—´ã€‚å®éªŒè¡¨æ˜ï¼ŒEvoCoTèƒ½å¸®åŠ©å¤šç§LLMåœ¨ç¨€ç–å¥–åŠ±ä¸‹è§£å†³æ­¤å‰æœªèƒ½è§£å†³çš„éš¾é¢˜ï¼Œæå‡æ•°å­¦æ¨ç†èƒ½åŠ›ï¼Œå¹¶ä¸”ä¼˜äºä¼ ç»ŸRLVRåŠæœ‰ç›‘ç£å¾®è°ƒç­‰æ–¹æ³•ï¼Œçªç ´æ¢ç´¢ç“¶é¢ˆã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="252-UniSVG-A-Unified-Dataset-for-Vector-Graphic-Understanding-and-Generation-with-Multimodal-Large-Language-Models"><a href="#252-UniSVG-A-Unified-Dataset-for-Vector-Graphic-Understanding-and-Generation-with-Multimodal-Large-Language-Models" class="headerlink" title="252. UniSVG: A Unified Dataset for Vector Graphic Understanding and Generation with Multimodal Large Language Models"></a>252. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/UniSVG__A_Unified_Dataset_for_Vector_Graphic_Understanding_and_Generation_with_Multimodal_Large_Lang.pdf">UniSVG: A Unified Dataset for Vector Graphic Understanding and Generation with Multimodal Large Language Models</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Zhejiang University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†UniSVGï¼Œè¿™æ˜¯é¦–ä¸ªé¢å‘å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰è®­ç»ƒä¸è¯„æµ‹çš„ç»Ÿä¸€SVGæ•°æ®é›†ï¼ŒåŒ…å«52.8ä¸‡æ¡æ•°æ®ï¼Œæ¶µç›–å›¾åƒåˆ°SVGã€æ–‡æœ¬åˆ°SVGåŠSVGç†è§£ç­‰å¤šç§ä»»åŠ¡ã€‚å®éªŒè¡¨æ˜ï¼Œåˆ©ç”¨UniSVGå¾®è°ƒçš„å¼€æºMLLMåœ¨SVGç”Ÿæˆä¸ç†è§£ä»»åŠ¡ä¸Šè¶…è¿‡äº†åŒ…æ‹¬GPT-4Våœ¨å†…çš„ä¸»æµå°é—­æ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„SVGå¤„ç†èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="253-LoSemB-Logic-Guided-Semantic-Bridging-for-Inductive-Tool-Retrieval"><a href="#253-LoSemB-Logic-Guided-Semantic-Bridging-for-Inductive-Tool-Retrieval" class="headerlink" title="253. LoSemB: Logic-Guided Semantic Bridging for Inductive Tool Retrieval"></a>253. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/LoSemB__Logic-Guided_Semantic_Bridging_for_Inductive_Tool_Retrieval.pdf">LoSemB: Logic-Guided Semantic Bridging for Inductive Tool Retrieval</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">The Hong Kong Polytechnic University</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§é¢å‘å¤§è¯­è¨€æ¨¡å‹å·¥å…·æ£€ç´¢ä»»åŠ¡çš„é€»è¾‘ä¿¡æ¯å¼•å¯¼è¯­ä¹‰æ¡¥æ¥æ¡†æ¶LoSemBã€‚è¯¥æ–¹æ³•åŒ…å«é€»è¾‘ç‰¹å¾æå–ä¸è¿ç§»çš„åµŒå…¥å¯¹é½æ¨¡å—ï¼Œæœ‰æ•ˆç¼“è§£æœªè§å·¥å…·çš„åˆ†å¸ƒåç§»ï¼Œå¹¶é€šè¿‡å…³ç³»å¢å¼ºæ£€ç´¢æœºåˆ¶ç»“åˆé€»è¾‘çº¦æŸä¸å›¾åµŒå…¥ç›¸ä¼¼æ€§ï¼Œæé«˜å¯¹æœªè§å·¥å…·çš„æ£€ç´¢å‡†ç¡®ç‡ã€‚å¤§é‡å®éªŒç»“æœè¡¨æ˜ï¼ŒLoSemBåœ¨å½’çº³ï¼ˆinductiveï¼‰ä¸ä¼ å¯¼ï¼ˆtransductiveï¼‰ä¸¤ç§è®¾ç½®ä¸‹å‡æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸”æ— éœ€å¯¹æ–°å·¥å…·é‡æ–°è®­ç»ƒï¼Œå…·å¤‡å¼ºæ³›åŒ–å’Œå®ç”¨æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="254-Semantic-Caching-for-Low-Cost-LLM-Serving-From-Offline-Learning-to-Online-Adaptation"><a href="#254-Semantic-Caching-for-Low-Cost-LLM-Serving-From-Offline-Learning-to-Online-Adaptation" class="headerlink" title="254. Semantic Caching for Low-Cost LLM Serving: From Offline Learning to Online Adaptation"></a>254. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Semantic_Caching_for_Low-Cost_LLM_Serving__From_Offline_Learning_to_Online_Adaptation.pdf">Semantic Caching for Low-Cost LLM Serving: From Offline Learning to Online Adaptation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Carnegie Mellon University</span></p>
<p>æœ¬è®ºæ–‡æå‡ºä¸€ç§é¢å‘å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†ä½æˆæœ¬æœåŠ¡çš„è¯­ä¹‰ç¼“å­˜æ¡†æ¶ï¼Œä»ç¦»çº¿å­¦ä¹ åˆ°åœ¨çº¿è‡ªé€‚åº”ï¼Œç³»ç»Ÿæ€§åœ°å»ºæ¨¡äº†ä¸ç¡®å®šç¯å¢ƒä¸‹çš„ç¼“å­˜æ·˜æ±°é—®é¢˜ã€‚æ–¹æ³•åŒ…æ‹¬è®¾è®¡è¶…æ¨¡é€†å‘è´ªå¿ƒã€CUCB-SCå’ŒCLCB-SC-LSç­‰ç®—æ³•ï¼Œåˆ†åˆ«é’ˆå¯¹å·²çŸ¥å‚æ•°ã€ç¦»çº¿æ•°æ®å­¦ä¹ å’Œåœ¨çº¿è‡ªé€‚åº”åœºæ™¯ï¼Œç†è®ºä¸Šç»™å‡ºè¿‘æœ€ä¼˜é€¼è¿‘ã€æœ‰é™æ ·æœ¬æ¬¡ä¼˜ç•Œå’Œæ¬¡çº¿æ€§é—æ†¾ä¸Šç•Œã€‚å®éªŒè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨å„ç§ç¼“å­˜å¤§å°å’ŒæŸ¥è¯¢åˆ†å¸ƒä¸‹æ˜¾è‘—ä¼˜äºåŸºçº¿ï¼Œç¼“å­˜åˆ‡æ¢æ•°å’Œè¿è¡Œæ—¶å‡å¤§å¹…é™ä½ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="255-GLiClass-Generalist-Lightweight-Model-for-Sequence-Classification-Tasks"><a href="#255-GLiClass-Generalist-Lightweight-Model-for-Sequence-Classification-Tasks" class="headerlink" title="255. GLiClass: Generalist Lightweight Model for Sequence Classification Tasks"></a>255. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/GLiClass__Generalist_Lightweight_Model_for_Sequence_Classification_Tasks.pdf">GLiClass: Generalist Lightweight Model for Sequence Classification Tasks</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Knowledgator Engineering</span></p>
<p>GLiClass adapts the GLiNER architecture into a uni-encoder transformer model for efficient multi-label sequence classification, enabling joint text-label encoding and rich inter-label interactions. It achieves state-of-the-art accuracy and throughput on standard benchmarks, scales favorably with label count, excels in zero-shot and few-shot settings, and introduces PPO-based reinforcement learning for data-sparse scenarios; GLiClass surpasses cross-encoder baselines in accuracy-latency trade-off while maintaining practical deployment flexibility.</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="256-Multi-Turn-Jailbreaks-Are-Simpler-Than-They-Seem"><a href="#256-Multi-Turn-Jailbreaks-Are-Simpler-Than-They-Seem" class="headerlink" title="256. Multi-Turn Jailbreaks Are Simpler Than They Seem"></a>256. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Multi-Turn_Jailbreaks_Are_Simpler_Than_They_Seem.pdf">Multi-Turn Jailbreaks Are Simpler Than They Seem</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Imperial College London</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§è‡ªåŠ¨åŒ–å¤šè½®è¶Šç‹±æ”»å‡»æµæ°´çº¿ï¼Œå¹¶åœ¨GPT-4ã€Claudeã€Geminiç­‰ä¸»æµå¤§æ¨¡å‹ä¸Šç³»ç»Ÿè¯„æµ‹ï¼Œå‘ç°æ‰€è°“å¤šè½®è¶Šç‹±çš„æˆåŠŸæœ¬è´¨ä¸Šç­‰ä»·äºå¤šæ¬¡å•è½®æ”»å‡»é‡‡æ ·ï¼Œå¹¶æ— é¢å¤–å¤æ‚æ€§ä¼˜åŠ¿ã€‚ç»“è®ºæŒ‡å‡ºï¼Œç°æœ‰å®‰å…¨è¯„ä¼°ä½ä¼°äº†æ”»å‡»æˆåŠŸç‡ï¼Œå¤šè½®ç­–ç•¥ä»…ç›¸å½“äºæ›´å¤šå°è¯•ï¼Œä¸”åŒä¸€å‚å•†æ¨¡å‹è„†å¼±æ€§é«˜åº¦ç›¸å…³ï¼Œéœ€å…³æ³¨æ ¹æœ¬é²æ£’æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="257-Beyond-Single-A-Data-Selection-Principle-for-LLM-Alignment-via-Fine-Grained-Preference-Signals"><a href="#257-Beyond-Single-A-Data-Selection-Principle-for-LLM-Alignment-via-Fine-Grained-Preference-Signals" class="headerlink" title="257. Beyond Single: A Data Selection Principle for LLM Alignment via Fine-Grained Preference Signals"></a>257. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Beyond_Single__A_Data_Selection_Principle_for_LLM_Alignment_via_Fine-Grained_Preference_Signals.pdf">Beyond Single: A Data Selection Principle for LLM Alignment via Fine-Grained Preference Signals</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Nanjing University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºç»†ç²’åº¦åå¥½ä¿¡å·çš„æ•°æ®é€‰æ‹©æ–¹æ³•ç”¨äºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯¹é½ã€‚æ ¸å¿ƒæ–¹æ³•åŒ…æ‹¬æ¨å¯¼å¤šåå¥½ç›´æ¥ä¼˜åŒ–ï¼ˆDMPOï¼‰ç›®æ ‡ï¼Œæå‡ºåå¥½åˆ†æ­§ï¼ˆPDï¼‰é¡¹ï¼Œåˆ©ç”¨PDå€¼é€‰æ‹©é«˜ä¸€è‡´æ€§å­é›†ç”¨äºæ ‡å‡†åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰è®­ç»ƒï¼Œå¹¶é€šè¿‡å¥–åŠ±æ¨¡å‹ä¼°ç®—å’Œé•¿åº¦åç½®ä¿®æ­£å®ç°é«˜æ•ˆç­›é€‰ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨UltraFeedbackæ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ•´ä½“åå¥½å’Œoracleæ–¹æ³•ï¼Œæå‡è®­ç»ƒæ•ˆç‡ä¸”æ— éœ€å¤æ‚æ ‡æ³¨ï¼Œå®ç°æ›´é²æ£’çš„LLMå¯¹é½ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="258-Klear-Reasoner-Advancing-Reasoning-Capability-via-Gradient-Preserving-Clipping-Policy-Optimization"><a href="#258-Klear-Reasoner-Advancing-Reasoning-Capability-via-Gradient-Preserving-Clipping-Policy-Optimization" class="headerlink" title="258. Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization"></a>258. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Klear-Reasoner__Advancing_Reasoning_Capability_via_Gradient-Preserving_Clipping_Policy_Optimization.pdf">Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Kuaishou Technology</span></p>
<p>æœ¬è®ºæ–‡æå‡ºKlear-Reasonerï¼Œé€šè¿‡é«˜è´¨é‡é“¾å¼æ€ç»´ç›‘ç£å¾®è°ƒï¼ˆlong CoT SFTï¼‰å’Œæ¢¯åº¦ä¿ç•™å‰ªåˆ‡ç­–ç•¥ä¼˜åŒ–ï¼ˆGPPOï¼‰æå‡æ•°å­¦ä¸ä»£ç æ¨ç†èƒ½åŠ›ã€‚GPPOåœ¨å¼ºåŒ–å­¦ä¹ é˜¶æ®µä¿ç•™æ‰€æœ‰tokençš„æ¢¯åº¦ä¿¡æ¯ï¼Œç»“åˆæ•°æ®è¿‡æ»¤ã€è½¯å¥–åŠ±å’ŒSFTç›‘ç£ï¼Œæœ‰æ•ˆæå‡æ¨¡å‹æ¢ç´¢æ€§ä¸æ”¶æ•›é€Ÿåº¦ï¼Œæœ€ç»ˆåœ¨AIMEå’ŒLiveCodeBenchç­‰å¤šä¸ªåŸºå‡†ä¸Šè¶…è¶ŠåŒè§„æ¨¡SOTAæ¨¡å‹ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="259-Learning-to-Align-Aligning-to-Learn-A-Unified-Approach-for-Self-Optimized-Alignment"><a href="#259-Learning-to-Align-Aligning-to-Learn-A-Unified-Approach-for-Self-Optimized-Alignment" class="headerlink" title="259. Learning to Align, Aligning to Learn: A Unified Approach for Self-Optimized Alignment"></a>259. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Learning_to_Align,_Aligning_to_Learn__A_Unified_Approach_for_Self-Optimized_Alignment.pdf">Learning to Align, Aligning to Learn: A Unified Approach for Self-Optimized Alignment</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">AntGroup</span></p>
<p>æœ¬æ–‡æå‡ºäº†GRAOï¼ˆGroup Relative Alignment Optimizationï¼‰æ¡†æ¶ï¼Œé€šè¿‡å¤šæ ·æœ¬ç”Ÿæˆã€ç»„å†…ç›¸å¯¹ä¼˜åŠ¿åŠ æƒå’Œå‚è€ƒæ„ŸçŸ¥å‚æ•°æ›´æ–°ï¼Œå°†SFTä¸RLçš„ä¼˜ç‚¹ç»“åˆï¼Œå®ç°é«˜æ•ˆè‡ªé€‚åº”å¯¹é½ã€‚å®éªŒè¯æ˜GRAOåœ¨å¤æ‚äººç±»å¯¹é½ä»»åŠ¡ä¸Šç›¸è¾ƒSFTã€DPOã€PPOå’ŒGRPOåˆ†åˆ«æå‡57.7%ã€17.65%ã€7.95%å’Œ5.18%ï¼Œå¹¶æ˜¾è‘—åŠ é€Ÿæ”¶æ•›ï¼Œé€‚ç”¨äºå¤šç§å¤§å‹è¯­è¨€æ¨¡å‹æ¶æ„ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="260-CHIMERA-HARNESSING-MULTI-AGENT-LLMS-FOR-AUTOMATIC-INSIDER-THREAT-SIMULATION"><a href="#260-CHIMERA-HARNESSING-MULTI-AGENT-LLMS-FOR-AUTOMATIC-INSIDER-THREAT-SIMULATION" class="headerlink" title="260. CHIMERA: HARNESSING MULTI-AGENT LLMS FOR AUTOMATIC INSIDER THREAT SIMULATION"></a>260. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Chimera__Harnessing_Multi-Agent_LLMs_for_Automatic_Insider_Threat_Simulation.pdf">CHIMERA: HARNESSING MULTI-AGENT LLMS FOR AUTOMATIC INSIDER THREAT SIMULATION</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Singapore Management University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†Chimeraï¼Œä¸€ä¸ªåŸºäºå¤šæ™ºèƒ½ä½“å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è‡ªåŠ¨åŒ–æ¡†æ¶ï¼Œç”¨äºæ¨¡æ‹Ÿä¼ä¸šå†…éƒ¨å‘˜å·¥çš„æ­£å¸¸ä¸æ¶æ„è¡Œä¸ºï¼Œå¹¶è‡ªåŠ¨ç”Ÿæˆæ—¥å¿—ï¼Œè§£å†³é«˜è´¨é‡å†…éƒ¨å¨èƒæ£€æµ‹ï¼ˆITDï¼‰æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ã€‚Chimeraé€šè¿‡è‡ªå®šä¹‰å‘˜å·¥è§’è‰²å’Œå¤šé˜¶æ®µä»»åŠ¡æµç¨‹ï¼Œæ¨¡æ‹ŸçœŸå®ä¼ä¸šè¿ä½œï¼Œç”Ÿæˆè¦†ç›–15ç§æ”»å‡»åœºæ™¯ã€6ç±»æ—¥å¿—æ¨¡æ€çš„ChimeraLogæ•°æ®é›†ï¼Œå¹¶ç»ä¸“å®¶è¯„ä¼°éªŒè¯å…¶çœŸå®æ€§å’Œå¤šæ ·æ€§ã€‚å®éªŒæ˜¾ç¤ºChimeraLogæ•°æ®æ›´å…·æŒ‘æˆ˜æ€§ï¼Œèƒ½ä¿ƒè¿›ITDæ¨¡å‹æ³›åŒ–èƒ½åŠ›æå‡ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="261-Semantic-Enhanced-Time-Series-Forecasting-via-Large-Language-Models"><a href="#261-Semantic-Enhanced-Time-Series-Forecasting-via-Large-Language-Models" class="headerlink" title="261. Semantic-Enhanced Time-Series Forecasting via Large Language Models"></a>261. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Semantic-Enhanced_Time-Series_Forecasting_via_Large_Language_Models.pdf">Semantic-Enhanced Time-Series Forecasting via Large Language Models</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Science and Technology Beijing</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†SE-LLMæ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥Temporal-Semantic Cross-Correlation (TSCC)æ¨¡å—å’ŒTime-Adapteræ’ä»¶ï¼Œæœ‰æ•ˆèåˆæ—¶åºæ•°æ®ä¸LLMçš„è¯­ä¹‰ç©ºé—´ï¼Œæå‡äº†LLMå¯¹æ—¶é—´åºåˆ—çš„ç†è§£å’Œé¢„æµ‹èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSE-LLMåœ¨å¤šé¡¹å…¬å¼€æ•°æ®é›†ä¸Šçš„é¢„æµ‹æ€§èƒ½å‡è¶…è¶Šç°æœ‰SOTAæ–¹æ³•ï¼Œä¸”å…·å¤‡æ›´é«˜çš„æ³›åŒ–èƒ½åŠ›å’Œè®¡ç®—æ•ˆç‡ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="262-1-2-3-Check-Enhancing-Contextual-Privacy-in-LLM-via-Multi-Agent-Reasoning"><a href="#262-1-2-3-Check-Enhancing-Contextual-Privacy-in-LLM-via-Multi-Agent-Reasoning" class="headerlink" title="262. 1-2-3 Check: Enhancing Contextual Privacy in LLM via Multi-Agent Reasoning"></a>262. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/1-2-3_Check__Enhancing_Contextual_Privacy_in_LLM_via_Multi-Agent_Reasoning.pdf">1-2-3 Check: Enhancing Contextual Privacy in LLM via Multi-Agent Reasoning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Carnegie Mellon University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œå°†LLMçš„éšç§æ¨ç†ä»»åŠ¡åˆ†è§£ä¸ºäº‹ä»¶æŠ½å–ã€åˆ†ç±»ã€æ€»ç»“ä¸‰ä¸ªå­ä»»åŠ¡ï¼Œå„Agentä¸“æ³¨äºç‰¹å®šå­ç¯èŠ‚ï¼Œé€šè¿‡æ§åˆ¶ä¿¡æ¯æµå’Œå¼•å…¥æ ¡éªŒç¯èŠ‚ï¼Œæœ‰æ•ˆå‡è½»å•Agentè¿‡è½½é—®é¢˜ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥å¤šAgentä½“ç³»åœ¨ConfAIdeå’ŒPrivacyLensåŸºå‡†ä¸Šæ˜¾è‘—é™ä½äº†éšç§æ³„éœ²ï¼ˆåˆ†åˆ«å‡å°‘18%å’Œ19%ï¼‰ï¼Œä¸”ä¿è¯äº†å…¬å…±å†…å®¹çš„å®Œæ•´æ€§ï¼Œä¼˜äºå•Agentæ–¹æ¡ˆï¼Œå‡¸æ˜¾äº†æ¨¡å—åŒ–ä¿¡æ¯æµè®¾è®¡åœ¨å¤æ‚éšç§åœºæ™¯ä¸‹çš„ä¼˜åŠ¿ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h2 id="ml">Machine Learning</h2>


<h3 id="263-Designing-a-Feedback-Driven-Decision-Support-System-for-Dynamic-Student-Intervention"><a href="#263-Designing-a-Feedback-Driven-Decision-Support-System-for-Dynamic-Student-Intervention" class="headerlink" title="263. Designing a Feedback-Driven Decision Support System for Dynamic Student Intervention"></a>263. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Designing_a_Feedback-Driven_Decision_Support_System_for_Dynamic_Student_Intervention.pdf">Designing a Feedback-Driven Decision Support System for Dynamic Student Intervention</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">WeAreGenius Research Institute</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åé¦ˆé©±åŠ¨çš„å†³ç­–æ”¯æŒç³»ç»Ÿï¼Œç”¨äºåŠ¨æ€å­¦ç”Ÿå¹²é¢„ï¼Œæ ¸å¿ƒæ–¹æ³•æ˜¯åˆ©ç”¨é—­ç¯æ¶æ„å’ŒLightGBMå›å½’æ¨¡å‹ï¼Œé€šè¿‡å¢é‡å¼åœ¨çº¿å­¦ä¹ ä¸æ–­å¸æ”¶å­¦ç”Ÿå¹²é¢„åçš„æ–°æ•°æ®ï¼Œå®ç°æ¨¡å‹çš„è‡ªæˆ‘è¿­ä»£å’Œä¼˜åŒ–ã€‚å®éªŒè¡¨æ˜ï¼Œç³»ç»Ÿå¯è‡ªåŠ¨æ•´åˆæ•™å¸ˆè¾“å…¥çš„æ–°æˆç»©ï¼Œæ˜¾è‘—æå‡é¢„æµ‹å‡†ç¡®åº¦ï¼ˆRMSEé™ä½10.7%ï¼‰ï¼Œä¸”å¯¹å­¦ç”Ÿå¹²é¢„æ•ˆæœæœ‰ä¸€è‡´ã€å¯è§£é‡Šçš„æ­£å‘è°ƒæ•´ï¼Œè¯æ˜æ¨¡å‹èƒ½æ³›åŒ–å¹²é¢„æˆåŠŸæ¨¡å¼ï¼Œæ¨åŠ¨æ•™è‚²å†³ç­–æ™ºèƒ½åŒ–å’Œäººæœ¬åŒ–ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="264-QuProFS-An-Evolutionary-Training-free-Approach-to-Efficient-Quantum-Feature-Map-Search"><a href="#264-QuProFS-An-Evolutionary-Training-free-Approach-to-Efficient-Quantum-Feature-Map-Search" class="headerlink" title="264. QuProFS: An Evolutionary Training-free Approach to Efficient Quantum Feature Map Search"></a>264. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/QuProFS__An_Evolutionary_Training-free_Approach_to_Efficient_Quantum_Feature_Map_Search.pdf">QuProFS: An Evolutionary Training-free Approach to Efficient Quantum Feature Map Search</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">The University of Tokyo</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†QuProFSï¼Œä¸€ç§åŸºäºè¿›åŒ–ç®—æ³•çš„è®­ç»ƒæ— å…³é‡å­ç‰¹å¾æ˜ å°„é«˜æ•ˆæœç´¢æ–¹æ³•ã€‚æ–¹æ³•é€šè¿‡ç¡¬ä»¶çº¦æŸæ„ŸçŸ¥çš„é‡å­ç”µè·¯é‡‡æ ·ã€KTAè¿‡æ»¤å’Œå¤šä»£ç†è®­ç»ƒæ— å…³è¯„ä»·æŒ‡æ ‡ï¼ˆå¦‚è¡¨è¾¾æ€§ã€å¯è®­ç»ƒæ€§ã€ç¡¬ä»¶é²æ£’æ€§ç­‰ï¼‰ï¼Œç»“åˆéçº¿æ€§æ’åºèšåˆä¸è¿›åŒ–ç®—å­ï¼ˆå±‚æ‰©å±•+é—¨å‰ªæï¼‰å®ç°é«˜æ•ˆã€é²æ£’çš„é‡å­ç‰¹å¾æ˜ å°„æœç´¢ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒQuProFSåœ¨å¤šç§ç»å…¸ä¸é‡å­æ•°æ®é›†ä¸Šå‡†ç¡®ç‡é«˜ï¼Œä¸”æ¶æ„æœç´¢é€Ÿåº¦è¾¾åˆ°ç°æœ‰æ–¹æ³•2å€ï¼ŒçœŸå®é‡å­ç¡¬ä»¶ä¸Šè¡¨ç°é²æ£’ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="265-SEF-MK-Speaker-Embedding-Free-Voice-Anonymization-through-Multi-k-means-Quantization"><a href="#265-SEF-MK-Speaker-Embedding-Free-Voice-Anonymization-through-Multi-k-means-Quantization" class="headerlink" title="265. SEF-MK: Speaker-Embedding-Free Voice Anonymization through Multi-k-means Quantization"></a>265. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/SEF-MK__Speaker-Embedding-Free_Voice_Anonymization_through_Multi-k-means_Quantization.pdf">SEF-MK: Speaker-Embedding-Free Voice Anonymization through Multi-k-means Quantization</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Duke Kunshan University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§å…¨æ–°çš„è¯´è¯äººåµŒå…¥æ— å…³ï¼ˆSpeaker-Embedding-Free, SEFï¼‰è¯­éŸ³åŒ¿ååŒ–æ–¹æ³•SEF-MKï¼Œåˆ©ç”¨WavLMè‡ªç›‘ç£è¡¨ç¤ºã€å¤šä¸ªk-meansé‡åŒ–æ¨¡å‹å’ŒConformer-HiFi-GANè§£ç å™¨ã€‚æ–¹æ³•æµç¨‹åŒ…æ‹¬ï¼šé¦–å…ˆä½¿ç”¨WavLMæå–è¯­éŸ³ç‰¹å¾ï¼Œç„¶ååœ¨å¤šä¸ªåŸºäºä¸åŒè¯´è¯äººå­é›†è®­ç»ƒçš„k-meansæ¨¡å‹ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªå¯¹ç‰¹å¾é‡åŒ–ï¼Œæœ€åé€šè¿‡Conformerå’ŒHiFi-GANé‡æ„åŒ¿ååŒ–è¯­éŸ³ã€‚å®éªŒè¡¨æ˜ï¼Œå¤šk-meansæ¨¡å‹èƒ½æ›´å¥½åœ°ä¿ç•™è¯­ä¹‰å’Œæƒ…æ„Ÿå†…å®¹ï¼ŒåŒæ—¶åœ¨åº”å¯¹æ”»å‡»è€…æ—¶æå‡äº†æ”»å‡»å¤šæ ·æ€§ä½†ä¹ŸåŠ å¤§éšç§é£é™©ï¼Œæ•´ä½“åœ¨éšç§ä¿æŠ¤å’Œè¯­éŸ³å¯ç”¨æ€§ä¹‹é—´å–å¾—æ–°çš„å¹³è¡¡ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="266-A-Stage-Aware-Mixture-of-Experts-Framework-for-Neurodegenerative-Disease-Progression-Modelling"><a href="#266-A-Stage-Aware-Mixture-of-Experts-Framework-for-Neurodegenerative-Disease-Progression-Modelling" class="headerlink" title="266. A Stage-Aware Mixture of Experts Framework for Neurodegenerative Disease Progression Modelling"></a>266. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/A_Stage-Aware_Mixture_of_Experts_Framework_for_Neurodegenerative_Disease_Progression_Modelling.pdf">A Stage-Aware Mixture of Experts Framework for Neurodegenerative Disease Progression Modelling</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University College London</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§é˜¶æ®µæ„ŸçŸ¥çš„ä¸“å®¶æ··åˆï¼ˆMoEï¼‰æ¡†æ¶ï¼Œç»“åˆç—…ç†å­¦æ¨¡å‹ã€éå‡åŒ€å›¾ç¥ç»æ‰©æ•£æ¨¡å‹ï¼ˆIGNDï¼‰å’Œæœ¬åœ°åŒ–ç¥ç»ååº”æ¨¡å—ï¼Œå¹¶é‡‡ç”¨æ—¶åºæ³¨æ„æœºåˆ¶åŠ¨æ€è°ƒèŠ‚å„ä¸“å®¶å¯¹ç–¾ç—…è¿›å±•çš„è´¡çŒ®ã€‚ç»“æœæ˜¾ç¤ºè¯¥æ¨¡å‹åœ¨é˜¿å°”èŒ¨æµ·é»˜ç—…tauè›‹ç™½ä¼ æ’­çš„é•¿æœŸé¢„æµ‹ä¸­ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œæ­ç¤ºäº†ç–¾ç—…ä¸åŒé˜¶æ®µä¸»å¯¼æœºåˆ¶çš„å˜åŒ–ï¼Œå¹¶æä¾›äº†æ›´å…·è§£é‡Šæ€§çš„ç—…ç†å­¦è§è§£ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="267-Multi-Level-Service-Performance-Forecasting-via-Spatiotemporal-Graph-Neural-Networks"><a href="#267-Multi-Level-Service-Performance-Forecasting-via-Spatiotemporal-Graph-Neural-Networks" class="headerlink" title="267. Multi-Level Service Performance Forecasting via Spatiotemporal Graph Neural Networks"></a>267. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Multi-Level_Service_Performance_Forecasting_via_Spatiotemporal_Graph_Neural_Networks.pdf">Multi-Level Service Performance Forecasting via Spatiotemporal Graph Neural Networks</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Independent Author</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºæ—¶ç©ºå›¾ç¥ç»ç½‘ç»œï¼ˆSTGNNï¼‰çš„åˆ†å¸ƒå¼å¤šçº§æœåŠ¡æ€§èƒ½é¢„æµ‹æ–¹æ³•ï¼Œé€šè¿‡å°†ç³»ç»Ÿåœ¨ä¸åŒæ—¶é—´ç‰‡çš„çŠ¶æ€å»ºæ¨¡ä¸ºå›¾ç»“æ„ï¼Œç»“åˆæœåŠ¡èŠ‚ç‚¹çš„è¿è¡Œç‰¹å¾å’ŒæœåŠ¡è°ƒç”¨å…³ç³»ï¼Œåˆ©ç”¨å›¾å·ç§¯ç½‘ç»œæå–ç»“æ„ä¾èµ–ï¼Œç»“åˆé—¨æ§å¾ªç¯å•å…ƒï¼ˆGRUï¼‰å»ºæ¨¡æ—¶åºåŠ¨æ€ï¼Œå¹¶å¼•å…¥æ—¶é—´ç¼–ç æœºåˆ¶æå‡å¯¹éå¹³ç¨³åºåˆ—çš„è¡¨è¾¾èƒ½åŠ›ï¼Œæ•´ä½“ç«¯åˆ°ç«¯è®­ç»ƒå®ç°é«˜ç²¾åº¦æ€§èƒ½æŒ‡æ ‡å›å½’ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤§è§„æ¨¡çœŸå®æ•°æ®é›†ä¸Šç›¸è¾ƒä¸»æµåŸºçº¿åœ¨MAEã€RMSEå’ŒRÂ²ç­‰æŒ‡æ ‡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå…·å¤‡è¾ƒå¼ºçš„æ³›åŒ–æ€§å’Œé²æ£’æ€§ï¼Œèƒ½å¤Ÿé€‚åº”ä¸åŒçª—å£é•¿åº¦å’Œå¹¶å‘è´Ÿè½½ï¼Œé€‚ç”¨äºæ™ºèƒ½è¿ç»´å’Œèµ„æºè°ƒåº¦ç­‰å®é™…åœºæ™¯ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="268-Improving-Real-Time-Concept-Drift-Detection-using-a-Hybrid-Transformer-Autoencoder-Framework"><a href="#268-Improving-Real-Time-Concept-Drift-Detection-using-a-Hybrid-Transformer-Autoencoder-Framework" class="headerlink" title="268. Improving Real-Time Concept Drift Detection using a Hybrid Transformer-Autoencoder Framework"></a>268. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Improving_Real-Time_Concept_Drift_Detection_using_a_Hybrid_Transformer-Autoencoder_Framework.pdf">Improving Real-Time Concept Drift Detection using a Hybrid Transformer-Autoencoder Framework</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Vellore Institute of Technology (VIT-AP)</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§ç»“åˆTransformerä¸Autoencoderçš„æ··åˆæ¡†æ¶ï¼Œç”¨äºå®æ—¶æ£€æµ‹æ•°æ®æµä¸­çš„æ¦‚å¿µæ¼‚ç§»ã€‚æ–¹æ³•åŒ…æ‹¬åˆ©ç”¨ç»Ÿè®¡æŒ‡æ ‡ï¼ˆPSIã€JSDï¼‰ã€é‡æ„è¯¯å·®ã€é¢„æµ‹ä¸ç¡®å®šæ€§ã€è§„åˆ™è¿è§„åŠåˆ†ç±»å™¨é”™è¯¯è¶‹åŠ¿ï¼Œé€šè¿‡CatBooståˆ†ç±»å™¨å’Œå¤åˆTrust Scoreæå‡æ£€æµ‹çµæ•åº¦ä¸è§£é‡Šæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨åˆæˆèˆªç©ºä¹˜å®¢æ•°æ®é›†ä¸Šæ¯”ä¸»æµæ–¹æ³•æ›´æ—©ã€æ›´æ•æ„Ÿåœ°æ£€æµ‹åˆ°æ¼‚ç§»ï¼Œå¹¶å¢å¼ºäº†æ¨¡å‹è§£é‡Šèƒ½åŠ›ï¼Œé€‚ç”¨äºåŠ¨æ€ç¯å¢ƒä¸‹çš„æœºå™¨å­¦ä¹ ç³»ç»Ÿç›‘æ§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="269-Balancing-Privacy-and-Efficiency-Music-Information-Retrieval-via-Additive-Homomorphic-Encryption"><a href="#269-Balancing-Privacy-and-Efficiency-Music-Information-Retrieval-via-Additive-Homomorphic-Encryption" class="headerlink" title="269. Balancing Privacy and Efficiency: Music Information Retrieval via Additive Homomorphic Encryption"></a>269. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Balancing_Privacy_and_Efficiency__Music_Information_Retrieval_via_Additive_Homomorphic_Encryption.pdf">Balancing Privacy and Efficiency: Music Information Retrieval via Additive Homomorphic Encryption</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Independent Researcher</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºåŠ æ³•åŒæ€åŠ å¯†ï¼ˆAHEï¼‰çš„éŸ³ä¹ä¿¡æ¯æ£€ç´¢æ–¹æ³•ï¼Œé€šè¿‡ç»“æ„åŒ–çš„åˆ†å—å†…ç§¯ä¸åŠ æƒå±‚æ¬¡å†…ç§¯å®ç°å¯¹é«˜ç»´éŸ³ä¹å‘é‡çš„é«˜æ•ˆéšç§ä¿æŠ¤ç›¸ä¼¼æ€§æœç´¢ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç›¸è¾ƒäºå…¨åŒæ€åŠ å¯†ï¼ˆFHEï¼‰ï¼ŒAHEæ–¹æ¡ˆåœ¨æ£€ç´¢é€Ÿåº¦å’Œå†…å­˜å ç”¨æ–¹é¢æ›´ä¼˜ï¼Œæœ‰æ•ˆå¹³è¡¡äº†å®‰å…¨æ€§ä¸å®ç”¨æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="270-TurboBias-Universal-ASR-Context-Biasing-powered-by-GPU-accelerated-Phrase-Boosting-Tree"><a href="#270-TurboBias-Universal-ASR-Context-Biasing-powered-by-GPU-accelerated-Phrase-Boosting-Tree" class="headerlink" title="270. TurboBias: Universal ASR Context-Biasing powered by GPU-accelerated Phrase-Boosting Tree"></a>270. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/TurboBias__Universal_ASR_Context-Biasing_powered_by_GPU-accelerated_Phrase-Boosting_Tree.pdf">TurboBias: Universal ASR Context-Biasing powered by GPU-accelerated Phrase-Boosting Tree</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">NVIDIA</span></p>
<p>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§é€šç”¨ASRä¸Šä¸‹æ–‡åç½®æ¡†æ¶GPU-PBï¼ŒåŸºäºGPUåŠ é€Ÿçš„çŸ­è¯­æå‡æ ‘å’Œæ”¹è¿›çš„æƒé‡åˆ†å¸ƒï¼Œå¯é«˜æ•ˆæ”¯æŒCTCã€RNN-Tå’ŒAttention Encoder-Decoderç­‰ä¸»æµå£°å­¦æ¨¡å‹ï¼Œå¹¶é€‚ç”¨äºè´ªå©ªå’ŒæŸæœç´¢è§£ç ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æå‡å…³é”®è¯è¯†åˆ«å‡†ç¡®ç‡ï¼ˆF-scoreï¼‰å’Œæ•´ä½“è¯†åˆ«æ€§èƒ½ï¼ˆWERï¼‰æ–¹é¢å‡ä¼˜äºç°æœ‰å¼€æºæ–¹æ³•ï¼Œä¸”æ¨ç†é€Ÿåº¦æŸè€—æä½ï¼Œæ”¯æŒé«˜è¾¾2ä¸‡æ¡çŸ­è¯­çš„æ‰©å±•ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="271-TLCCSP-A-Scalable-Framework-for-Enhancing-Time-Series-Forecasting-with-Time-Lagged-Cross-Correlations"><a href="#271-TLCCSP-A-Scalable-Framework-for-Enhancing-Time-Series-Forecasting-with-Time-Lagged-Cross-Correlations" class="headerlink" title="271. TLCCSP: A Scalable Framework for Enhancing Time Series Forecasting with Time-Lagged Cross-Correlations"></a>271. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/TLCCSP__A_Scalable_Framework_for_Enhancing_Time_Series_Forecasting_with_Time-Lagged_Cross-Correlatio.pdf">TLCCSP: A Scalable Framework for Enhancing Time Series Forecasting with Time-Lagged Cross-Correlations</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">School of Artificial Intelligence, Beijing Normal University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†TLCCSPæ¡†æ¶ï¼Œé€šè¿‡è®¾è®¡Sequence Shifted Dynamic Time Warping (SSDTW) ç®—æ³•è‡ªåŠ¨å‘ç°æ—¶é—´åºåˆ—é—´çš„æ—¶æ»ç›¸å…³æ€§ï¼Œå¹¶å¼•å…¥å¯¹æ¯”å­¦ä¹ ç¼–ç å™¨é«˜æ•ˆè¿‘ä¼¼SSDTWè·ç¦»ï¼Œæå¤§æå‡äº†å¤šé¢†åŸŸï¼ˆæ°”è±¡ã€é‡‘èã€æˆ¿åœ°äº§ï¼‰æ—¶é—´åºåˆ—é¢„æµ‹çš„å‡†ç¡®æ€§å’Œå¯æ‰©å±•æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒTLCCSPåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—é™ä½äº†é¢„æµ‹è¯¯å·®ï¼Œä¸”å¯¹æ¯”å­¦ä¹ æ–¹æ³•å°†è®¡ç®—è€—æ—¶å‡å°‘çº¦99%ï¼Œæœ‰æ•ˆæ”¯æŒå¤§è§„æ¨¡å®æ—¶é¢„æµ‹ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="272-UniMove-A-Unified-Model-for-Multi-city-Human-Mobility-Prediction"><a href="#272-UniMove-A-Unified-Model-for-Multi-city-Human-Mobility-Prediction" class="headerlink" title="272. UniMove: A Unified Model for Multi-city Human Mobility Prediction"></a>272. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/UniMove__A_Unified_Model_for_Multi-city_Human_Mobility_Prediction.pdf">UniMove: A Unified Model for Multi-city Human Mobility Prediction</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Tsinghua University</span></p>
<p>æœ¬è®ºæ–‡æå‡ºUniMoveï¼Œä¸€ä¸ªç”¨äºå¤šåŸå¸‚äººç±»ç§»åŠ¨æ€§é¢„æµ‹çš„ç»Ÿä¸€æ¨¡å‹ã€‚UniMoveé‡‡ç”¨è½¨è¿¹-ä½ç½®åŒå¡”ç»“æ„ï¼Œé€šè¿‡ä½ç½®å¡”ç”Ÿæˆé€šç”¨ç©ºé—´è¡¨ç¤ºï¼Œå¹¶åŠ å…¥Deep &amp; Cross Netä»¥å¢å¼ºç‰¹å¾è¡¨è¾¾ï¼ŒåŒæ—¶è½¨è¿¹å¡”é‡‡ç”¨MoE Transformeræ¨¡å—è‡ªé€‚åº”é€‰æ‹©ä¸“å®¶ç½‘ç»œå¤„ç†ä¸åŒåŸå¸‚çš„å¼‚è´¨ç§»åŠ¨æ¨¡å¼ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒUniMoveèƒ½åœ¨å¤šåŸå¸‚æ•°æ®è”åˆè®­ç»ƒä¸­å®ç°æ•°æ®äº’è¡¥ï¼Œå‡†ç¡®ç‡æå‡è¶…è¿‡10.2%ï¼Œå°¤å…¶å¯¹æ•°æ®ç¨€ç–åŸå¸‚æå‡æ˜¾è‘—ï¼Œå…·å¤‡æ›´å¼ºæ³›åŒ–èƒ½åŠ›å’Œè®­ç»ƒæ•ˆç‡ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="273-Simulating-Biological-Intelligence-Active-Inference-with-Experiment-Informed-Generative-Model"><a href="#273-Simulating-Biological-Intelligence-Active-Inference-with-Experiment-Informed-Generative-Model" class="headerlink" title="273. Simulating Biological Intelligence: Active Inference with Experiment-Informed Generative Model"></a>273. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Simulating_Biological_Intelligence__Active_Inference_with_Experiment-Informed_Generative_Model.pdf">Simulating Biological Intelligence: Active Inference with Experiment-Informed Generative Model</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Turner Institute for Brain and Mental Health, School of Psychological Sciences, Monash University</span></p>
<p>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºä¸»åŠ¨æ¨æ–­ï¼ˆActive Inferenceï¼‰ç†è®ºçš„ç”Ÿæˆæ¨¡å‹æ¡†æ¶ï¼Œæ¨¡æ‹Ÿç”Ÿç‰©ç¥ç»ç½‘ç»œå†³ç­–è¿‡ç¨‹ï¼Œé€šè¿‡ç»“åˆPOMDPç»“æ„å’Œå®éªŒæ•°æ®ï¼Œç³»ç»Ÿå¯¹æ¯”äº†å¤šç§å†³ç­–ç®—æ³•ï¼ˆåŒ…æ‹¬è®°å¿†å¢å¼ºçš„åäº‹å®å­¦ä¹ ã€åŠ¨æ€è§„åˆ’å’Œç»å…¸ä¸»åŠ¨æ¨æ–­ï¼‰åœ¨Pongç¯å¢ƒä¸‹çš„å­¦ä¹ è¡¨ç°ã€‚ç»“æœæ˜¾ç¤ºï¼Œå…·æœ‰è®°å¿†æœºåˆ¶çš„åäº‹å®å­¦ä¹ æ–¹æ³•åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„å†³ç­–æ•ˆæœä¼˜äºä¼ ç»Ÿè§„åˆ’ç®—æ³•ï¼Œæ­ç¤ºäº†è®°å¿†åœ¨æ™ºèƒ½ä½“ç›®æ ‡å¯¼å‘è¡Œä¸ºä¸­çš„å…³é”®ä½œç”¨ï¼Œå¹¶ä¸ºå¯è§£é‡Šã€ç±»è„‘AIç³»ç»Ÿçš„è®¾è®¡æä¾›äº†ç†è®ºåŸºç¡€ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="274-Neural-Beam-Field-for-Spatial-Beam-RSRP-Prediction"><a href="#274-Neural-Beam-Field-for-Spatial-Beam-RSRP-Prediction" class="headerlink" title="274. Neural Beam Field for Spatial Beam RSRP Prediction"></a>274. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Neural_Beam_Field_for_Spatial_Beam_RSRP_Prediction.pdf">Neural Beam Field for Spatial Beam RSRP Prediction</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Xiamen University</span></p>
<p>æœ¬æ–‡æå‡ºäº†Neural Beam Field (NBF)ï¼Œä¸€ç§ç»“åˆTransformerç¥ç»ç½‘ç»œå’Œç‰©ç†æ¨¡å‹çš„æ··åˆæ¡†æ¶ï¼Œç”¨äºé«˜æ•ˆä¸”å¯è§£é‡Šçš„ç©ºé—´æ³¢æŸRSRPé¢„æµ‹ã€‚æ–¹æ³•æ ¸å¿ƒåŒ…æ‹¬å¤šè·¯å¾„æ¡ä»¶åŠŸç‡å‰–é¢(MCPP)çš„å¼•å…¥ï¼Œç»“åˆå…ˆéªŒç‰©ç†å»ºæ¨¡ä¸ç¥ç»ç½‘ç»œå­¦ä¹ ï¼Œå¹¶é€šè¿‡é¢„è®­ç»ƒ-æ ¡å‡†ç­–ç•¥æå‡æ”¶æ•›ä¸æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒNBFè¾ƒä¼ ç»Ÿè¡¨æ ¼æ³•å’Œçº¯é»‘ç›’ç¥ç»ç½‘ç»œåœ¨å‡†ç¡®ç‡ã€è®­ç»ƒæ•ˆç‡å’Œæ¨¡å‹ç´§å‡‘æ€§æ–¹é¢å‡æœ‰æ˜¾è‘—æå‡ï¼Œé€‚ç”¨äºå¯†é›†æ— çº¿ç½‘ç»œä¸­çš„æ™ºèƒ½æ³¢æŸç®¡ç†ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="275-Machine-Learning-Algorithms-for-Improving-Exact-Classical-Solvers-in-Mixed-Integer-Continuous-Optimization"><a href="#275-Machine-Learning-Algorithms-for-Improving-Exact-Classical-Solvers-in-Mixed-Integer-Continuous-Optimization" class="headerlink" title="275. Machine Learning Algorithms for Improving Exact Classical Solvers in Mixed Integer Continuous Optimization"></a>275. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Machine_Learning_Algorithms_for_Improving_Exact_Classical_Solvers_in_Mixed_Integer_Continuous_Optimi.pdf">Machine Learning Algorithms for Improving Exact Classical Solvers in Mixed Integer Continuous Optimization</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">UniversitÃ¤t Wien</span></p>
<p>æœ¬æ–‡ç³»ç»Ÿç»¼è¿°äº†æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰å’Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æŠ€æœ¯åœ¨æå‡æ•´æ•°ä¸æ··åˆæ•´æ•°éçº¿æ€§è§„åˆ’ï¼ˆINLPã€MINLPï¼‰ç­‰ç²¾ç¡®ä¼˜åŒ–ç®—æ³•ä¸­çš„åº”ç”¨ï¼Œç‰¹åˆ«èšç„¦äºä¸åˆ†æ”¯å®šç•Œï¼ˆBranch-and-Bound, BBï¼‰æ¡†æ¶çš„é›†æˆï¼ŒåŒ…æ‹¬åˆ†æ”¯å†³ç­–ã€åˆ‡å‰²é€‰æ‹©ã€èŠ‚ç‚¹æ’åºå’Œå‚æ•°æ§åˆ¶ç­‰ç¯èŠ‚ã€‚é€šè¿‡å°†ç›‘ç£å­¦ä¹ ã€æ¨¡ä»¿å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ åµŒå…¥ä¼ ç»Ÿä¼˜åŒ–æµç¨‹ï¼Œæ˜¾è‘—åŠ é€Ÿæ±‚è§£è¿‡ç¨‹ä¸”ä¸æŸå¤±å…¨å±€æœ€ä¼˜æ€§ã€‚ç»“è®ºæŒ‡å‡ºï¼šå­¦ä¹ å¢å¼ºçš„ä¼˜åŒ–æ–¹æ³•åœ¨å¤§è§„æ¨¡æˆ–ç»“æ„å¤æ‚é—®é¢˜ä¸Šèƒ½æé«˜æ”¶æ•›é€Ÿåº¦ï¼Œä½†åœ¨æ•°æ®ç¨€ç¼ºå’Œç»“æ„è§„åˆ™æ—¶ä»éœ€ä¾èµ–ä¼ ç»Ÿç®—æ³•ï¼Œä¸¤è€…èåˆæ˜¯æœªæ¥æ™ºèƒ½ä¼˜åŒ–å‘å±•çš„å…³é”®ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="276-A-Score-based-Diffusion-Model-Approach-for-Adaptive-Learning-of-Stochastic-Partial-Differential-Equation-Solutions"><a href="#276-A-Score-based-Diffusion-Model-Approach-for-Adaptive-Learning-of-Stochastic-Partial-Differential-Equation-Solutions" class="headerlink" title="276. A Score-based Diffusion Model Approach for Adaptive Learning of Stochastic Partial Differential Equation Solutions"></a>276. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/A_Score-based_Diffusion_Model_Approach_for_Adaptive_Learning_of_Stochastic_Partial_Differential_Equa.pdf">A Score-based Diffusion Model Approach for Adaptive Learning of Stochastic Partial Differential Equation Solutions</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of South Carolina</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºåˆ†æ•°(score)-é©±åŠ¨æ‰©æ•£æ¨¡å‹çš„è‡ªé€‚åº”å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºé€’å½’è´å¶æ–¯æ¨æ–­ä¸‹çš„éšæœºåå¾®åˆ†æ–¹ç¨‹(SPDEs)è§£çš„åŠ¨æ€ä¼°è®¡ã€‚æ–¹æ³•å°†ç‰©ç†çŸ¥è¯†ç¼–ç åˆ°æ‰©æ•£æ¨¡å‹çš„åˆ†æ•°å‡½æ•°ï¼Œé€šè¿‡æ•°å€¼ä»¿çœŸå’Œè§‚æµ‹æ•°æ®çš„ä¼¼ç„¶æ ¡æ­£ï¼Œå®ç°æ¨¡å‹çŠ¶æ€çš„è¿­ä»£ä¼˜åŒ–ï¼Œå¹¶æå‡ºæ— éœ€è®­ç»ƒçš„Ensemble Score Filterä»¥æå‡é«˜ç»´å®æ—¶æ¨æ–­æ•ˆç‡ã€‚å¤§é‡æ•°å€¼å®éªŒï¼ˆå¦‚Burgersæ–¹ç¨‹ã€Navier-Stokesæ–¹ç¨‹ã€Allen-Cahnæ–¹ç¨‹ï¼‰æ˜¾ç¤ºï¼Œåœ¨ç¨€ç–å’Œæœ‰å™ªå£°è§‚æµ‹æ¡ä»¶ä¸‹ï¼Œè¯¥æ–¹æ³•èƒ½å‡†ç¡®ã€é²æ£’åœ°æ¢å¤éšè—ç‰©ç†çŠ¶æ€å’Œæå‡è§£çš„ç²¾åº¦ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="277-Mode-Aware-Non-Linear-Tucker-Autoencoder-for-Tensor-based-Unsupervised-Learning"><a href="#277-Mode-Aware-Non-Linear-Tucker-Autoencoder-for-Tensor-based-Unsupervised-Learning" class="headerlink" title="277. Mode-Aware Non-Linear Tucker Autoencoder for Tensor-based Unsupervised Learning"></a>277. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Mode-Aware_Non-Linear_Tucker_Autoencoder_for_Tensor-based_Unsupervised_Learning.pdf">Mode-Aware Non-Linear Tucker Autoencoder for Tensor-based Unsupervised Learning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">ä¸œå—å¤§å­¦</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ— ç›‘ç£å­¦ä¹ æ¡†æ¶â€”â€”Mode-Aware Non-linear Tucker Autoencoder (MA-NTAE)ï¼Œé€šè¿‡é€’å½’çš„Pickâ€“Unfoldâ€“Encodeâ€“Foldæ“ä½œå®ç°é«˜é˜¶å¼ é‡çš„çµæ´»éçº¿æ€§å‹ç¼©ï¼Œç»“åˆTuckeråˆ†è§£ä¸ç°ä»£è‡ªç¼–ç å™¨æŠ€æœ¯ï¼Œæ˜¾è‘—æå‡äº†é«˜ç»´æ•°æ®çš„å‹ç¼©ã€é‡æ„å’Œèšç±»è¡¨ç°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMA-NTAEåœ¨å¤šä¸ªåˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šçš„é‡æ„è¯¯å·®ã€èšç±»æŒ‡æ ‡å‡ä¼˜äºå…¸å‹çš„æ·±åº¦è‡ªç¼–ç å™¨ï¼ˆDAEï¼‰å’Œå¼ é‡åˆ†è§£ç¥ç»ç½‘ç»œï¼ˆTFNNï¼‰ï¼Œä¸”æ¨¡å‹å‚æ•°é‡å°ã€è®­ç»ƒæ•ˆç‡é«˜ï¼Œå°¤å…¶é€‚ç”¨äºé«˜é˜¶é«˜ç»´å¼ é‡åœºæ™¯ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="278-Structured-Superposition-of-Autoencoders-for-UEP-Codes-at-Intermediate-Blocklengths"><a href="#278-Structured-Superposition-of-Autoencoders-for-UEP-Codes-at-Intermediate-Blocklengths" class="headerlink" title="278. Structured Superposition of Autoencoders for UEP Codes at Intermediate Blocklengths"></a>278. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Structured_Superposition_of_Autoencoders_for_UEP_Codes_at_Intermediate_Blocklengths.pdf">Structured Superposition of Autoencoders for UEP Codes at Intermediate Blocklengths</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Novi Sad</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§ç»“æ„åŒ–è‡ªç¼–ç å™¨ï¼ˆAEï¼‰æ¶æ„ï¼Œå°†ç¼–ç å’Œè§£ç è¿‡ç¨‹åˆ†ä¸ºå¤šä¸ªAEå­æ¨¡å—ï¼Œå¹¶ç»“åˆå åŠ ç¼–ç ä¸SICè§£ç æ€æƒ³ï¼Œå®ç°äº†ä¸­ç­‰åŒºå—é•¿åº¦ä¸‹çš„æ¯”ç‰¹çº§ä¸ç­‰é”™è¯¯ä¿æŠ¤ï¼ˆUEPï¼‰ç è®¾è®¡ã€‚æ•°å€¼ç»“æœæ˜¾ç¤ºï¼Œè¯¥ç»“æ„åœ¨å¯è¾¾é”™è¯¯æ¦‚ç‡åŒºåŸŸä¼˜äºä¼ ç»Ÿå åŠ éšæœºç¼–ç ä¸SICè§£ç æ–¹æ³•ï¼Œä¸”å¯é«˜æ•ˆæ‰©å±•è‡³æ›´å¤§åŒºå—é•¿åº¦ï¼Œé€‚ç”¨äºèµ„æºå—é™åœºæ™¯ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="279-Lightning-Prediction-under-Uncertainty-DeepLight-with-Hazy-Loss"><a href="#279-Lightning-Prediction-under-Uncertainty-DeepLight-with-Hazy-Loss" class="headerlink" title="279. Lightning Prediction under Uncertainty: DeepLight with Hazy Loss"></a>279. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Lightning_Prediction_under_Uncertainty__DeepLight_with_Hazy_Loss.pdf">Lightning Prediction under Uncertainty: DeepLight with Hazy Loss</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Bangladesh University of Engineering and Technology</span></p>
<p>æœ¬æ–‡æå‡ºäº†DeepLightï¼Œä¸€ç§æ–°é¢–çš„æ·±åº¦å­¦ä¹ æ¶æ„ï¼Œé€šè¿‡å¤šåˆ†æ”¯ConvLSTMå’ŒåŒç¼–ç å™¨ï¼Œèåˆé›·è¾¾åå°„ç‡ã€äº‘å±æ€§å’Œå†å²é—ªç”µæ•°æ®è¿›è¡Œé—ªç”µé¢„æµ‹ã€‚åˆ›æ–°æ€§åœ°å¼•å…¥Hazy Lossé‚»åŸŸæ„ŸçŸ¥æŸå¤±å‡½æ•°ï¼Œæœ‰æ•ˆå¤„ç†é—ªç”µçš„æ—¶ç©ºä¸ç¡®å®šæ€§ï¼Œæå‡é¢„æµ‹å‡†ç¡®æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒDeepLightåœ¨å¤šä¸ªé¢„æµ‹æ—¶é•¿ä¸Šè¾ƒç°æœ‰æ–¹æ³•Equitable Threat Scoreæå‡8%â€“30%ï¼ŒHazy Losså¯¹å¤šæ¨¡å‹å‡æœ‰æ˜¾è‘—å¢ç›Šã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="280-Leveraging-GNN-to-Enhance-MEF-Method-in-Predicting-ENSO"><a href="#280-Leveraging-GNN-to-Enhance-MEF-Method-in-Predicting-ENSO" class="headerlink" title="280. Leveraging GNN to Enhance MEF Method in Predicting ENSO"></a>280. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Leveraging_GNN_to_Enhance_MEF_Method_in_Predicting_ENSO.pdf">Leveraging GNN to Enhance MEF Method in Predicting ENSO</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Shiraz University of Technology</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰å¢å¼ºçš„å¤šæ¨¡æ€ENSOé¢„æµ‹ï¼ˆMEFï¼‰æ¡†æ¶ï¼Œå°†3Då·ç§¯ç¥ç»ç½‘ç»œï¼ˆ3D-CNNï¼‰ä¸æ—¶é—´åºåˆ—æ¨¡å—è¾“å‡ºçš„80ä¸ªé›†æˆæˆå‘˜é€šè¿‡æ„å»ºç›¸ä¼¼æ€§åŠ æƒå›¾è¿›è¡Œç»“æ„åŒ–åˆ†æï¼Œå¹¶åˆ©ç”¨ç¤¾åŒºæ£€æµ‹æ–¹æ³•é€‰å–æœ€ä¼˜å­é›†ï¼Œæœ€ç»ˆæå‡é¢„æµ‹çš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ï¼Œå°¤å…¶åœ¨é•¿æœŸé¢„æµ‹åœºæ™¯ä¸‹è¡¨ç°æ›´ä¼˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGNNæ–¹æ³•å¯æœ‰æ•ˆè¿‡æ»¤ä¸ç¨³å®šå™ªå£°æˆå‘˜ï¼Œå®ç°æ›´é«˜çš„ç›¸å…³æ€§å’Œä¸€è‡´æ€§è¾“å‡ºï¼Œä¸”è¯¥æ–¹æ³•å¯¹æ¨¡å‹ç»“æ„æ— ä¾èµ–ï¼Œæ˜“äºåº”ç”¨äºå…¶å®ƒé›†æˆé¢„æµ‹ç³»ç»Ÿã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="281-ProteoKnight-Convolution-based-phage-virion-protein-classification-and-uncertainty-analysis"><a href="#281-ProteoKnight-Convolution-based-phage-virion-protein-classification-and-uncertainty-analysis" class="headerlink" title="281. ProteoKnight: Convolution-based phage virion protein classification and uncertainty analysis"></a>281. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/ProteoKnight__Convolution-based_phage_virion_protein_classification_and_uncertainty_analysis.pdf">ProteoKnight: Convolution-based phage virion protein classification and uncertainty analysis</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">BRAC University</span></p>
<p>æœ¬è®ºæ–‡æå‡ºProteoKnightæ–¹æ³•ï¼Œé‡‡ç”¨åŸºäºDNA-Walkçš„Knightç¼–ç ï¼Œå°†è›‹ç™½è´¨åºåˆ—è½¬åŒ–ä¸ºå›¾åƒï¼Œå¹¶åˆ©ç”¨é¢„è®­ç»ƒå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰è¿›è¡ŒäºŒåˆ†ç±»å’Œå¤šåˆ†ç±»é¢„æµ‹ï¼ŒåŒæ—¶å¼•å…¥Monte Carlo Dropoutæ–¹æ³•å¯¹æ¨¡å‹é¢„æµ‹è¿›è¡Œä¸ç¡®å®šæ€§åˆ†æã€‚ç»“æœæ˜¾ç¤ºï¼ŒKnightç¼–ç ç»“åˆé«˜æ•ˆCNNæ¨¡å‹å¯åœ¨äºŒåˆ†ç±»ä»»åŠ¡ä¸­è¾¾åˆ°çº¦90.8%çš„å‡†ç¡®ç‡ï¼Œå¹¶æ­ç¤ºäº†è›‹ç™½è´¨ç±»åˆ«å’Œåºåˆ—é•¿åº¦å¯¹é¢„æµ‹ç½®ä¿¡åº¦çš„å½±å“ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="282-Finite-Time-Convergence-Analysis-of-ODE-based-Generative-Models-for-Stochastic-Interpolants"><a href="#282-Finite-Time-Convergence-Analysis-of-ODE-based-Generative-Models-for-Stochastic-Interpolants" class="headerlink" title="282. Finite-Time Convergence Analysis of ODE-based Generative Models for Stochastic Interpolants"></a>282. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Finite-Time_Convergence_Analysis_of_ODE-based_Generative_Models_for_Stochastic_Interpolants.pdf">Finite-Time Convergence Analysis of ODE-based Generative Models for Stochastic Interpolants</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">IIIS, Tsinghua University</span></p>
<p>è¯¥è®ºæ–‡ç³»ç»Ÿåˆ†æäº†åŸºäºå¸¸å¾®åˆ†æ–¹ç¨‹ï¼ˆODEï¼‰çš„ç”Ÿæˆæ¨¡å‹åœ¨éšæœºæ’å€¼æ¡†æ¶ä¸‹çš„æœ‰é™æ—¶é—´æ”¶æ•›æ€§ï¼Œé€šè¿‡ç†è®ºæ¨å¯¼ç»™å‡ºäº†å‰å‘Euleræ–¹æ³•å’ŒHeunâ€™sæ–¹æ³•åœ¨æ€»å˜å·®è·ç¦»ä¸Šçš„è¯¯å·®ç•Œï¼Œå¹¶åˆ†æäº†è¿­ä»£å¤æ‚åº¦ã€‚å®éªŒç»“æœéªŒè¯äº†ç†è®ºæ”¶æ•›é€Ÿç‡ï¼Œä¸ºå®é™…ç”Ÿæˆè¿‡ç¨‹çš„æ•°å€¼å®ç°æä¾›äº†æ›´ç²¾ç¡®çš„è¯¯å·®æ§åˆ¶å’Œå¤æ‚åº¦ä¼˜åŒ–ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="283-Fairness-of-Automatic-Speech-Recognition-Looking-Through-a-Philosophical-Lens"><a href="#283-Fairness-of-Automatic-Speech-Recognition-Looking-Through-a-Philosophical-Lens" class="headerlink" title="283. Fairness of Automatic Speech Recognition: Looking Through a Philosophical Lens"></a>283. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Fairness_of_Automatic_Speech_Recognition__Looking_Through_a_Philosophical_Lens.pdf">Fairness of Automatic Speech Recognition: Looking Through a Philosophical Lens</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Cornell University</span></p>
<p>æœ¬æ–‡é€šè¿‡å“²å­¦è§†è§’åˆ†æè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰ç³»ç»Ÿçš„åè§ä¸å…¬å¹³æ€§ï¼Œæå‡ºASRå¯¹éæ ‡å‡†æ–¹è¨€çš„ç³»ç»Ÿæ€§è¯¯è¯†ä¸ä»…æ˜¯æŠ€æœ¯å±€é™ï¼Œæ›´æ˜¯å¯¹è¾¹ç¼˜åŒ–è¯­è¨€ç¾¤ä½“çš„ä¸å°Šé‡ã€‚ä½œè€…åŒºåˆ†äº†é“å¾·ä¸­æ€§çš„åˆ†ç±»ï¼ˆdiscriminate1ï¼‰ä¸æœ‰å®³æ­§è§†ï¼ˆdiscriminate2ï¼‰ï¼Œå¹¶æ­ç¤ºASRåè§çš„ä¸‰å¤§ç‹¬ç‰¹ä¼¦ç†ç»´åº¦ï¼šæ—¶é—´è´Ÿæ‹…ï¼ˆtemporal taxationï¼‰ã€å¯¹è¯æµä¸­æ–­å’Œå¯¹èº«ä»½è®¤åŒçš„å½±å“ã€‚ç»“è®ºè®¤ä¸ºï¼Œè§£å†³ASRåè§ä¸ä»…éœ€æŠ€æœ¯æ”¹è¿›ï¼Œæ›´éœ€æ‰¿è®¤å¤šæ ·åŒ–è¯­éŸ³å½¢å¼çš„åˆæ³•æ€§ï¼Œæ¨åŠ¨æŠ€æœ¯ä¸ä¼¦ç†å¹¶é‡ï¼Œå®ç°å¯¹è¯­è¨€å¤šæ ·æ€§çš„å°Šé‡ä¸åŒ…å®¹ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="284-An-effective-potential-for-generative-modelling-with-active-matter"><a href="#284-An-effective-potential-for-generative-modelling-with-active-matter" class="headerlink" title="284. An effective potential for generative modelling with active matter"></a>284. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/An_effective_potential_for_generative_modelling_with_active_matter.pdf">An effective potential for generative modelling with active matter</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Queen Mary University of London</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºä¸»åŠ¨ç²’å­è¿‡ç¨‹çš„ç”Ÿæˆæ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡åœ¨ä½ç½®åæ ‡ä¸Šæ–½åŠ æœ‰æ•ˆçš„æ—¶é—´ç›¸å…³åŠ¿èƒ½ï¼Œå®ç°äº†æ‰©æ•£æ¨¡å‹çš„æ—¶é—´åæ¼”é‡‡æ ·ã€‚å…³é”®æŠ€æœ¯åŒ…æ‹¬Foxå’ŒUCNè¿‘ä¼¼ï¼Œæœ‰æ•ˆåŠ¿èƒ½ç”±æ ‡å‡†scoreå‡½æ•°åŠå…¶é«˜é˜¶å¯¼æ•°å†³å®šï¼Œæ•°å€¼å®éªŒéªŒè¯äº†æ–¹æ³•çš„å‡†ç¡®æ€§ã€‚ç»“è®ºè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•èƒ½ç²¾ç¡®å†ç°ç›®æ ‡åˆ†å¸ƒï¼Œä¸”å…·å¤‡å®éªŒå®ç°æ½œåŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="285-OFAL-An-Oracle-Free-Active-Learning-Framework"><a href="#285-OFAL-An-Oracle-Free-Active-Learning-Framework" class="headerlink" title="285. OFAL: An Oracle-Free Active Learning Framework"></a>285. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/OFAL__An_Oracle-Free_Active_Learning_Framework.pdf">OFAL: An Oracle-Free Active Learning Framework</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Amirkabir University of Technology</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†OFALï¼Œä¸€ç§æ— éœ€äººå·¥æ ‡æ³¨è€…çš„ä¸»åŠ¨å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡ç¥ç»ç½‘ç»œçš„ä¸ç¡®å®šæ€§é‡åŒ–ï¼ˆåˆ©ç”¨Monte Carlo Dropoutè¿‘ä¼¼è´å¶æ–¯ç¥ç»ç½‘ç»œï¼‰ä¸å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰ï¼Œå°†æ¨¡å‹é«˜ç½®ä¿¡çš„æ— æ ‡ç­¾æ ·æœ¬è½¬æ¢ä¸ºå…·æœ‰é«˜ä¿¡æ¯é‡çš„ä¸ç¡®å®šæ ·æœ¬ï¼Œä»è€Œæå‡æ¨¡å‹æ€§èƒ½ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨MNISTæ•°æ®é›†ä¸Šï¼Œé€šè¿‡å¤šè½®ç”Ÿæˆä¸ç¡®å®šæ ·æœ¬å¹¶ä¸åŸæ ·æœ¬å…±åŒè®­ç»ƒï¼Œæ¨¡å‹å‡†ç¡®ç‡æå‡2.7%ï¼Œä¸”OFALå¯ä¸å…¶å®ƒä¸»åŠ¨å­¦ä¹ é‡‡æ ·æ–¹æ³•ç»“åˆï¼Œåœ¨æ— éœ€é¢å¤–æ ‡æ³¨æˆæœ¬ä¸‹è¿›ä¸€æ­¥æå‡æ•ˆæœã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="286-Learned-Regularization-for-Microwave-Tomography"><a href="#286-Learned-Regularization-for-Microwave-Tomography" class="headerlink" title="286. Learned Regularization for Microwave Tomography"></a>286. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Learned_Regularization_for_Microwave_Tomography.pdf">Learned Regularization for Microwave Tomography</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">University of Science and Technology of China</span></p>
<p>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§ç‰©ç†ä¿¡æ¯å¼•å¯¼çš„æ··åˆé‡å»ºæ¡†æ¶ï¼Œå°†å•æ­¥æ‰©æ•£æ¨¡å‹ï¼ˆSingle-Step Diffusion Regularization, SSD-Regï¼‰ä½œä¸ºPlug-and-Playæ­£åˆ™é¡¹åµŒå…¥åˆ°å¾®æ³¢å±‚ææˆåƒï¼ˆMWTï¼‰è¿­ä»£é‡å»ºæµç¨‹ä¸­ï¼Œæœ‰æ•ˆç»“åˆäº†ç²¾ç¡®çš„ç‰©ç†å»ºæ¨¡ä¸ç”Ÿæˆå¼å…ˆéªŒã€‚è¯¥æ–¹æ³•æ— éœ€é…å¯¹æ•°æ®ï¼Œé€šè¿‡FrÃ©chetå¯å¾®å‰å‘æ¨¡å‹å’Œå•æ­¥æ‰©æ•£æ­£åˆ™é¡¹ï¼Œå¼•å…¥å¼ºç»“æ„å…ˆéªŒï¼Œæ˜¾è‘—æå‡äº†é‡å»ºçš„å‡†ç¡®æ€§ã€ç¨³å®šæ€§å’Œæ”¶æ•›é€Ÿåº¦ã€‚å¤§é‡ä»¿çœŸå’ŒçœŸå®æ•°æ®å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç²¾åº¦ã€æŠ—å™ªæ€§å’Œæ•ˆç‡æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå±•ç°å‡ºè¾ƒå¼ºçš„ä¸´åºŠåº”ç”¨æ½œåŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="287-C-MAG-Cascade-Multimodal-Attributed-Graphs-for-Supply-Chain-Link-Prediction"><a href="#287-C-MAG-Cascade-Multimodal-Attributed-Graphs-for-Supply-Chain-Link-Prediction" class="headerlink" title="287. C-MAG: Cascade Multimodal Attributed Graphs for Supply Chain Link Prediction"></a>287. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/C-MAG__Cascade_Multimodal_Attributed_Graphs_for_Supply_Chain_Link_Prediction.pdf">C-MAG: Cascade Multimodal Attributed Graphs for Supply Chain Link Prediction</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">AAITC, Lenovo</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†C-MAGï¼ˆCascade Multimodal Attributed Graphsï¼‰æ–¹æ³•ï¼Œé€šè¿‡ä¸¤é˜¶æ®µçº§è”æ¶æ„å°†æ–‡æœ¬å’Œå›¾åƒç­‰å¤šæ¨¡æ€ä¿¡æ¯èšåˆè¿›åˆ¶é€ å•†èŠ‚ç‚¹ï¼Œå†é€šè¿‡å¼‚æ„å›¾ç¥ç»ç½‘ç»œå®ç°åˆ¶é€ å•†-äº§å“å…³ç³»çš„é«˜ç²¾åº¦é¢„æµ‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒC-MAGåœ¨ROC-AUCå’ŒPR-AUCç­‰æŒ‡æ ‡ä¸Šä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œä¸”å¯¹è§†è§‰å™ªå£°å…·æœ‰é²æ£’æ€§ï¼Œä¸ºä¾›åº”é“¾çŸ¥è¯†å›¾è°±çš„å¤šæ¨¡æ€é›†æˆå’Œé“¾è·¯é¢„æµ‹æä¾›äº†æ–°çš„æŠ€æœ¯æ–¹æ¡ˆã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="288-From-Source-to-Target-Leveraging-Transfer-Learning-for-Predictive-Process-Monitoring-in-Organizations"><a href="#288-From-Source-to-Target-Leveraging-Transfer-Learning-for-Predictive-Process-Monitoring-in-Organizations" class="headerlink" title="288. From Source to Target: Leveraging Transfer Learning for Predictive Process Monitoring in Organizations"></a>288. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/From_Source_to_Target__Leveraging_Transfer_Learning_for_Predictive_Process_Monitoring_in_Organizatio.pdf">From Source to Target: Leveraging Transfer Learning for Predictive Process Monitoring in Organizations</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Friedrich-Alexander-UniversitÃ¤t Erlangen-NÃ¼rnberg</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºè¿ç§»å­¦ä¹ çš„é¢„æµ‹æµç¨‹ç›‘æ§ï¼ˆPPMï¼‰æŠ€æœ¯ï¼Œé€šè¿‡é¢„è®­ç»ƒåµŒå…¥æ¨¡å‹è¿›è¡Œæ´»åŠ¨ç¼–ç å’Œç›¸å¯¹è·¨åŸŸæ—¶é—´æˆ³ç¼–ç ï¼Œå°†æºä¸šåŠ¡æµç¨‹çš„LSTMé¢„æµ‹æ¨¡å‹ç§»æ¤åˆ°ç›®æ ‡æµç¨‹ï¼Œæ— éœ€å¯¹ç›®æ ‡æ•°æ®è¿›è¡Œå¾®è°ƒã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•å¯åœ¨ç»„ç»‡å†…å¤–å®ç°è·¨æµç¨‹çŸ¥è¯†è½¬ç§»ï¼Œæœ‰æ•ˆæå‡ç›®æ ‡æµç¨‹çš„é¢„æµ‹æ€§èƒ½ï¼Œå¸®åŠ©ç¼ºä¹æ•°æ®æˆ–ç®—åŠ›çš„ç»„ç»‡å®ç°é«˜æ•ˆæµç¨‹ç›‘æ§å’Œå†³ç­–æ”¯æŒã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="289-On-Understanding-of-the-Dynamics-of-Model-Capacity-in-Continual-Learning"><a href="#289-On-Understanding-of-the-Dynamics-of-Model-Capacity-in-Continual-Learning" class="headerlink" title="289. On Understanding of the Dynamics of Model Capacity in Continual Learning"></a>289. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/On_Understanding_of_the_Dynamics_of_Model_Capacity_in_Continual_Learning.pdf">On Understanding of the Dynamics of Model Capacity in Continual Learning</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Capital One</span></p>
<p>æœ¬æ–‡æå‡ºäº†â€œè¿ç»­å­¦ä¹ æœ‰æ•ˆæ¨¡å‹å®¹é‡ï¼ˆCLEMCï¼‰â€çš„åŠ¨æ€ç†è®ºæ¡†æ¶ï¼Œç³»ç»Ÿåˆ»ç”»äº†ç¥ç»ç½‘ç»œåœ¨è¿ç»­å­¦ä¹ ä¸­çš„ç¨³å®šæ€§-å¯å¡‘æ€§å¹³è¡¡ç‚¹éšä»»åŠ¡æ¼”åŒ–çš„åŠ¨æ€å˜åŒ–ã€‚æ–¹æ³•ä¸Šï¼Œä½œè€…åŸºäºåŠ¨æ€è§„åˆ’å’Œæœ€ä¼˜æ§åˆ¶ï¼Œæ¨å¯¼å‡ºæ¨¡å‹å®¹é‡éšä»»åŠ¡åˆ†å¸ƒã€æƒé‡æ›´æ–°ã€ä¼˜åŒ–è¿‡ç¨‹å˜åŒ–çš„é€’æ¨æ–¹ç¨‹ï¼Œå¹¶ä»ç†è®ºä¸Šè¯æ˜äº†æ— è®ºæ¨¡å‹ç»“æ„æˆ–ä¼˜åŒ–æ–¹æ³•å¦‚ä½•ï¼Œåªè¦æ–°ä»»åŠ¡çš„åˆ†å¸ƒä¸æ–­å˜åŒ–ï¼Œå®¹é‡ï¼ˆå³æ¨¡å‹å¯¹æ–°ä»»åŠ¡çš„è¡¨å¾èƒ½åŠ›ï¼‰éƒ½ä¼šä¸å¯é¿å…åœ°å‘æ•£ï¼Œå¯¼è‡´é—å¿˜ç°è±¡ä¸æ–­ç´¯ç§¯ã€‚é€šè¿‡FNNã€CNNã€GNNå’Œå¤§è§„æ¨¡Transformerç­‰å¤šç§æ¶æ„åŠåˆæˆ&#x2F;çœŸå®æ•°æ®é›†å®éªŒï¼Œå®è¯éªŒè¯äº†ç†è®ºç»“è®ºçš„æ™®é€‚æ€§ã€‚ç»“è®ºï¼šè¿ç»­å­¦ä¹ ä¸­æ¨¡å‹å®¹é‡åŠ¨æ€å˜åŒ–ã€ä¸å¯é¿å…åœ°éšç€ä»»åŠ¡å˜åŒ–å‘æ•£ï¼Œéœ€é‡‡ç”¨åŠ¨æ€æ¨¡å‹å’Œå®¹é‡çº¦æŸæ–¹æ³•æ‰èƒ½æœ‰æ•ˆåº”å¯¹ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="290-Learning-to-Select-MCP-Algorithms-From-Traditional-ML-to-Dual-Channel-GAT-MLP"><a href="#290-Learning-to-Select-MCP-Algorithms-From-Traditional-ML-to-Dual-Channel-GAT-MLP" class="headerlink" title="290. Learning to Select MCP Algorithms: From Traditional ML to Dual-Channel GAT-MLP"></a>290. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Learning_to_Select_MCP_Algorithms__From_Traditional_ML_to_Dual-Channel_GAT-MLP.pdf">Learning to Select MCP Algorithms: From Traditional ML to Dual-Channel GAT-MLP</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Shantou University</span></p>
<p>è¯¥è®ºæ–‡é’ˆå¯¹æœ€å¤§å›¢é—®é¢˜ï¼ˆMCPï¼‰çš„ç®—æ³•é€‰æ‹©ï¼Œæå‡ºäº†ä¸€ä¸ªç»“åˆä¼ ç»Ÿæœºå™¨å­¦ä¹ å’Œå›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰çš„å­¦ä¹ å‹æ¡†æ¶ã€‚ä½œè€…é€šè¿‡æ„å»ºåŒ…å«å¤šæ ·åŒ–å›¾å®ä¾‹å’Œç»“æ„ç‰¹å¾çš„æ•°æ®é›†ï¼Œè¯„ä¼°äº†SVMã€éšæœºæ£®æ—ç­‰ä¼ ç»Ÿåˆ†ç±»å™¨ï¼Œå¹¶æå‡ºäº†èåˆå±€éƒ¨ç»“æ„ç¼–ç ï¼ˆGATï¼‰å’Œå…¨å±€ç‰¹å¾å»ºæ¨¡ï¼ˆMLPï¼‰çš„åŒé€šé“GAT-MLPæ¨¡å‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGAT-MLPåœ¨å‡†ç¡®ç‡å’ŒF1åˆ†æ•°ä¸Šå‡ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œèƒ½æœ‰æ•ˆè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜MCPç®—æ³•ï¼Œæ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬ï¼ŒéªŒè¯äº†åŒé€šé“æ¶æ„åœ¨ç»„åˆç®—æ³•é€‰æ‹©ä¸Šçš„æœ‰æ•ˆæ€§ä¸æ³›åŒ–èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="291-MemoryKT-An-Integrative-Memory-and-Forgetting-Method-for-Knowledge-Tracing"><a href="#291-MemoryKT-An-Integrative-Memory-and-Forgetting-Method-for-Knowledge-Tracing" class="headerlink" title="291. MemoryKT: An Integrative Memory-and-Forgetting Method for Knowledge Tracing"></a>291. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/MemoryKT__An_Integrative_Memory-and-Forgetting_Method_for_Knowledge_Tracing.pdf">MemoryKT: An Integrative Memory-and-Forgetting Method for Knowledge Tracing</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">South China Normal University</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ—¶åºå˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰çš„çŸ¥è¯†è¿½è¸ªï¼ˆKTï¼‰æ¨¡å‹MemoryKTï¼Œå°†è®°å¿†çš„ç¼–ç ã€å­˜å‚¨å’Œæ£€ç´¢ä¸‰é˜¶æ®µè¿‡ç¨‹è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶åœ¨æ—¶åºæµç¨‹ä¸­åµŒå…¥ä¸ªæ€§åŒ–é—å¿˜æ¨¡å—ï¼ŒåŠ¨æ€è°ƒèŠ‚å­¦ç”Ÿè®°å¿†å­˜å‚¨å¼ºåº¦ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMemoryKTåœ¨å››ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰ä¸»æµKTæ–¹æ³•ï¼Œæå‡äº†æ¨¡å‹çš„æ€§èƒ½ä¸ä¸ªæ€§åŒ–å»ºæ¨¡èƒ½åŠ›ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="292-Fast-and-Generalizable-parameter-embedded-Neural-Operators-for-Lithium-Ion-Battery-Simulation"><a href="#292-Fast-and-Generalizable-parameter-embedded-Neural-Operators-for-Lithium-Ion-Battery-Simulation" class="headerlink" title="292. Fast and Generalizable parameter-embedded Neural Operators for Lithium-Ion Battery Simulation"></a>292. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Fast_and_Generalizable_parameter-embedded_Neural_Operators_for_Lithium-Ion_Battery_Simulation.pdf">Fast and Generalizable parameter-embedded Neural Operators for Lithium-Ion Battery Simulation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">RWTH Aachen University</span></p>
<p>æœ¬æ–‡æå‡ºå¹¶ç³»ç»Ÿæ¯”è¾ƒäº†ä¸‰ç§ç®—å­å­¦ä¹ ç¥ç»ç½‘ç»œï¼ˆDeepONetã€FNOå’Œæ–°æå‡ºçš„å‚æ•°åµŒå…¥Fourierç¥ç»ç®—å­PE-FNOï¼‰åœ¨é”‚ç¦»å­ç”µæ± ä»¿çœŸä¸­çš„åº”ç”¨ã€‚PE-FNOåœ¨ä¿æŒé«˜å‡†ç¡®ç‡çš„åŒæ—¶å®ç°äº†å¯¹ææ–™å‚æ•°å¹¿æ³›å˜åŒ–çš„æ³›åŒ–ï¼Œå¹¶åœ¨é€Ÿåº¦ä¸Šæ¯”ä¼ ç»Ÿå¤šçº¿ç¨‹ä»¿çœŸå™¨å¿«çº¦ä¸¤ç™¾å€ï¼Œé€‚åˆå®æ—¶ç”µæ± ç®¡ç†å’Œå¤§è§„æ¨¡æ¨æ–­ä»»åŠ¡ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="293-FNBT-Full-Negation-Belief-Transformation-for-Open-World-Information-Fusion-Based-on-Dempster-Shafer-Theory-of-Evidence"><a href="#293-FNBT-Full-Negation-Belief-Transformation-for-Open-World-Information-Fusion-Based-on-Dempster-Shafer-Theory-of-Evidence" class="headerlink" title="293. FNBT: Full Negation Belief Transformation for Open-World Information Fusion Based on Dempster-Shafer Theory of Evidence"></a>293. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/FNBT__Full_Negation_Belief_Transformation_for_Open-World_Information_Fusion_Based_on_Dempster-Shafer.pdf">FNBT: Full Negation Belief Transformation for Open-World Information Fusion Based on Dempster-Shafer Theory of Evidence</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">School of Artificial Intelligence, South China Normal University</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºDempster-Shaferè¯æ®ç†è®ºçš„å…¨å¦å®šä¿¡å¿µå˜æ¢ï¼ˆFNBTï¼‰æ–¹æ³•ï¼Œç”¨äºè§£å†³å®é™…åº”ç”¨ä¸­å› å¼‚æ„å¸§å¯¼è‡´çš„ä¿¡æ¯èåˆé—®é¢˜ã€‚FNBTé€šè¿‡å¼•å…¥å¼€æ”¾ä¸–ç•Œåˆ¤æ®ã€å¸§æ‰©å±•å’Œå…¨å¦å®šæœºåˆ¶ï¼Œå°†åŸå§‹æ¦‚ç‡åˆ†é…æ˜ å°„åˆ°æ‰©å±•å¸§ï¼Œä½¿ä¼ ç»Ÿç»„åˆè§„åˆ™åœ¨å¼€æ”¾ä¸–ç•Œä¸‹æœ‰æ•ˆï¼Œç†è®ºè¯æ˜å…¶å…·å¤‡è´¨é‡å‡½æ•°ä¸å˜æ€§ã€å¯ç»§æ‰¿æ€§å’Œæœ¬è´¨å†²çªæ¶ˆé™¤ç­‰æ€§è´¨ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFNBTåœ¨å¤šä¸ªçœŸå®åˆ†ç±»ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«é€‚ç”¨äºæ•°æ®å­¤å²›å’Œå¼‚æ„æ•°æ®æºèåˆåœºæ™¯ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="294-Multi-modal-Adaptive-Mixture-of-Experts-for-Cold-start-Recommendation"><a href="#294-Multi-modal-Adaptive-Mixture-of-Experts-for-Cold-start-Recommendation" class="headerlink" title="294. Multi-modal Adaptive Mixture of Experts for Cold-start Recommendation"></a>294. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Multi-modal_Adaptive_Mixture_of_Experts_for_Cold-start_Recommendation.pdf">Multi-modal Adaptive Mixture of Experts for Cold-start Recommendation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">VNU University of Engineering and Technology</span></p>
<p>æœ¬è®ºæ–‡æå‡ºäº†MAMEXæ¡†æ¶ï¼Œé€šè¿‡å¤šæ¨¡æ€ä¸“å®¶ç½‘ç»œå’Œå¯å­¦ä¹ é—¨æ§æœºåˆ¶å¯¹å†·å¯åŠ¨æ¨èç³»ç»Ÿä¸­çš„å¤šæ¨¡æ€ä¿¡æ¯ï¼ˆå¦‚å›¾åƒã€æ–‡æœ¬ï¼‰è¿›è¡Œè‡ªé€‚åº”èåˆï¼ŒåŠ¨æ€å¹³è¡¡å„æ¨¡æ€è´¡çŒ®ï¼Œå¹¶å¼•å…¥æ­£åˆ™é¡¹é˜²æ­¢æ¨¡æ€å¡Œç¼©ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMAMEXåœ¨å¤šä¸ªAmazonæ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæå‡äº†Recallå’ŒNDCGæŒ‡æ ‡ï¼ŒéªŒè¯äº†æ¨¡å‹çš„æœ‰æ•ˆæ€§å’Œé€‚åº”æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="295-Deep-Learning-Based-Analysis-of-Power-Consumption-in-Gasoline-Electric-and-Hybrid-Vehicles"><a href="#295-Deep-Learning-Based-Analysis-of-Power-Consumption-in-Gasoline-Electric-and-Hybrid-Vehicles" class="headerlink" title="295. Deep Learning-Based Analysis of Power Consumption in Gasoline, Electric, and Hybrid Vehicles"></a>295. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Deep_Learning-Based_Analysis_of_Power_Consumption_in_Gasoline,_Electric,_and_Hybrid_Vehicles.pdf">Deep Learning-Based Analysis of Power Consumption in Gasoline, Electric, and Hybrid Vehicles</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">National Research Council Canada</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ ï¼ˆTCNã€LSTMã€Transformerï¼‰ä¸ä¼ ç»Ÿæœºå™¨å­¦ä¹ ï¼ˆRFï¼‰çš„æ•°æ®é©±åŠ¨æ–¹æ³•ï¼Œåˆ©ç”¨è½¦è¾†åŠ¨åŠ›ç³»ç»ŸåŠ¨æ€ç‰¹å¾ï¼Œé¢„æµ‹æ±½æ²¹è½¦ï¼ˆICEï¼‰ã€ç”µåŠ¨è½¦ï¼ˆEVï¼‰ã€æ··åˆåŠ¨åŠ›è½¦ï¼ˆHEVï¼‰çš„ç¬æ—¶ä¸ç´¯è®¡èƒ½è€—ï¼Œå¹¶æ”¶é›†äº†ä¸‰ç±»è½¦è¾†çš„çœŸå®é“è·¯æ•°æ®ã€‚ç»“æœè¡¨æ˜ï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨ICEä¸Šçš„é¢„æµ‹ç²¾åº¦æé«˜ï¼ˆMAEå’ŒRMSEçº¦ä¸º10^-3ï¼‰ï¼Œåœ¨EVå’ŒHEVä¸ŠTransformerå’ŒLSTMè¡¨ç°æœ€ä½³ï¼Œç´¯è®¡èƒ½è€—è¯¯å·®ä½äº4.1%å’Œ2.1%ï¼Œä¸”ä¸ç¡®å®šæ€§åˆ†ææ˜¾ç¤ºEVå’ŒHEVé¢„æµ‹æ³¢åŠ¨æ›´å¤§ï¼Œçªæ˜¾äº†å¤æ‚åŠ¨åŠ›ç³»ç»Ÿå¯¹èƒ½è€—å»ºæ¨¡çš„æŒ‘æˆ˜ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="296-Topological-Feature-Compression-for-Molecular-Graph-Neural-Networks"><a href="#296-Topological-Feature-Compression-for-Molecular-Graph-Neural-Networks" class="headerlink" title="296. Topological Feature Compression for Molecular Graph Neural Networks"></a>296. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Topological_Feature_Compression_for_Molecular_Graph_Neural_Networks.pdf">Topological Feature Compression for Molecular Graph Neural Networks</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Imperial College London</span></p>
<p>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§ç»“åˆé«˜é˜¶æ‹“æ‰‘ç‰¹å¾å‹ç¼©çš„åˆ†å­å›¾ç¥ç»ç½‘ç»œï¼ˆPACTNetï¼‰ï¼Œé€šè¿‡ECCç®—æ³•å°†é«˜é˜¶ç»†èƒå¤å½¢çš„æ‹“æ‰‘ç‰¹å¾ä¸ä¼ ç»Ÿåˆ†å­å›¾ç‰¹å¾èåˆï¼Œæœ‰æ•ˆæ•æ‰å…¨çƒå‡ ä½•ä¿¡æ¯ä¸”ä¿æŒç‰¹å¾çš„å¯è§£é‡Šæ€§å’Œé«˜æ•ˆè®¡ç®—ã€‚é€šè¿‡åœ¨å¤šä¸ªåˆ†å­æ€§è´¨é¢„æµ‹åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼ŒPACTNetåœ¨å¤§å¤šæ•°ä»»åŠ¡ä¸­å®ç°äº†ç»Ÿè®¡å­¦æ˜¾è‘—ä¼˜äºç°æœ‰ä¸»æµGNNæ¨¡å‹çš„è¡¨ç°ï¼Œå…¼é¡¾äº†å‡†ç¡®ç‡ã€é²æ£’æ€§å’Œè®¡ç®—æ•ˆç‡ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="297-Frequency-Domain-Analysis-of-Time-Dependent-Multiomic-Data-in-Progressive-Neurodegenerative-Diseases-A-Proposed-Quantum-Classical-Hybrid-Approach-with-Quaternionic-Extensions"><a href="#297-Frequency-Domain-Analysis-of-Time-Dependent-Multiomic-Data-in-Progressive-Neurodegenerative-Diseases-A-Proposed-Quantum-Classical-Hybrid-Approach-with-Quaternionic-Extensions" class="headerlink" title="297. Frequency-Domain Analysis of Time-Dependent Multiomic Data in Progressive Neurodegenerative Diseases: A Proposed Quantum-Classical Hybrid Approach with Quaternionic Extensions"></a>297. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Frequency-Domain_Analysis_of_Time-Dependent_Multiomic_Data_in_Progressive_Neurodegenerative_Diseases.pdf">Frequency-Domain Analysis of Time-Dependent Multiomic Data in Progressive Neurodegenerative Diseases: A Proposed Quantum-Classical Hybrid Approach with Quaternionic Extensions</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Massachusetts General Hospital</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§å°†å¤šç»„å­¦å’Œç¥ç»å½±åƒæ—¶åºæ•°æ®é€šè¿‡å‚…é‡Œå¶&#x2F;Laplaceå˜æ¢è½¬å…¥é¢‘åŸŸï¼Œå¹¶åˆ©ç”¨å“ˆå¯†é¡¿é‡å»ºæ¨¡ã€å˜åˆ†é‡å­ç‰¹å¾æ±‚è§£å™¨ï¼ˆVQEï¼‰å’Œå››å…ƒæ•°æ‰©å±•è¿›è¡Œé«˜ç»´ç‰¹å¾æå–å’Œç–¾ç—…åŠ¨åŠ›å­¦å»ºæ¨¡çš„æ–¹æ³•ã€‚ç»“è®ºæŒ‡å‡ºè¯¥ç†è®ºæ¡†æ¶ä¸ºæœªæ¥ç”¨é‡å­æ··åˆè®¡ç®—å’Œè¶…å¤æ•°æ–¹æ³•åˆ†æç¥ç»å˜æ€§ç—…æä¾›äº†æ•°å­¦åŸºç¡€ï¼Œæœ‰æœ›æå‡é«˜å±æ‚£è€…é¢„æµ‹å’Œç²¾å‡†åŒ»ç–—å†³ç­–ï¼Œä½†éœ€è¿›ä¸€æ­¥å®è¯éªŒè¯ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="298-Generative-Inversion-for-Property-Targeted-Materials-Design-Application-to-Shape-Memory-Alloys"><a href="#298-Generative-Inversion-for-Property-Targeted-Materials-Design-Application-to-Shape-Memory-Alloys" class="headerlink" title="298. Generative Inversion for Property-Targeted Materials Design: Application to Shape Memory Alloys"></a>298. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Generative_Inversion_for_Property-Targeted_Materials_Design__Application_to_Shape_Memory_Alloys.pdf">Generative Inversion for Property-Targeted Materials Design: Application to Shape Memory Alloys</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Xiâ€™an Jiaotong University</span></p>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰åæ¼”çš„æ–°å‹é«˜æ€§èƒ½å½¢çŠ¶è®°å¿†åˆé‡‘ï¼ˆSMAï¼‰é€†å‘è®¾è®¡æ¡†æ¶ï¼Œç»“åˆé¢„è®­ç»ƒGANå’Œæ€§è´¨é¢„æµ‹æ¨¡å‹ï¼Œé€šè¿‡æ¢¯åº¦ä¼˜åŒ–åœ¨æ½œç©ºé—´ç”Ÿæˆæ»¡è¶³æŒ‡å®šæ€§èƒ½æŒ‡æ ‡çš„åˆé‡‘æˆåˆ†ä¸å·¥è‰ºå‚æ•°ã€‚å®éªŒåˆæˆå’Œè¡¨å¾çš„äº”ç§NiTiåŸºåˆé‡‘å‡è¾¾åˆ°é«˜è½¬å˜æ¸©åº¦å’Œå¤§æœºæ¢°åŠŸè¾“å‡ºï¼ŒA1åˆé‡‘æ€§èƒ½ä¼˜å¼‚ï¼ŒéªŒè¯äº†æ¡†æ¶çš„æœ‰æ•ˆæ€§å’Œå¹¿æ³›é€‚ç”¨æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="299-Disentangling-Multiplex-Spatial-Temporal-Transition-Graph-Representation-Learning-for-Socially-Enhanced-POI-Recommendation"><a href="#299-Disentangling-Multiplex-Spatial-Temporal-Transition-Graph-Representation-Learning-for-Socially-Enhanced-POI-Recommendation" class="headerlink" title="299. Disentangling Multiplex Spatial-Temporal Transition Graph Representation Learning for Socially Enhanced POI Recommendation"></a>299. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/Disentangling_Multiplex_Spatial-Temporal_Transition_Graph_Representation_Learning_for_Socially_Enhan.pdf">Disentangling Multiplex Spatial-Temporal Transition Graph Representation Learning for Socially Enhanced POI Recommendation</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">South China Normal University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºäº†DiMuSTæ–¹æ³•ï¼Œé€šè¿‡æ„å»ºç¤¾ä¼šå¼‚è´¨å›¾å’Œå¤šè·¯ç©ºé—´-æ—¶é—´è½¬ç§»å›¾ï¼Œåˆ©ç”¨Disentangled Variational Multiplex Graph Auto-Encoder (DAE)å®ç°ç©ºé—´-æ—¶é—´ä¿¡æ¯çš„å…±äº«ä¸ç§æœ‰åˆ†å¸ƒè§£è€¦ï¼Œå¹¶é€šè¿‡Product of Expertsæœºåˆ¶èåˆå…±äº«ç‰¹å¾ï¼Œå¯¹ç§æœ‰ç‰¹å¾è¿›è¡Œå¯¹æ¯”çº¦æŸå»å™ªã€‚è¯¥æ–¹æ³•åœ¨ä¸¤ä¸ªçœŸå®æ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰POIæ¨èæ–¹æ³•ï¼Œæœ‰æ•ˆæå‡äº†æ¨èå‡†ç¡®ç‡å’Œæ¨¡å‹é²æ£’æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>
<h3 id="300-EMPATHIA-Multi-Faceted-Human-AI-Collaboration-for-Refugee-Integration"><a href="#300-EMPATHIA-Multi-Faceted-Human-AI-Collaboration-for-Refugee-Integration" class="headerlink" title="300. EMPATHIA: Multi-Faceted Human-AI Collaboration for Refugee Integration"></a>300. <a target="_blank" rel="noopener" href="http://172.16.18.71:5000/pdfs/papers_auto_crawl/2025/2025-08/2025-08-12/EMPATHIA__Multi-Faceted_Human-AI_Collaboration_for_Refugee_Integration.pdf">EMPATHIA: Multi-Faceted Human-AI Collaboration for Refugee Integration</a></h3><p><span style="
    font-size: 15px !important; 
    color: #555 !important; 
    background: #f9f9f9 !important; 
    padding: 6px 10px !important; 
    border-radius: 4px !important; 
    margin: 6px 0 8px !important; 
    display: inline-block !important; 
    font-style: italic !important;     /* æ–œä½“ */
    font-weight: bold !important;      /* åŠ ç²— */
">Texas A&amp;M University</span></p>
<p>è¯¥è®ºæ–‡æå‡ºEMPATHIAæ¡†æ¶ï¼Œé€šè¿‡å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆæƒ…æ„Ÿã€æ–‡åŒ–ã€ä¼¦ç†ä¸‰ä»£ç†ï¼‰åŠselectorâ€“validatoræ¶æ„ï¼Œå®ç°éš¾æ°‘å®‰ç½®çš„äººæœºååŒå†³ç­–ï¼Œå…¼é¡¾æƒ…æ„Ÿã€æ–‡åŒ–å’Œä¼¦ç†ä»·å€¼ã€‚å®éªŒè¯æ˜ï¼Œåœ¨UN Kakumaæ•°æ®é›†ä¸Šï¼Œç³»ç»Ÿèƒ½ä»¥87.4%ä¸€è‡´ç‡ç»™å‡ºå¯è§£é‡Šæ¨èï¼Œæœ‰æ•ˆæå‡å®‰ç½®å…¬å¹³æ€§å’Œå¯æ‰©å±•æ€§ã€‚</p>
<img src="https://images.unsplash.com/photo-1506784983877-45594efa4cbe?auto=format&fit=crop&w=600&q=80" srcset="/img/loading.gif" lazyload alt="è®ºæ–‡é…å›¾" width="300px" style="display: block; margin: 0 auto;" />

<hr>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>ä»Šæ—¥è®ºæ–‡æŠ¥çº¸</div>
      <div>http://example.com/2025/08/2025-08-13_article/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>ä½œè€…</div>
          <div>Ywfhhh</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>å‘å¸ƒäº</div>
          <div>2025å¹´8æœˆ12æ—¥</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>è®¸å¯åè®®</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - ç½²å">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/08/2025-08-14_article/" title="ä»Šæ—¥è®ºæ–‡æŠ¥çº¸">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">ä»Šæ—¥è®ºæ–‡æŠ¥çº¸</span>
                        <span class="visible-mobile">ä¸Šä¸€ç¯‡</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/08/2025-08-12_article/" title="ä»Šæ—¥è®ºæ–‡æŠ¥çº¸">
                        <span class="hidden-mobile">ä»Šæ—¥è®ºæ–‡æŠ¥çº¸</span>
                        <span class="visible-mobile">ä¸‹ä¸€ç¯‡</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://lib.baomitu.com/valine/1.5.1/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"opdC4BuOPaDCEVIDXc9OKzUp-gzGzoHsz","appKey":"va2F2XvdFvtuyZh8JscAcxdH","path":"window.location.pathname","placeholder":"æ¬¢è¿äº¤æµè®¨è®º...","avatar":"retro","meta":["nick","mail","link"],"requiredFields":[],"pageSize":10,"lang":"zh-CN","highlight":false,"recordIP":false,"serverURLs":"","emojiCDN":null,"emojiMaps":null,"enableQQ":false,"enable":true,"appid":"opdC4BuOPaDCEVIDXc9OKzUp-gzGzoHsz","appkey":"va2F2XvdFvtuyZh8JscAcxdH","notify":false,"verify":false},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>ç›®å½•</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">æœç´¢</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">å…³é”®è¯</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        æ€»è®¿é—®é‡ 
        <span id="busuanzi_value_site_pv"></span>
         æ¬¡
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        æ€»è®¿å®¢æ•° 
        <span id="busuanzi_value_site_uv"></span>
         äºº
      </span>
    
    

  

</div>

  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- ä¸»é¢˜çš„å¯åŠ¨é¡¹ï¼Œå°†å®ƒä¿æŒåœ¨æœ€åº•éƒ¨ -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">åšå®¢åœ¨å…è®¸ JavaScript è¿è¡Œçš„ç¯å¢ƒä¸‹æµè§ˆæ•ˆæœæ›´ä½³</div>
  </noscript>
</body>
</html>
